<!DOCTYPE html>
<html>
<head>
    
<!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-126536496-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    
    <title>无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记 | 张逸霄的技术小站 | 欢迎RSS订阅我的个人主页！</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="structure,NLP">
    <meta name="description" content="这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。">
<meta name="keywords" content="structure,NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记">
<meta property="og:url" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/index.html">
<meta property="og:site_name" content="张逸霄的技术小站">
<meta property="og:description" content="这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/1.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/3.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/4.png">
<meta property="og:updated_time" content="2020-02-10T13:43:37.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记">
<meta name="twitter:description" content="这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。">
<meta name="twitter:image" content="http://ldzhangyx.github.io/2020/02/07/diora-urnng/1.png">
    
        <link rel="alternate" type="application/atom+xml" title="张逸霄的技术小站" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/icon.png">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">张逸霄</h5>
          <a href="mailto:ldzhangyx@outlook.com" title="ldzhangyx@outlook.com" class="mail">ldzhangyx@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/pubs"  >
                <i class="icon icon-lg icon-pubs"></i>
                论文列表
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/projects"  >
                <i class="icon icon-lg icon-code"></i>
                项目列表
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/community"  >
                <i class="icon icon-lg icon-microphone"></i>
                社群活动
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/ldzhangyx" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                GitHub
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-link"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-minus"></i>
                Minus
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://yixiao-music.github.io" target="_blank" >
                <i class="icon icon-lg icon-music"></i>
                音乐会议Deadline
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/abc"  >
                <i class="icon icon-lg icon-play"></i>
                ABCjs在线渲染工具
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-02-06T18:44:05.000Z" itemprop="datePublished" class="page-time">
  2020-02-07
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#参考文献"><span class="post-toc-number">1.</span> <span class="post-toc-text">参考文献</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#正文"><span class="post-toc-number">2.</span> <span class="post-toc-text">正文</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Introduction"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">Introduction</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#DIORA"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">DIORA</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#用inside-outside算法填写chart"><span class="post-toc-number">2.3.1.</span> <span class="post-toc-text">用inside-outside算法填写chart</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Inside-Pass"><span class="post-toc-number">2.3.1.1.</span> <span class="post-toc-text">Inside Pass</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#TreeLSTM"><span class="post-toc-number">2.3.1.1.1.</span> <span class="post-toc-text">TreeLSTM</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#MLP"><span class="post-toc-number">2.3.1.1.2.</span> <span class="post-toc-text">MLP</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Outside-Pass"><span class="post-toc-number">2.3.1.2.</span> <span class="post-toc-text">Outside Pass</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#训练目标"><span class="post-toc-number">2.3.2.</span> <span class="post-toc-text">训练目标</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#DIORA-CKY-Parsing"><span class="post-toc-number">2.3.3.</span> <span class="post-toc-text">DIORA CKY Parsing</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#实验"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">实验</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#无监督解析"><span class="post-toc-number">2.4.1.</span> <span class="post-toc-text">无监督解析</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#无监督短语分割"><span class="post-toc-number">2.4.2.</span> <span class="post-toc-text">无监督短语分割</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#短语相似性"><span class="post-toc-number">2.4.3.</span> <span class="post-toc-text">短语相似性</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Related-Work"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">Related Work</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Latent-Tree-Learning"><span class="post-toc-number">2.5.1.</span> <span class="post-toc-text">Latent Tree Learning</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Neural-Inside-Outside-Parsers"><span class="post-toc-number">2.5.2.</span> <span class="post-toc-text">Neural Inside-Outside Parsers</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Learning-from-Raw-Text"><span class="post-toc-number">2.5.3.</span> <span class="post-toc-text">Learning from Raw Text</span></a></li></ol></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-diora-urnng"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-02-07 02:44:05" datetime="2020-02-06T18:44:05.000Z"  itemprop="datePublished">2020-02-07</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。</p>
<a id="more"></a>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="https://godweiyang.com/2018/04/19/inside-outside/" target="_blank" rel="noopener">https://godweiyang.com/2018/04/19/inside-outside/</a><br>[2] <a href="https://godweiyang.com/2019/07/25/diora/" target="_blank" rel="noopener">https://godweiyang.com/2019/07/25/diora/</a><br>[3] <a href="https://arxiv.org/pdf/1904.02142.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.02142.pdf</a></p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>DIORA这篇文章在NAACL 2019被提出，与其同时提出的还有URNNG。由paperwithcode.com提供的成分句法分析任务中F1值的排行来看，DIORA的效果排在第一，紧随其后的是Compound PCFG，随后是ON-LSTM，而URNNG排在最后。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="1.png" alt="2019年底的排行榜情况，在PTB上做parsing" title="">
                </div>
                <div class="image-caption">2019年底的排行榜情况，在PTB上做parsing</div>
            </figure>
<p>ON-LSTM是一个非常自然的模型，然而其建模效果似乎并不出色。我推测是因为ON-LSTM的训练机制，导致其无法先看到所有的单词，再导出树。这样做出来的树会存在明显的不平衡现象，即树很可能是一棵极度不平衡的二叉树。</p>
<p>而直接通过整个句子对树进行推导的算法因此更有可能达到一个更好的结果。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>句法分析被广泛用于NLP下游任务，然而tree data很少，且仅限于newswire域。想在其他的域中用这些方法，不仅缺少数据，而且效果很差。</p>
<p>无监督建模，比如BERT和ELBo都是很成功的，在无监督领域，作者提出了新的深度学习方法，从任何域中提取浅层解析和完整语法树。模型同时构建了内部成分的表示，反映了语法和语义规律，便于用在下游任务中。</p>
<p>模型建立在现有的<strong>latent tree chart parser</strong>工作上，这些方法为一棵树上的所有节点产生表示，表示为chart里的一个cell。每一个表示都是对所有可能子树的软加权。然而他们仍然需要句子级别的注释，因为它们目的是提升下游任务。</p>
<p>为了解决这个限制，作者提出了DIORA。DIORA将Inside-Outside算法（<a href="https://www.wikiwand.com/en/Inside%E2%80%93outside_algorithm）合并到一个latent" target="_blank" rel="noopener">https://www.wikiwand.com/en/Inside%E2%80%93outside_algorithm）合并到一个latent</a> tree chart parser中。自下而上的inside算法，计算输入句子中二叉树所有可能成分的表示形式。这个步骤等效于之前研究的forward pass。这些inside表示只编码了当前的子树，忽略了所有的外界上下文；而outside算法，对每个节点自上而下地计算，为节点的子树表示提供一个外部的上下文。然后对模型进行训练，目标为leaf结点的outside表示能够重建leaf的输入单词，类似于mask的语言模型的预训练，但是我们动态编程预测每一个单词用的是一个没有mask的上下文。</p>
<p>怎么得到一棵最可能的树？通过CKY算法和各个constituents之间的compatibility。之前的工作不是没有很好地对齐已知的treebanks，就是没有显式建模短语的机制，需要复杂的过程提取结构。</p>
<h2 id="DIORA"><a href="#DIORA" class="headerlink" title="DIORA"></a>DIORA</h2><p>目标是设计一个可以从原始文本中学习结构的模型，和一个训练它的方法。模型遵循一个假设：<strong>句子的最有效压缩将来自于遵循基础输入的正确句法结构（the most effectie compression of a sentence will be derived from following the true syntactic structure of the underlying input）</strong>。模型建立在之前parser的基础上，用inside-outside算法进行了扩充，并且被训练为能通过outside上下文重现每一个输入词。根据我们的假设，在某种程度上收到“替代原理”（substitution principle）的启发，模型将通过发现、利用文本的句法规律性来最好地重构输入。</p>
<p>方法中，inside pass递归地压缩输入序列。在每一步中，将两个孩子的向量表示输入到合成函数（composition function）中，该函数输出父亲的inside向量表示。这个过程一直持续到树的根节点，最终生成代表整个句子的单个向量（图2a）.这类似于AE的压缩步骤，等效于现在的latent tree parser的前向传递。先从叶子节点开始，从下往上，每一个节点的inside向量和score都由它的两个儿子计算出来。</p>
<p>接下来，启动outside pass。使用一个通用的（根节点）的表示，它被当作一个单独的参数学习。我们展开它直到产生叶子结点的表示。之后，对叶子节点进行优化，以构建输入句子，就像AE所做的一样。计算每一个节点的outside向量时，输入则是其兄弟节点的inside向量和父结点的outside向量。可以看公式。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="用inside-outside算法填写chart"><a href="#用inside-outside算法填写chart" class="headerlink" title="用inside-outside算法填写chart"></a>用inside-outside算法填写chart</h3><p>由上文得知，inside得出来的表示不考虑外部上下文。当inside表示被计算后，我们通过一个top-down的outside pass来计算outside表示。填完表格后，每一个成分k（表格里的每一个cell），都有对应的</p>
<ul>
<li>一个inside向量$\bar{a}(k)$和</li>
<li>一个outside向量$\bar{b}(k)$，以及</li>
<li>inside相容性分数（compatibility score）$\bar{e}(k)$和</li>
<li>outside相容性分数$\bar{f}(k)$</li>
</ul>
<p>约定输入一个长度为T的句子x，每一个x都可以被预训练的embedding vector $v$表示。</p>
<h4 id="Inside-Pass"><a href="#Inside-Pass" class="headerlink" title="Inside Pass"></a>Inside Pass</h4><p>首先为了避免困扰，特此说明：在NLP的成分语法中，树的节点和叶子都是一个成分。</p>
<p>我们接下来约定i，j，k这些都指代的成分所包括的一个范围。</p>
<p>对于每一对相邻成分i和j，计算一个compatibility分数，和一个composition向量。</p>
<p>这样的分数和向量表示了特定范围k（k可以大于2）以内，k内所有可能的成分对（pair）进行软加权（soft weight）计算得出一个向量，那就是上层节点的inside向量。将这些成分对记为${k}$。</p>
<p>当span为1时，vector被初始化为embedding vector $v$的非线性变换；而score被初始化为0.</p>
<script type="math/tex; mode=display">
\begin{array}{l}{\left[\begin{array}{l}{x} \\ {o} \\ {u}\end{array}\right]=\left[\begin{array}{c}{\sigma} \\ {\sigma} \\ {\tanh }\end{array}\right]\left(U_{\psi} v_{k}+b\right)} \\ {\bar{a}(k)=o+\tanh (x \odot u)} \\ {\bar{e}(k)=0}\end{array}</script><p>作者说明：This function shares its bias term b with $Compose_α$, although $U_ψ$ is not tied to any other weights.</p>
<p>而表格的高层通过这样的加法进行计算：</p>
<script type="math/tex; mode=display">
\begin{aligned} \bar{a}(k) &=\sum_{i, j \in\{k\}} e(i, j) a(i, j) \\ \bar{e}(k) &=\sum_{i, j \in\{k\}} e(i, j) \hat{e}(i, j) \end{aligned}</script><p>这也很好理解，这就是软加权的过程。</p>
<p>相容函数$\hat{e}$（区分相容分数$\hat{e}$）旨在产生一个分数计算两个相邻的cell有多大可能被合并。我们使用被学习到参数的矩阵S，实现一个双线性函数（矩阵模拟函数功能）。我们额外加上了原有cell的分数。直觉上来说，这些独立的分数关系到这些cell有多大可能存在于最后的二叉树中。</p>
<p>相容函数$\hat{e}$这么计算：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&e(i, j)=\frac{\exp (\hat{e}(i, j))}{\sum_{\hat{i}, \hat{j} \in\{k\}} \exp (\hat{e}(\hat{i}, \hat{j}))}\\
&\hat{e}(i, j)=\phi\left(\bar{a}(i), \bar{a}(j) ; S_{\alpha}\right)+\bar{e}(i)+\bar{e}(j)
\end{aligned}</script><p>其中的双线性投影$\phi$被这么定义：</p>
<script type="math/tex; mode=display">
\phi(u, v ; W)=u^{\top} W v</script><p>其实有点类似于attention计算。</p>
<p>上面的路线最终得到了$e(i,j)$。</p>
<p>之后通过composition function得到$a(i,j)$。</p>
<p>这个函数的选择有好几种。可以选择TreeLSTM或者是2层MLP。将函数定义为Compose，产生一个hidden state h，对于TreeLSTM，得到的是cell state。</p>
<script type="math/tex; mode=display">
a(i, j)=\text { Compose }_{\alpha}(\bar{a}(i), \bar{a}(j))</script><p>概述一下，inside向量 = 所有可能的节点对i,j的composition score的加权和</p>
<h5 id="TreeLSTM"><a href="#TreeLSTM" class="headerlink" title="TreeLSTM"></a>TreeLSTM</h5><p>TreeLSTM做了一个这样的变换，得到h和c：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{l}
{x} \\
{f_{i}} \\
{f_{j}} \\
{o} \\
{u}
\end{array}\right]=\left[\begin{array}{c}
{\sigma} \\
{\sigma} \\
{\sigma} \\
{\sigma} \\
{\tanh }
\end{array}\right]\left(U\left[\begin{array}{l}
{h_{i}} \\
{h_{j}}
\end{array}\right]+b+\left[\begin{array}{c}
{0} \\
{\omega} \\
{\omega} \\
{0} \\
{0}
\end{array}\right]\right)</script><script type="math/tex; mode=display">
\begin{array}{l}
{c=c_{i} \odot f_{i}+c_{j} \odot f_{j}+x \odot u} \\
{h=o+\tanh (c)}
\end{array}</script><p>参数w在inside里设为1，outside里设为0.</p>
<h5 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h5><script type="math/tex; mode=display">
h=W_{1}\left(W_{0}\left\langle h_{i}, h_{j}\right\rangle+ b\right)+b_{1}</script><p>其中$\left\langle h_{i}, h_{j}\right\rangle$是concat操作。</p>
<p>现在我们回顾一下整个inside过程：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>实际上这么多计算就是为了得到e和a……</p>
<p>当然$\hat{a}$还是有意义的，这是为了填chart。</p>
<h4 id="Outside-Pass"><a href="#Outside-Pass" class="headerlink" title="Outside Pass"></a>Outside Pass</h4><p>Outside算法类似inside算法。outside chart的根节点被作为偏差学习。后代cell被预测，使用的是可能的outside上下文的消歧（disambiguation）。每一个上下文都包括一个inside表中的同级cell，和一个outside表中的父级cell。因为计算顺序的问题，我们从上往下计算的时候，知道了父亲的outside变量，而不知道兄弟的outside变量，所以要用inside向量。</p>
<p>函数f与之前的函数e类似，在span k上对成分对(i,j)做归一化，消除了outside上下文的歧义。函数b为缺失的同级细胞生成短语级表示。公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\bar{b}(k) &=\sum_{i, j \in\{k\}} f(i, j) b(i, j) \\
\bar{f}(k) &=\sum_{i, j \in\{k\}} f(i, j) \hat{f}(i, j) \\
b(i, j) &=\operatorname{Compose}_{\beta}(\bar{a}(i), \bar{b}(j)) \\
\hat{f}(i, j) &=\phi\left(\bar{a}(i), \bar{b}(j) ; S_{\beta}\right)+\bar{e}(i)+\bar{f}(j)
\end{aligned}</script><p>在大多数实验中，b中使用的Compose与a共享参数，$\hat{e}$和$\hat{f}$依然是如此。？</p>
<h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><p>最后我们推出来每一个叶子结点的outside表示，这个表示是完全由context推出来的。因为根节点的vector是随机初始化的，所以不会存在信息泄露问题，使得outside向量混入了inside向量的信息。</p>
<p>使用类似AE的语言建模目标。<strong>也就是，我们希望叶子的outside向量能最大程度上还原叶子的inside向量</strong>。</p>
<p>我们模型并不限制单个z上x的重构，因为root的outside表示是用bias而不是root自己的inside向量表示的。因此，我们以许多子树根为condition的x，每个子树根仅仅是输入的子集的压缩。</p>
<p>为了近似这种重构，使用max-margin loss。考虑一组${x^*}$的N个negative samples，从词频出现频率中采样。？</p>
<p>terminal outside向量$\bar{b}(i)$被训练以预测原始输入$v_i$。</p>
<p>损失函数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_{\boldsymbol{x}}=\sum_{i=0}^{T-1} \sum_{i^{*}=0}^{N-1} \max (0,1-\bar{b}(i) \cdot \bar{a}(i)\\
\left.+\bar{b}(i) \cdot \bar{a}\left(i^{*}\right)\right)
\end{aligned}</script><p>这是一个max-margin loss。采样负样本有一个好处，会让训练更加稳健。这个loss的含义实际上就是：让outside向量与inside向量相似。</p>
<p>普通的交叉熵损失函数是：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&Z^{*}=\sum_{i^{*}=0}^{N-1} \exp \left(\bar{b}(i) \cdot \bar{a}\left(i^{*}\right)\right)\\
&L_{\boldsymbol{x}}=-\sum_{i=0}^{T-1} \log \frac{\exp (\bar{b}(i) \cdot \bar{a}(i))}{\exp (\bar{b}(i) \cdot \bar{a}(i))+Z^{\star}}
\end{aligned}</script><h3 id="DIORA-CKY-Parsing"><a href="#DIORA-CKY-Parsing" class="headerlink" title="DIORA CKY Parsing"></a>DIORA CKY Parsing</h3><p>为了获取DIORA的解析，我们要使用input sentence填充inside和outside chart。我们使用CKY过程，根据单一语法规则日趋最大得分分析。CKY算法的步骤如图。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>因为我的博客关注的是音乐方面的问题，NLP本身的实验细节我会略过。</p>
<h3 id="无监督解析"><a href="#无监督解析" class="headerlink" title="无监督解析"></a>无监督解析</h3><p>数据集为WSJ和MultiNLI。对比模型为PRPN，ON-LSTM，确定性构造的做分支、右分支、平衡树、随机数、RL-SPINN，ST-Gumbel。后两者训练用于NLI任务。</p>
<h3 id="无监督短语分割"><a href="#无监督短语分割" class="headerlink" title="无监督短语分割"></a>无监督短语分割</h3><h3 id="短语相似性"><a href="#短语相似性" class="headerlink" title="短语相似性"></a>短语相似性</h3><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Latent-Tree-Learning"><a href="#Latent-Tree-Learning" class="headerlink" title="Latent Tree Learning"></a>Latent Tree Learning</h3><ul>
<li>survey: Do latent tree learning models identify meaningful structure in sentences?</li>
<li>第一个parsing的积极结果：Grammar induction with neural language models: An unusual replication（URNNG）</li>
<li>IO算法计算边界概率：Structured alignment networks for matching sentences</li>
</ul>
<h3 id="Neural-Inside-Outside-Parsers"><a href="#Neural-Inside-Outside-Parsers" class="headerlink" title="Neural Inside-Outside Parsers"></a>Neural Inside-Outside Parsers</h3><ul>
<li>最接近：graph-based dependency parser + beam search: The insideoutside recursive neural network model for dependency parsing</li>
<li>Neural CRF Parser，需要标记和语法规则：Neural crf parsing.<br>In Association for Computational Linguistics</li>
<li>Structured alignment networks for matching sentences</li>
</ul>
<h3 id="Learning-from-Raw-Text"><a href="#Learning-from-Raw-Text" class="headerlink" title="Learning from Raw Text"></a>Learning from Raw Text</h3><p>语法结构的无监督学习，包括无监督分割、无监督依赖分析等。</p>
<p>相关文献包括：</p>
<ul>
<li>Semi-supervised recursive autoencoders for predicting sentiment distributions</li>
<li>The forest convolutional network: Compositional distributional semantics with a neural chart and without binarization</li>
<li>Learning to compose task-specific tree structures, AAAI 2018</li>
<li>Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs</li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2020-02-10T13:43:37.000Z" itemprop="dateUpdated">2020-02-10 21:43:37</time>
</span><br>


        
        原文地址：<a href="/2020/02/07/diora-urnng/" target="_blank" rel="external">http://ldzhangyx.github.io/2020/02/07/diora-urnng/</a>
        
    </div>
    
    <footer>
        <a href="http://ldzhangyx.github.io">
            <img src="/img/avatar.jpg" alt="张逸霄">
            张逸霄
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/structure/">structure</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&title=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&title=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&source=这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2020/02/07/diora-urnng/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2020/03/16/matplotlib-practice/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">matplotlib最佳实践技巧</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2020/01/13/binary-tree/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">利用networkx进行二叉树可视化</h4>
      </a>
    </div>
  
</nav>



    

















    <section class="comments" id="comments">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
        <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
        <script>
            var id = location.pathname
            if (location.pathname.length > 50) {
              id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
            }
            const gitalk = new Gitalk({
              clientID: '2fe1bcc914de92fd5141',
              clientSecret: '38e2830b66e3ce7e3a8b21cc86bbd2b715f6b2e3',
              accessToken: '6d91fb0c829c1a9b85219dd747aa5952fd3ec312',
              repo: 'ldzhangyx.github.io',
              owner: 'ldzhangyx',
              admin: ['ldzhangyx'],
              id: id,      // Ensure uniqueness and length less than 50
              title: document.title.split('|')[0],
              distractionFreeMode: false  // Facebook-like distraction free mode
            })
            gitalk.render('gitalk-container')
        </script>
    </section>
    


</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        非常感谢~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>张逸霄 &copy; 2017 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&title=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&title=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&source=这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2020/02/07/diora-urnng/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2020/02/07/diora-urnng/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACKUlEQVR42u3aS27DMAwFwNz/0um2RePgkVKDmhqtgtRwNVkQ/D0e8Xl+O1ffJM9fPZm8c8PBwMC4LeP59rx/pnfF389fvS25GwYGxjmM5BJV0tV194ZpDAwMjOSZ6uVyJAYGBsY64z3mM6UvBgbGOYxqwtdLB/N08w9rcQwMjBsy8q775z//yXwDAwPjVoxn8awkgslgoHcwMDBmM/IAV22Z5VExKlCT+2BgYAxl7Gr9V1crdi2fbZ5gYGBg/HtGjkmu3ksWq029FwEXAwNjNGOlfE0CblK+Nhc4MDAwDmD0mvLVC+XjzHKqioGBcQyj16xv/uNWunn5E2NgYBzASIrGXpBNWv+9dPPHXzEwMEYz1kePvbSvB4sGBhgYGOMY1bBYTSurV8+D+4ttEQwMjKGMalstX7moLmdUl8/KBwMDYxCj2npbefP656iPiIGBcXNGHjp7BW31nckPGkVuDAyM0YyV4jMfVfYSx8IwAAMDYxCjOhjIA2veMltZv8DAwDiH8ZmAWE0BcxIGBsbJjGrhujJISIJytBCGgYExmtGbJ+QLpvlPkw8YXgRcDAyMcYxn8exduUjeHxXPGBgYoxkrqxK7Bgm953sLHxgYGPdl9IrGvBGWhN08EGNgYJzMyANfMk5YSfs21OIYGBjHM3rNsh5420IYBgbGkYy9LbO8MbctNcTAwLghozcMqKaM1QS0sMaBgYExmpGXjtXvdy1Y9NgYGBgjGF/svfoIR/W8ogAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdnjs.cloudflare.com/ajax/libs/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Yixiao Zhang's Website';
            clearTimeout(titleTime);
        } else {
            document.title = 'Yixiao Zhang's Website';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
