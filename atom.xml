<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张逸霄的技术小站</title>
  
  <subtitle>欢迎RSS订阅我的个人主页！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ldzhangyx.github.io/"/>
  <updated>2020-08-30T19:51:39.896Z</updated>
  <id>http://ldzhangyx.github.io/</id>
  
  <author>
    <name>张逸霄</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>音乐生成工具包MusPy简介和快速上手指南</title>
    <link href="http://ldzhangyx.github.io/2020/08/30/muspy/"/>
    <id>http://ldzhangyx.github.io/2020/08/30/muspy/</id>
    <published>2020-08-30T09:35:01.000Z</published>
    <updated>2020-08-30T19:51:39.896Z</updated>
    
    <content type="html"><![CDATA[<p><strong>也许是全网第一篇MusPy评测？</strong></p><p>评价写在最前面：<strong>这是一个实用性极强的库，为每一个入行的人铺平了道路，使得人们能轻松地获取和清洗数据集。也许我该称呼它为symbolic music界的torchvision？总之，非常推荐作为轮子使用，加入到自己的常备库里。</strong></p><p><strong>但是，不可忽略的一点是，使用下来bug不少。建议等几个版本。</strong></p><p>很久没写笔记了。最近一段时间很忙，预计这几天会陆陆续续将看过的文章的笔记更新上。处于更新列表的文章列于这篇笔记最后。</p><h2 id="什么是MusPy"><a href="#什么是MusPy" class="headerlink" title="什么是MusPy"></a>什么是MusPy</h2><p>MusPy这个词来自于今年ISMIR里的论文：《MusPy: A Toolkit for Symbolic Music Generation》，作者是UCSD计算机音乐组的学生，其中一作Hao-Wen Dong曾是台湾Yi-Hsuan Yang组的学生，二作Ke Chen是上纽大Music X Lab的前学生。现两人均在UCSD读博。</p><p>文章中介绍到，MusPy是一个用于生成symbolic music的开源Python库，其功能包括：</p><ul><li>数据集准备，可以对接PyTorch和TensorFlow。</li><li>数据的读取和预处理，支持了常见格式，有这和其他库合作的接口。支持数种常见表示。</li><li>模型的评估算法和工具，包括音频渲染、乐谱可视化、pianoroll可视化，以及指标计算。</li></ul><p>实际上MusPy能够在下面的模块中给出帮助：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>在Introduction中，作者介绍了之前数据集存在的各种缺陷，以及工具包带来的一些意义。主要有：</p><ol><li>数据集中的数据由于目的不一致，所以编码也没有统一。如MIDI为了播放设计，MusicXML/LilyPond为了记谱软件开发，MEI（XML格式的一个编码）是为了管理组织音乐文件，还有一些是为了提高可读性。这些格式不一致的确对我们带来了很多困扰。</li><li>音乐有层次结构，如何存储和表达层次结构也有着不同的设计，难以统一。当然还有一些专门为了生成模型设计的表示形式，如PianoRoll之类的。</li><li>人们开发了一些音乐生成的评估指标，用于客观评价。一个提供其实现的库可以帮助模型更好进行复现。</li></ol><h3 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h3><p>Related Work模块中，作者探讨了相关工作。</p><ul><li>在数据集搜集上，几乎没有相近工作。Magenta也许算一个，但它们与自家模型实现绑定得很紧。（我们组都是预先处理好数据集，在内部共享通用的）</li><li>在数据处理上，Music21是一个通用的处理工具。（但是众所周知它不是特别好用）</li><li>jSymbolic提供了一个评估的手段，但是并没有为了生成模型评估优化过。（连我都没听过，也不知道作者到底哪里找到的，不容易。）</li></ul><p>下面来看一下各个模块的功能。MusPy的功能总览将在最后给出。</p><h3 id="MusPy支持的数据集"><a href="#MusPy支持的数据集" class="headerlink" title="MusPy支持的数据集"></a>MusPy支持的数据集</h3><p>MusPy提供了一个MusPy类，作为一个通用的container。目前MusPy支持下面的数据集。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>MusPy对象存储了音乐的下列数据：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>实际上作者为了方便使用，使得MusPy成为了一种平衡各个数据优点的类。MusPy同时也提供了到music21，mido，pretty_midi的PyPianoroll的转换接口。具体的展示我会放在实战里。</p><h3 id="MusPy允许导出的数据表示"><a href="#MusPy允许导出的数据表示" class="headerlink" title="MusPy允许导出的数据表示"></a>MusPy允许导出的数据表示</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>上图展示了支持的四种表示。我们组自己常用第一种表示。</p><h3 id="MusPy的评估工具"><a href="#MusPy的评估工具" class="headerlink" title="MusPy的评估工具"></a>MusPy的评估工具</h3><ul><li>与音高有关的metrics：polyphony, polyphony rate, pitch-in-scale rate, scale consistency, pitch entropy and pitch class entropy.</li><li>与节奏有关的metrics：empty-beat rate, drum-inpattern rate, drum pattern consistency and groove consistency.</li></ul><p>最后，放出MusPy的架构：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="MusPy快速实战"><a href="#MusPy快速实战" class="headerlink" title="MusPy快速实战"></a>MusPy快速实战</h2><p>我们使用下面的环境完成实战：Python 3.7，PyTorch，编程环境为Jupyter Notebook。</p><p>MusPy的GitHub地址在：<a href="https://github.com/salu133445/muspy" target="_blank" rel="noopener">https://github.com/salu133445/muspy</a><br>其文档在：<a href="https://salu133445.github.io/muspy/" target="_blank" rel="noopener">https://salu133445.github.io/muspy/</a></p><p>MusPy提供了两个流程图。第一张流程图展示了数据集的获取和加载流程：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="6.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>这张图展示了获取数据的过程。MusPy提供了两种内部处理流程。第一种允许直接使用数据集，第二种可以允许你预先保留数据集，进行保存，以避免每一次加载数据集都要进行额外的处理：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="8.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>第二张图展示了MusPy的数据IO：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="7.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="安装MusPy"><a href="#安装MusPy" class="headerlink" title="安装MusPy"></a>安装MusPy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install muspy</span><br></pre></td></tr></table></figure><p>过程很顺利，注意到pypianoroll，mido，music21，pretty-midi是muspy的依赖库（因为muspy提供了接口支持）</p><h3 id="任务：加载Nottingham数据集，并可视化数据"><a href="#任务：加载Nottingham数据集，并可视化数据" class="headerlink" title="任务：加载Nottingham数据集，并可视化数据"></a>任务：加载Nottingham数据集，并可视化数据</h3><p>首先我们通过下载API获取数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_collection = muspy.NottinghamDatabase(</span><br><span class="line">    <span class="string">"/gpfsnyu/scratch/yz6492/data/"</span>, </span><br><span class="line">    download_and_extract = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>具体各个数据集的加载方法可以参考<code>https://salu133445.github.io/muspy/doc/datasets.html</code>。</p><p>下载速度还行：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="10.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>实际下载下来是这个样子的：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="12.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="13.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>接下来转换格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_collection.convert()</span><br></pre></td></tr></table></figure><p>好像GG了……我改天去报个issue。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>总之先换一个数据集试试看。<strong>EssenFolksong数据集也不能正常转换，会被卡在927上。</strong>NESMusicDatabase目前是正常的。花了8分钟处理完毕，速度还行。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>转换完之后在目录下生成_converted目录，里面就是json文件：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>阅读Document，发现数据集加载函数中有一个use_converted参数，默认为None。</p><p>然后取一条数据出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_collection[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>当然可想而知得到的是json文件：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>将其转化成PyTorch的数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = data_collection.to_pytorch_dataset(representation=<span class="string">"pianoroll"</span>)</span><br></pre></td></tr></table></figure><p>这个函数是一个高级封装函数，其中包含了两个重要参数：representation和splits。</p><blockquote><p>representation参数接受‘event’, ‘note’, ‘pianoroll’, ‘monotoken’ and ‘polytoken’，而splits参数接受float或者list，划分为2-3份。</p></blockquote><p>我们先看看representation参数代表了什么：</p><p>参数为pianoroll时，数据被转换为了0-1矩阵，有128维：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="18.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>参数为monotoken时，函数果断报了个错。看来实际上函数只接受四种输入：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>当参数为pitch note event时，函数返回正常。</p><p>最后试图visualize这个数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_collection[<span class="number">0</span>].show_pianoroll()</span><br></pre></td></tr></table></figure><p>非常正常。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="20.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>试图显示score，报错提示要安装music font。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">muspy.download_bravura_font() <span class="comment"># run once</span></span><br><span class="line">muspy.show_score(data_collection[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p>报了个奇怪的错。总之score感觉没有那么好生成。成功之后会更新的。</p><p>结论：<strong>除了NottinghamDatabase这个意外，其他大部分函数运作正常，用起来很舒服。文档也还算清晰，值得好评。</strong></p><p>两个issue已经上报：</p><p><a href="https://github.com/salu133445/muspy/issues/2" target="_blank" rel="noopener">https://github.com/salu133445/muspy/issues/2</a><br><a href="https://github.com/salu133445/muspy/issues/3" target="_blank" rel="noopener">https://github.com/salu133445/muspy/issues/3</a></p><h3 id="任务：评测数据的基本指标"><a href="#任务：评测数据的基本指标" class="headerlink" title="任务：评测数据的基本指标"></a>任务：评测数据的基本指标</h3><h2 id="更新计划"><a href="#更新计划" class="headerlink" title="更新计划"></a>更新计划</h2><h3 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h3><ul><li>Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models</li><li>Jukebox: A Generative Model for Music</li><li>MixPoet: Diverse Poetry Generation via Learning Controllable Mixed Latent Space</li><li>Deep Unsupervised Drum Transcription</li><li>Vector Quantized Contrastive Predictive Coding for Template-based Music Generation</li><li>Variational Template Machine for Data-to-Text Generation</li><li>PIANOTREE VAE: Structured Representation Learning for Polyphonic Music</li><li>Learning Interpretable Representation for Controllable Polyphonic Music Generation</li><li>POP909: A Pop-song Dataset for Music Arrangement Generation</li></ul><h3 id="软件工程"><a href="#软件工程" class="headerlink" title="软件工程"></a>软件工程</h3><ul><li>前端工程，以及我为什么尝试做音乐智能的人机交互：一些思考</li></ul><h3 id="学术界和业界"><a href="#学术界和业界" class="headerlink" title="学术界和业界"></a>学术界和业界</h3><ul><li>20世纪出现的一些仍然未解决的问题，阅读心得</li><li>关于一套新的乐理体系</li><li>欧洲各个实验室的研究方向介绍</li><li>CSMT</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;也许是全网第一篇MusPy评测？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;评价写在最前面：&lt;strong&gt;这是一个实用性极强的库，为每一个入行的人铺平了道路，使得人们能轻松地获取和清洗数据集。也许我该称呼它为symbolic music界的torchvision？总
      
    
    </summary>
    
      <category term="软件工程" scheme="http://ldzhangyx.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="music generation" scheme="http://ldzhangyx.github.io/tags/music-generation/"/>
    
      <category term="音乐生成" scheme="http://ldzhangyx.github.io/tags/%E9%9F%B3%E4%B9%90%E7%94%9F%E6%88%90/"/>
    
      <category term="deep learning" scheme="http://ldzhangyx.github.io/tags/deep-learning/"/>
    
      <category term="toolkit" scheme="http://ldzhangyx.github.io/tags/toolkit/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch工程中，提升代码体验的几点想法</title>
    <link href="http://ldzhangyx.github.io/2020/06/20/python-init/"/>
    <id>http://ldzhangyx.github.io/2020/06/20/python-init/</id>
    <published>2020-06-20T13:09:22.470Z</published>
    <updated>2018-11-16T05:36:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>提及PyTorch的代码写作，我没有找到一个大家约定俗成的规约。我自己遵循了一些能让Python代码更具有可读性和持续开发的规则，现记录如下。</p><a id="more"></a><h2 id="保持工程的模块化"><a href="#保持工程的模块化" class="headerlink" title="保持工程的模块化"></a>保持工程的模块化</h2><p>一个我认为整洁的项目应该遵循这样的结构，现在我以一个Encoder-Decoder框架为例进行描述。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''The structure of my project.</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">+--data</span><br><span class="line">|--+log</span><br><span class="line">|--+dataset</span><br><span class="line">|  |  +--train.txt</span><br><span class="line">|  |  +--test.txt</span><br><span class="line">+--model</span><br><span class="line">|  +--__init__.py</span><br><span class="line">|  +--encoder.py</span><br><span class="line">|  +--decoder.py</span><br><span class="line">|  +--(model_name).py</span><br><span class="line">|  +--highway.py</span><br><span class="line">|  ...</span><br><span class="line">+--utils</span><br><span class="line">|  +--__init__.py</span><br><span class="line">|  +--batch_loader.py</span><br><span class="line">|  +--parameters.py</span><br><span class="line">|  +--functional.py</span><br><span class="line">|  ...</span><br><span class="line">+--README.md</span><br><span class="line">+--LICENSE</span><br><span class="line">+--test.py</span><br><span class="line">+--train.py</span><br></pre></td></tr></table></figure><p>在data文件夹里，放置数据集和模型，以及log输出；<br>在model文件夹里，将模型尽可能模块化，并用一个顶层模块将子模块组合起来。这个顶层模块要实现训练与测试的类方法。<br>在utils里放置参数列表文件，小工具，以及对数据预处理的文件。（我曾见过有用Jupyter Notebook进行可视化的数据清理的做法）<br>如果要开源，请加入README.md和LICENSE，一般我会选择GPL v3的License。<br>在test.py和train.py里实例化模型，进行训练和测试。</p><p>一个可以参照的GitHub开源项目可以点这里：<a href="https://github.com/kefirski/pytorch_RVAE" target="_blank" rel="noopener">https://github.com/kefirski/pytorch_RVAE</a></p><h2 id="写一个好的注释"><a href="#写一个好的注释" class="headerlink" title="写一个好的注释"></a>写一个好的注释</h2><p>Google曾经发布过一个<a href="https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/contents/" target="_blank" rel="noopener">代码风格指南</a>，里面详细地介绍了Python代码应当遵循的有用的规范。在里面的函数一节里，就提及了注释的规范。</p><p>对于文档注释，文档字符串是包, 模块, 类或函数里的第一个语句。这些字符串可以通过对象的<strong>doc</strong>成员被自动提取, 并且被pydoc所用。根据<a href="https://www.python.org/dev/peps/pep-0257/" target="_blank" rel="noopener">PEP-257</a>(这也是一个非常有名的指南)，文档字符串使用的注释风格应当是成对的三个双引号。</p><p>格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Add</span><span class="params">(arg_1, arg_2)</span>:</span></span><br><span class="line">    <span class="string">"""Add two numbers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    There should be some details if needed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        arg_1: The first number to be added.</span></span><br><span class="line"><span class="string">        arg_2: The second number to be added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        A number. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        ...</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>如果是书写一个类，那么在类声明的下一行应该对其<strong>所有的类成员Attributes</strong>做出解释。</p><h2 id="在容易混淆的函数声明中使用类型约束"><a href="#在容易混淆的函数声明中使用类型约束" class="headerlink" title="在容易混淆的函数声明中使用类型约束"></a>在容易混淆的函数声明中使用类型约束</h2><p>这是一点个人的看法。<a href="https://www.python.org/dev/peps/pep-0484/" target="_blank" rel="noopener">PEP-484</a>文档对类型约束提出了规范。在必要的时候使用类型约束能让我在运行之前就能发现一些问题。</p><p>不加类型约束：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greetings</span><span class="params">(name_list)</span>:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>加入类型约束：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greetings</span><span class="params">(name_list: List<span class="params">(str)</span>)</span> -&gt; str:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><h2 id="使用数据类装饰器（Python-3-7特性）"><a href="#使用数据类装饰器（Python-3-7特性）" class="headerlink" title="使用数据类装饰器（Python 3.7特性）"></a>使用数据类装饰器（Python 3.7特性）</h2><p>在使用数据类的时候（比如我的parameters.py中的Parameters类）（根据我的个人习惯，我会将文件名全部小写，但是类会大写首字母），遵循这一条会让可读性有一定提升。<a href="https://www.python.org/dev/peps/pep-0557/" target="_blank" rel="noopener">PEP-557</a>规定了相关规则。</p><p>顺带一提，建议工程中所有的类都<strong>显式继承object类</strong>或者<strong>nn.Module类</strong>。</p><p>原版代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, a, b)</span>:</span></span><br><span class="line">        self.a = a</span><br><span class="line">        self.b = b</span><br></pre></td></tr></table></figure></p><p>使用类装饰器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span></span><br><span class="line">    a: str</span><br><span class="line">    b: str</span><br></pre></td></tr></table></figure></p><p>这个类越是数据类，好处越明显。而且这个装饰器还会自动地帮助你实现一些魔术方法。</p><h2 id="使用新的Super方法调用"><a href="#使用新的Super方法调用" class="headerlink" title="使用新的Super方法调用"></a>使用新的Super方法调用</h2><p>在我们初始化一个神经网络模块的时候，这样的代码在开源代码中十分常见：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>但是这个超类方法可以被下列写法完全替代：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>推荐使用。</p><h2 id="使用-init-py文件"><a href="#使用-init-py文件" class="headerlink" title="使用__init__.py文件"></a>使用__init__.py文件</h2><p>这个文件的作用是将文件夹变为一个Python模块。Python 中的每个模块的包中，都有__init__.py 文件。</p><p>通常__init__.py 文件为空，但是我们还可以为它增加其他的功能。我们在导入一个包时，实际上是导入了它的__init__.py文件。这样我们可以在__init__.py文件中批量导入我们所需要的模块，而不再需要一个一个的导入。</p><p>这样做在写代码时有个额外的好处：在Visual Studio Code等编辑器中，编辑器能够进行<strong>智能提示和自动补全</strong>。</p><h2 id="在必要的时候使用assert"><a href="#在必要的时候使用assert" class="headerlink" title="在必要的时候使用assert"></a>在必要的时候使用assert</h2><p>assert是一个不怎么被提起的功能，然而我在实际使用中感受到assert可以帮助我们进行debug。一般来说，我进行debug最常用的方法是进行单步调试，在<strong>关键的地方打断点，观察变量列表</strong>；然而断点的机制决定了它并不是持久化的debug策略，我们在与其他人协作写代码的时候，也无法提醒其重点关注和检查哪些问题。</p><p>用于持久化进行测试的常见方法一般是将需要观察的变量进行print输出，然后<strong>观察output控制台</strong>。然而print函数在debug过程中可是要去掉的。所以assert函数可以<strong>在关键的地方对变量进行检查</strong>。通过这种检查，函数的功能得以保证，且无需添加if，避免了过深的隐蔽bug；此外，assert语句可以提醒其他的阅读这段代码的人：这个地方的变量应当满足什么要求，是怎么样的一个变量。</p><h2 id="持续更新中"><a href="#持续更新中" class="headerlink" title="持续更新中"></a>持续更新中</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;提及PyTorch的代码写作，我没有找到一个大家约定俗成的规约。我自己遵循了一些能让Python代码更具有可读性和持续开发的规则，现记录如下。&lt;/p&gt;
    
    </summary>
    
      <category term="软件工程" scheme="http://ldzhangyx.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="PyTorch" scheme="http://ldzhangyx.github.io/tags/PyTorch/"/>
    
      <category term="Python" scheme="http://ldzhangyx.github.io/tags/Python/"/>
    
      <category term="软件工程" scheme="http://ldzhangyx.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>一个罕见的bug：PyCharm无法连接SFTP server，提示could not resolve address</title>
    <link href="http://ldzhangyx.github.io/2020/05/12/pycharm-ssh-debug/"/>
    <id>http://ldzhangyx.github.io/2020/05/12/pycharm-ssh-debug/</id>
    <published>2020-05-12T05:37:48.000Z</published>
    <updated>2020-05-12T05:37:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>bug描述：</p><p>PyCharm 2019.2版本之前建立的file transfer和deployment连接失效，test connection提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Connection to xxx failed.</span><br><span class="line">Could not resolve xxx.</span><br></pre></td></tr></table></figure><p>分析：</p><p>这是一个罕见的bug，全网尚无同样的情况发生。由于我使用MobaXTerm仍然可以正常连接server，我推测问题在本机设置，可能是PyCharm或SSH的问题。</p><p>我记起之前在Windows下，我调整了<code>C:\Users\xxx\.ssh</code>文件夹的权限，问题可能出在这里。</p><p>我重新配置了该文件夹的权限，使得我的账户可以完全控制该文件夹和子文件。</p><p>之后我发现<code>known_hosts</code>文件在当前账户下没有写入权限。我重新设置了该文件的权限，分配了当前账户的完全控制权限，并且开启继承。之后用一个同名空文件将该文件覆盖。</p><p>问题解决，连接成功。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;bug描述：&lt;/p&gt;
&lt;p&gt;PyCharm 2019.2版本之前建立的file transfer和deployment连接失效，test connection提示：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cla
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="debug" scheme="http://ldzhangyx.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>matplotlib最佳实践技巧</title>
    <link href="http://ldzhangyx.github.io/2020/03/16/matplotlib-practice/"/>
    <id>http://ldzhangyx.github.io/2020/03/16/matplotlib-practice/</id>
    <published>2020-03-16T02:54:40.000Z</published>
    <updated>2020-04-20T03:08:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="在subplot中使用seaborn绘制子图"><a href="#在subplot中使用seaborn绘制子图" class="headerlink" title="在subplot中使用seaborn绘制子图"></a>在subplot中使用seaborn绘制子图</h2><p><a href="https://stackoverflow.com/questions/41384040/subplot-for-seaborn-boxplot" target="_blank" rel="noopener">https://stackoverflow.com/questions/41384040/subplot-for-seaborn-boxplot</a><br><a href="https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.pyplot.subplots.html" target="_blank" rel="noopener">https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.pyplot.subplots.html</a><br><a href="https://stackoverflow.com/questions/34162443/why-do-many-examples-use-fig-ax-plt-subplots-in-matplotlib-pyplot-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/34162443/why-do-many-examples-use-fig-ax-plt-subplots-in-matplotlib-pyplot-python</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = fig.subplot(nrows, ncolumns, figsize=(A,B)) <span class="comment"># 三个参数可选，如果不填就默认1x1</span></span><br><span class="line">                                                        <span class="comment"># 为什么要这样初始化，请看上面第三个链接</span></span><br><span class="line"><span class="comment"># 这里ax是一个列表，每一个元素就是子图index。</span></span><br><span class="line"><span class="comment"># fig是子图对象列表</span></span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">'title1'</span>) <span class="comment"># 以这种方式设定title</span></span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">'title1'</span>)</span><br><span class="line"></span><br><span class="line">sns.scatterplot(x, y, data, <span class="comment"># 指定数据</span></span><br><span class="line">                hue, palatte=<span class="string">'rainbow'</span>, <span class="comment"># 指定怎么分类，怎么染色</span></span><br><span class="line">                markers=<span class="keyword">True</span>, <span class="comment"># 指定图例</span></span><br><span class="line">                ax = axes[<span class="number">0</span>] <span class="comment"># 指定绘制在哪个子图里</span></span><br><span class="line">                )</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">axs[<span class="number">1</span>].scatter(x, y) <span class="comment">#plt直接操作</span></span><br></pre></td></tr></table></figure><p>其中axes的内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9ed85feb50&gt;,</span><br><span class="line">       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9ed8980650&gt;],</span><br><span class="line">      dtype=object)</span><br></pre></td></tr></table></figure><h2 id="在subplot中绘制3D图的不优雅的方法"><a href="#在subplot中绘制3D图的不优雅的方法" class="headerlink" title="在subplot中绘制3D图的不优雅的方法"></a>在subplot中绘制3D图的不优雅的方法</h2><p>使用<code>add_subplot()</code>方法，以和上面不一样的方法初始化子图。<br><a href="https://zhuanlan.zhihu.com/p/66306575" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/66306575</a><br><a href="https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html" target="_blank" rel="noopener">https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">121</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">122</span>) <span class="comment"># 用于别的子图</span></span><br></pre></td></tr></table></figure><p>当然，如果只想画一个3D图，还有别的办法可选，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">'3d'</span>)</span><br></pre></td></tr></table></figure><h2 id="matplotlib的图做交互式展示"><a href="#matplotlib的图做交互式展示" class="headerlink" title="matplotlib的图做交互式展示"></a>matplotlib的图做交互式展示</h2><p>使用ipympl扩展，在jupyter notebook和jupyter lab上均可使用。</p><p>安装完之后，在jupyter notebook的代码里加一行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib widget</span><br></pre></td></tr></table></figure><p>这里有一个坑是，2020年4月当前版本的new edge似乎有显示bug。我切换到firefox quantum之后可以正常交互。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;在subplot中使用seaborn绘制子图&quot;&gt;&lt;a href=&quot;#在subplot中使用seaborn绘制子图&quot; class=&quot;headerlink&quot; title=&quot;在subplot中使用seaborn绘制子图&quot;&gt;&lt;/a&gt;在subplot中使用seaborn绘制
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://ldzhangyx.github.io/tags/python/"/>
    
      <category term="matplotlib" scheme="http://ldzhangyx.github.io/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>无监督句法分析：《Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders》论文笔记</title>
    <link href="http://ldzhangyx.github.io/2020/02/07/diora-urnng/"/>
    <id>http://ldzhangyx.github.io/2020/02/07/diora-urnng/</id>
    <published>2020-02-06T18:44:05.000Z</published>
    <updated>2020-02-10T13:43:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。</p><a id="more"></a><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="https://godweiyang.com/2018/04/19/inside-outside/" target="_blank" rel="noopener">https://godweiyang.com/2018/04/19/inside-outside/</a><br>[2] <a href="https://godweiyang.com/2019/07/25/diora/" target="_blank" rel="noopener">https://godweiyang.com/2019/07/25/diora/</a><br>[3] <a href="https://arxiv.org/pdf/1904.02142.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.02142.pdf</a></p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>DIORA这篇文章在NAACL 2019被提出，与其同时提出的还有URNNG。由paperwithcode.com提供的成分句法分析任务中F1值的排行来看，DIORA的效果排在第一，紧随其后的是Compound PCFG，随后是ON-LSTM，而URNNG排在最后。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="2019年底的排行榜情况，在PTB上做parsing" title="">                </div>                <div class="image-caption">2019年底的排行榜情况，在PTB上做parsing</div>            </figure><p>ON-LSTM是一个非常自然的模型，然而其建模效果似乎并不出色。我推测是因为ON-LSTM的训练机制，导致其无法先看到所有的单词，再导出树。这样做出来的树会存在明显的不平衡现象，即树很可能是一棵极度不平衡的二叉树。</p><p>而直接通过整个句子对树进行推导的算法因此更有可能达到一个更好的结果。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>句法分析被广泛用于NLP下游任务，然而tree data很少，且仅限于newswire域。想在其他的域中用这些方法，不仅缺少数据，而且效果很差。</p><p>无监督建模，比如BERT和ELBo都是很成功的，在无监督领域，作者提出了新的深度学习方法，从任何域中提取浅层解析和完整语法树。模型同时构建了内部成分的表示，反映了语法和语义规律，便于用在下游任务中。</p><p>模型建立在现有的<strong>latent tree chart parser</strong>工作上，这些方法为一棵树上的所有节点产生表示，表示为chart里的一个cell。每一个表示都是对所有可能子树的软加权。然而他们仍然需要句子级别的注释，因为它们目的是提升下游任务。</p><p>为了解决这个限制，作者提出了DIORA。DIORA将Inside-Outside算法（<a href="https://www.wikiwand.com/en/Inside%E2%80%93outside_algorithm）合并到一个latent" target="_blank" rel="noopener">https://www.wikiwand.com/en/Inside%E2%80%93outside_algorithm）合并到一个latent</a> tree chart parser中。自下而上的inside算法，计算输入句子中二叉树所有可能成分的表示形式。这个步骤等效于之前研究的forward pass。这些inside表示只编码了当前的子树，忽略了所有的外界上下文；而outside算法，对每个节点自上而下地计算，为节点的子树表示提供一个外部的上下文。然后对模型进行训练，目标为leaf结点的outside表示能够重建leaf的输入单词，类似于mask的语言模型的预训练，但是我们动态编程预测每一个单词用的是一个没有mask的上下文。</p><p>怎么得到一棵最可能的树？通过CKY算法和各个constituents之间的compatibility。之前的工作不是没有很好地对齐已知的treebanks，就是没有显式建模短语的机制，需要复杂的过程提取结构。</p><h2 id="DIORA"><a href="#DIORA" class="headerlink" title="DIORA"></a>DIORA</h2><p>目标是设计一个可以从原始文本中学习结构的模型，和一个训练它的方法。模型遵循一个假设：<strong>句子的最有效压缩将来自于遵循基础输入的正确句法结构（the most effectie compression of a sentence will be derived from following the true syntactic structure of the underlying input）</strong>。模型建立在之前parser的基础上，用inside-outside算法进行了扩充，并且被训练为能通过outside上下文重现每一个输入词。根据我们的假设，在某种程度上收到“替代原理”（substitution principle）的启发，模型将通过发现、利用文本的句法规律性来最好地重构输入。</p><p>方法中，inside pass递归地压缩输入序列。在每一步中，将两个孩子的向量表示输入到合成函数（composition function）中，该函数输出父亲的inside向量表示。这个过程一直持续到树的根节点，最终生成代表整个句子的单个向量（图2a）.这类似于AE的压缩步骤，等效于现在的latent tree parser的前向传递。先从叶子节点开始，从下往上，每一个节点的inside向量和score都由它的两个儿子计算出来。</p><p>接下来，启动outside pass。使用一个通用的（根节点）的表示，它被当作一个单独的参数学习。我们展开它直到产生叶子结点的表示。之后，对叶子节点进行优化，以构建输入句子，就像AE所做的一样。计算每一个节点的outside向量时，输入则是其兄弟节点的inside向量和父结点的outside向量。可以看公式。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="用inside-outside算法填写chart"><a href="#用inside-outside算法填写chart" class="headerlink" title="用inside-outside算法填写chart"></a>用inside-outside算法填写chart</h3><p>由上文得知，inside得出来的表示不考虑外部上下文。当inside表示被计算后，我们通过一个top-down的outside pass来计算outside表示。填完表格后，每一个成分k（表格里的每一个cell），都有对应的</p><ul><li>一个inside向量$\bar{a}(k)$和</li><li>一个outside向量$\bar{b}(k)$，以及</li><li>inside相容性分数（compatibility score）$\bar{e}(k)$和</li><li>outside相容性分数$\bar{f}(k)$</li></ul><p>约定输入一个长度为T的句子x，每一个x都可以被预训练的embedding vector $v$表示。</p><h4 id="Inside-Pass"><a href="#Inside-Pass" class="headerlink" title="Inside Pass"></a>Inside Pass</h4><p>首先为了避免困扰，特此说明：在NLP的成分语法中，树的节点和叶子都是一个成分。</p><p>我们接下来约定i，j，k这些都指代的成分所包括的一个范围。</p><p>对于每一对相邻成分i和j，计算一个compatibility分数，和一个composition向量。</p><p>这样的分数和向量表示了特定范围k（k可以大于2）以内，k内所有可能的成分对（pair）进行软加权（soft weight）计算得出一个向量，那就是上层节点的inside向量。将这些成分对记为${k}$。</p><p>当span为1时，vector被初始化为embedding vector $v$的非线性变换；而score被初始化为0.</p><script type="math/tex; mode=display">\begin{array}{l}{\left[\begin{array}{l}{x} \\ {o} \\ {u}\end{array}\right]=\left[\begin{array}{c}{\sigma} \\ {\sigma} \\ {\tanh }\end{array}\right]\left(U_{\psi} v_{k}+b\right)} \\ {\bar{a}(k)=o+\tanh (x \odot u)} \\ {\bar{e}(k)=0}\end{array}</script><p>作者说明：This function shares its bias term b with $Compose_α$, although $U_ψ$ is not tied to any other weights.</p><p>而表格的高层通过这样的加法进行计算：</p><script type="math/tex; mode=display">\begin{aligned} \bar{a}(k) &=\sum_{i, j \in\{k\}} e(i, j) a(i, j) \\ \bar{e}(k) &=\sum_{i, j \in\{k\}} e(i, j) \hat{e}(i, j) \end{aligned}</script><p>这也很好理解，这就是软加权的过程。</p><p>相容函数$\hat{e}$（区分相容分数$\hat{e}$）旨在产生一个分数计算两个相邻的cell有多大可能被合并。我们使用被学习到参数的矩阵S，实现一个双线性函数（矩阵模拟函数功能）。我们额外加上了原有cell的分数。直觉上来说，这些独立的分数关系到这些cell有多大可能存在于最后的二叉树中。</p><p>相容函数$\hat{e}$这么计算：</p><script type="math/tex; mode=display">\begin{aligned}&e(i, j)=\frac{\exp (\hat{e}(i, j))}{\sum_{\hat{i}, \hat{j} \in\{k\}} \exp (\hat{e}(\hat{i}, \hat{j}))}\\&\hat{e}(i, j)=\phi\left(\bar{a}(i), \bar{a}(j) ; S_{\alpha}\right)+\bar{e}(i)+\bar{e}(j)\end{aligned}</script><p>其中的双线性投影$\phi$被这么定义：</p><script type="math/tex; mode=display">\phi(u, v ; W)=u^{\top} W v</script><p>其实有点类似于attention计算。</p><p>上面的路线最终得到了$e(i,j)$。</p><p>之后通过composition function得到$a(i,j)$。</p><p>这个函数的选择有好几种。可以选择TreeLSTM或者是2层MLP。将函数定义为Compose，产生一个hidden state h，对于TreeLSTM，得到的是cell state。</p><script type="math/tex; mode=display">a(i, j)=\text { Compose }_{\alpha}(\bar{a}(i), \bar{a}(j))</script><p>概述一下，inside向量 = 所有可能的节点对i,j的composition score的加权和</p><h5 id="TreeLSTM"><a href="#TreeLSTM" class="headerlink" title="TreeLSTM"></a>TreeLSTM</h5><p>TreeLSTM做了一个这样的变换，得到h和c：</p><script type="math/tex; mode=display">\left[\begin{array}{l}{x} \\{f_{i}} \\{f_{j}} \\{o} \\{u}\end{array}\right]=\left[\begin{array}{c}{\sigma} \\{\sigma} \\{\sigma} \\{\sigma} \\{\tanh }\end{array}\right]\left(U\left[\begin{array}{l}{h_{i}} \\{h_{j}}\end{array}\right]+b+\left[\begin{array}{c}{0} \\{\omega} \\{\omega} \\{0} \\{0}\end{array}\right]\right)</script><script type="math/tex; mode=display">\begin{array}{l}{c=c_{i} \odot f_{i}+c_{j} \odot f_{j}+x \odot u} \\{h=o+\tanh (c)}\end{array}</script><p>参数w在inside里设为1，outside里设为0.</p><h5 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h5><script type="math/tex; mode=display">h=W_{1}\left(W_{0}\left\langle h_{i}, h_{j}\right\rangle+ b\right)+b_{1}</script><p>其中$\left\langle h_{i}, h_{j}\right\rangle$是concat操作。</p><p>现在我们回顾一下整个inside过程：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>实际上这么多计算就是为了得到e和a……</p><p>当然$\hat{a}$还是有意义的，这是为了填chart。</p><h4 id="Outside-Pass"><a href="#Outside-Pass" class="headerlink" title="Outside Pass"></a>Outside Pass</h4><p>Outside算法类似inside算法。outside chart的根节点被作为偏差学习。后代cell被预测，使用的是可能的outside上下文的消歧（disambiguation）。每一个上下文都包括一个inside表中的同级cell，和一个outside表中的父级cell。因为计算顺序的问题，我们从上往下计算的时候，知道了父亲的outside变量，而不知道兄弟的outside变量，所以要用inside向量。</p><p>函数f与之前的函数e类似，在span k上对成分对(i,j)做归一化，消除了outside上下文的歧义。函数b为缺失的同级细胞生成短语级表示。公式如下：</p><script type="math/tex; mode=display">\begin{aligned}\bar{b}(k) &=\sum_{i, j \in\{k\}} f(i, j) b(i, j) \\\bar{f}(k) &=\sum_{i, j \in\{k\}} f(i, j) \hat{f}(i, j) \\b(i, j) &=\operatorname{Compose}_{\beta}(\bar{a}(i), \bar{b}(j)) \\\hat{f}(i, j) &=\phi\left(\bar{a}(i), \bar{b}(j) ; S_{\beta}\right)+\bar{e}(i)+\bar{f}(j)\end{aligned}</script><p>在大多数实验中，b中使用的Compose与a共享参数，$\hat{e}$和$\hat{f}$依然是如此。？</p><h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><p>最后我们推出来每一个叶子结点的outside表示，这个表示是完全由context推出来的。因为根节点的vector是随机初始化的，所以不会存在信息泄露问题，使得outside向量混入了inside向量的信息。</p><p>使用类似AE的语言建模目标。<strong>也就是，我们希望叶子的outside向量能最大程度上还原叶子的inside向量</strong>。</p><p>我们模型并不限制单个z上x的重构，因为root的outside表示是用bias而不是root自己的inside向量表示的。因此，我们以许多子树根为condition的x，每个子树根仅仅是输入的子集的压缩。</p><p>为了近似这种重构，使用max-margin loss。考虑一组${x^*}$的N个negative samples，从词频出现频率中采样。？</p><p>terminal outside向量$\bar{b}(i)$被训练以预测原始输入$v_i$。</p><p>损失函数为：</p><script type="math/tex; mode=display">\begin{aligned}L_{\boldsymbol{x}}=\sum_{i=0}^{T-1} \sum_{i^{*}=0}^{N-1} \max (0,1-\bar{b}(i) \cdot \bar{a}(i)\\\left.+\bar{b}(i) \cdot \bar{a}\left(i^{*}\right)\right)\end{aligned}</script><p>这是一个max-margin loss。采样负样本有一个好处，会让训练更加稳健。这个loss的含义实际上就是：让outside向量与inside向量相似。</p><p>普通的交叉熵损失函数是：</p><script type="math/tex; mode=display">\begin{aligned}&Z^{*}=\sum_{i^{*}=0}^{N-1} \exp \left(\bar{b}(i) \cdot \bar{a}\left(i^{*}\right)\right)\\&L_{\boldsymbol{x}}=-\sum_{i=0}^{T-1} \log \frac{\exp (\bar{b}(i) \cdot \bar{a}(i))}{\exp (\bar{b}(i) \cdot \bar{a}(i))+Z^{\star}}\end{aligned}</script><h3 id="DIORA-CKY-Parsing"><a href="#DIORA-CKY-Parsing" class="headerlink" title="DIORA CKY Parsing"></a>DIORA CKY Parsing</h3><p>为了获取DIORA的解析，我们要使用input sentence填充inside和outside chart。我们使用CKY过程，根据单一语法规则日趋最大得分分析。CKY算法的步骤如图。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>因为我的博客关注的是音乐方面的问题，NLP本身的实验细节我会略过。</p><h3 id="无监督解析"><a href="#无监督解析" class="headerlink" title="无监督解析"></a>无监督解析</h3><p>数据集为WSJ和MultiNLI。对比模型为PRPN，ON-LSTM，确定性构造的做分支、右分支、平衡树、随机数、RL-SPINN，ST-Gumbel。后两者训练用于NLI任务。</p><h3 id="无监督短语分割"><a href="#无监督短语分割" class="headerlink" title="无监督短语分割"></a>无监督短语分割</h3><h3 id="短语相似性"><a href="#短语相似性" class="headerlink" title="短语相似性"></a>短语相似性</h3><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Latent-Tree-Learning"><a href="#Latent-Tree-Learning" class="headerlink" title="Latent Tree Learning"></a>Latent Tree Learning</h3><ul><li>survey: Do latent tree learning models identify meaningful structure in sentences?</li><li>第一个parsing的积极结果：Grammar induction with neural language models: An unusual replication（URNNG）</li><li>IO算法计算边界概率：Structured alignment networks for matching sentences</li></ul><h3 id="Neural-Inside-Outside-Parsers"><a href="#Neural-Inside-Outside-Parsers" class="headerlink" title="Neural Inside-Outside Parsers"></a>Neural Inside-Outside Parsers</h3><ul><li>最接近：graph-based dependency parser + beam search: The insideoutside recursive neural network model for dependency parsing</li><li>Neural CRF Parser，需要标记和语法规则：Neural crf parsing.<br>In Association for Computational Linguistics</li><li>Structured alignment networks for matching sentences</li></ul><h3 id="Learning-from-Raw-Text"><a href="#Learning-from-Raw-Text" class="headerlink" title="Learning from Raw Text"></a>Learning from Raw Text</h3><p>语法结构的无监督学习，包括无监督分割、无监督依赖分析等。</p><p>相关文献包括：</p><ul><li>Semi-supervised recursive autoencoders for predicting sentiment distributions</li><li>The forest convolutional network: Compositional distributional semantics with a neural chart and without binarization</li><li>Learning to compose task-specific tree structures, AAAI 2018</li><li>Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章聊聊无监督句法分析的文章：DIORA。文章最后会顺带着聊一下别的PCFG系统。&lt;/p&gt;
    
    </summary>
    
      <category term="论文笔记" scheme="http://ldzhangyx.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="structure" scheme="http://ldzhangyx.github.io/tags/structure/"/>
    
      <category term="NLP" scheme="http://ldzhangyx.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>利用networkx进行二叉树可视化</title>
    <link href="http://ldzhangyx.github.io/2020/01/13/binary-tree/"/>
    <id>http://ldzhangyx.github.io/2020/01/13/binary-tree/</id>
    <published>2020-01-13T07:36:18.000Z</published>
    <updated>2020-01-13T07:36:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>画一棵二叉树。附可执行的Python代码。</p><a id="more"></a><h1 id="如何绘画一棵二叉树？"><a href="#如何绘画一棵二叉树？" class="headerlink" title="如何绘画一棵二叉树？"></a>如何绘画一棵二叉树？</h1><p>NLP领域句法树的绘画，和音乐结构二叉树的绘画，都希望能有一个unlabel的二叉树绘画库，表现出下图中类似的效果：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="6.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>我目前没有找到一个通行的包来支持这样的二叉树生成，所以我自己写了一个类似的低配版：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="7.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>这个函数的输入是一个嵌套列表。我设计函数以中序树的方式读取列表。这个类依托于networkx库进行生成。</p><p>首先简单说一下原理。我开源的两个demo project:</p><ul><li><a href="https://github.com/ldzhangyx/diora-for-music-structure" target="_blank" rel="noopener">https://github.com/ldzhangyx/diora-for-music-structure</a></li><li><a href="https://github.com/ldzhangyx/Unsupervised-Music-Structure-Extraction-via-Ordered-Neurons" target="_blank" rel="noopener">https://github.com/ldzhangyx/Unsupervised-Music-Structure-Extraction-via-Ordered-Neurons</a></li></ul><p>最后parse得到的二叉树都是这么表示的：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="8.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>其中，rest用” “表示，而sustain用”-“表示。pitch已经使用pretty_midi转为了音名。</p><p>首先中序遍历整个列表。如果当前元素是列表则访问左孩子，如果当前元素是音符，则纪录叶子。使用递归的方式实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">list_to_tree</span><span class="params">(self, input, layer)</span>:</span>  <span class="comment"># 递归地添加所有节点，做成中序树</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(input, list) <span class="keyword">and</span> layer &lt; self.depth_limit:  <span class="comment"># 当前节点不是叶节点 ，或深度没有到达限制</span></span><br><span class="line">        left_node = self.list_to_tree(input[<span class="number">0</span>], layer + <span class="number">1</span>)  <span class="comment"># 左子树，返回子树的root</span></span><br><span class="line">        current_node = self.add_node(layer, tag=<span class="keyword">None</span>)  <span class="comment"># 当前节点</span></span><br><span class="line">        right_node = self.list_to_tree(input[<span class="number">1</span>], layer + <span class="number">1</span>)  <span class="comment"># 右子树，返回子树的root</span></span><br><span class="line">        self.graph.add_edge(left_node, current_node)</span><br><span class="line">        self.graph.add_edge(right_node, current_node)</span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> isinstance(input, list):  <span class="comment"># 当前节点是叶节点</span></span><br><span class="line">        current_node = self.add_node(layer, tag=input)</span><br><span class="line">    <span class="keyword">elif</span> layer &gt;= self.depth_limit:</span><br><span class="line">        child_list = self.flat_list(input)</span><br><span class="line">        left_list = child_list[:int(len(child_list) / <span class="number">2</span>)]</span><br><span class="line">        right_list = child_list[int(len(child_list) / <span class="number">2</span>):]</span><br><span class="line">        child_node_list = list()</span><br><span class="line">        <span class="keyword">for</span> leaf <span class="keyword">in</span> left_list:  <span class="comment"># 左子树</span></span><br><span class="line">            child_node = self.list_to_tree(leaf, layer + <span class="number">1</span>)</span><br><span class="line">            child_node_list.append(child_node)</span><br><span class="line">        current_node = self.add_node(layer, tag=<span class="keyword">None</span>)  <span class="comment"># 多叉树，但还是要保持中序（为了美观）</span></span><br><span class="line">        <span class="keyword">for</span> leaf <span class="keyword">in</span> right_list:  <span class="comment"># 右子树</span></span><br><span class="line">            child_node = self.list_to_tree(leaf, layer + <span class="number">1</span>)</span><br><span class="line">            child_node_list.append(child_node)</span><br><span class="line">        <span class="keyword">for</span> child_node <span class="keyword">in</span> child_node_list:</span><br><span class="line">            self.graph.add_edge(child_node, current_node)</span><br><span class="line">    <span class="keyword">return</span> current_node</span><br></pre></td></tr></table></figure><p>上面有一个参数是self.depth_limit，用来指定最大深度。如果超过最大深度影响可视化效果，则将当前列表的子列表摊平，转换为多叉树。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flat_list</span><span class="params">(self, the_list)</span>:</span></span><br><span class="line">    now = the_list[:]</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">while</span> now:</span><br><span class="line">        head = now.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> isinstance(head, list):</span><br><span class="line">            now = head + now</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res.append(head)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>添加节点的函数如下。networkx的nodes列表可以遍历所有的node。我们用是否有tag属性区分叶子节点和中间节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_node</span><span class="params">(self, layer, tag)</span>:</span></span><br><span class="line">    self.graph.add_node(self.counter)</span><br><span class="line">    <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:  <span class="comment"># 叶子</span></span><br><span class="line">        self.graph.nodes[self.counter][<span class="string">'tag'</span>] = tag</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 中间节点</span></span><br><span class="line">        self.graph.nodes[self.counter][<span class="string">'tag'</span>] = <span class="string">""</span></span><br><span class="line">    self.graph.nodes[self.counter][<span class="string">'layer'</span>] = layer</span><br><span class="line">    self.graph.nodes[self.counter][<span class="string">'sequence_index'</span>] = self.sequence_index</span><br><span class="line">    self.counter += <span class="number">1</span>  <span class="comment"># 更新counter标记</span></span><br><span class="line">    self.sequence_index += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> self.counter - <span class="number">1</span>  <span class="comment"># 返回这次添加的counter_id</span></span><br></pre></td></tr></table></figure><p>如果这棵二叉树不想保留sustain（或者rest），那么提前执行下面函数，改写list：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_list</span><span class="params">(self, input_list)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> isinstance(input_list[<span class="number">0</span>], list): <span class="comment"># 递归地解决左子树</span></span><br><span class="line">        input_list[<span class="number">0</span>] = self.reshape_list(input_list[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> isinstance(input_list[<span class="number">1</span>], list): <span class="comment"># 递归地解决右子树</span></span><br><span class="line">        input_list[<span class="number">1</span>] = self.reshape_list(input_list[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 边界有几种情况：都不删，都删，和只删一边</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">0</span>], list) <span class="keyword">and</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">1</span>], list): <span class="comment"># 两个子树都为叶子节点，边界条件</span></span><br><span class="line">        <span class="keyword">if</span> input_list[<span class="number">0</span>] == <span class="string">"-"</span> <span class="keyword">and</span> input_list[<span class="number">1</span>] == <span class="string">"-"</span>:  <span class="comment"># 都删需要满足两边都是叶子</span></span><br><span class="line">            <span class="keyword">return</span> _sustain</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">0</span>], list):</span><br><span class="line">        <span class="keyword">if</span> input_list[<span class="number">0</span>] == <span class="string">"-"</span>: <span class="comment"># 删左边需要保证左边是叶子</span></span><br><span class="line">            <span class="keyword">return</span> input_list[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">1</span>], list):</span><br><span class="line">        <span class="keyword">if</span> input_list[<span class="number">1</span>] == <span class="string">"-"</span>: <span class="comment"># 删右边需要保证右边是叶子</span></span><br><span class="line">            <span class="keyword">return</span> input_list[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> input_list</span><br></pre></td></tr></table></figure><p>最后执行绘画函数。先计算总长度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">max_layer = max([self.graph.nodes[k][<span class="string">'layer'</span>] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)])</span><br><span class="line">sequence_len = max([self.graph.nodes[k][<span class="string">'sequence_index'</span>] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)]) + <span class="number">1</span></span><br><span class="line">leaf_len = len([self.graph.nodes[k] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes) <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] != <span class="string">''</span>])</span><br></pre></td></tr></table></figure><p>为了看上去比较舒服，我将每四个音符聚在了一起，使用了blank_counter变量修正位置。如果不需要做这样的聚合，可以直接去掉这个变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.reschedule_index:  <span class="comment"># 将子树尝试均匀排列</span></span><br><span class="line">    position_counter = <span class="number">0</span></span><br><span class="line">    beat_flag = <span class="number">4</span></span><br><span class="line">    blank_counter = <span class="number">0</span></span><br><span class="line">    bar_flag = leaf_len / <span class="number">4</span></span><br><span class="line">    <span class="keyword">for</span> leaf_index <span class="keyword">in</span> range(sequence_len):  <span class="comment"># 先修正最底层</span></span><br><span class="line">        <span class="keyword">if</span> self.graph.nodes[leaf_index][<span class="string">'tag'</span>] != <span class="string">''</span>:</span><br><span class="line">            self.graph.nodes[leaf_index][<span class="string">'sequence_index'</span>] = position_counter</span><br><span class="line">            position_counter += <span class="number">1</span></span><br><span class="line">            position_counter += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> (position_counter - blank_counter) % beat_flag == <span class="number">0</span>:</span><br><span class="line">                position_counter += <span class="number">1</span></span><br><span class="line">                blank_counter += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> (position_counter - blank_counter) % bar_flag == <span class="number">0</span>:</span><br><span class="line">                position_counter += <span class="number">1</span></span><br><span class="line">                blank_counter += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>为了可视化，我们先固定最底层的所有叶子节点。一个明确的原则是，顶层节点的位置应由其子树的位置决定。任何子树的根节点都应该在它左孩子和右孩子连线的垂直平分线上。于是逐层向上修正节点位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 反过来修正上面所有层数</span></span><br><span class="line"><span class="keyword">for</span> layer_index <span class="keyword">in</span> range(max_layer):  <span class="comment"># 0 to max_layer - 1</span></span><br><span class="line">    current_layer = max_layer - layer_index  <span class="comment"># reverse</span></span><br><span class="line">    <span class="comment"># 寻找直接子节点</span></span><br><span class="line">    <span class="keyword">for</span> node_index <span class="keyword">in</span> range(sequence_len):</span><br><span class="line">        <span class="keyword">if</span> self.graph.nodes[node_index][<span class="string">'layer'</span>] == current_layer <span class="keyword">and</span> self.graph.nodes[node_index][</span><br><span class="line">            <span class="string">'tag'</span>] == <span class="string">''</span>:  <span class="comment"># 中间节点</span></span><br><span class="line">            position_list = list()</span><br><span class="line">            adj_node_list = list(self.graph.adj[node_index].keys())</span><br><span class="line">            positions = [self.graph.nodes[node][<span class="string">'sequence_index'</span>] <span class="keyword">for</span> node <span class="keyword">in</span> adj_node_list</span><br><span class="line">                            <span class="keyword">if</span> self.graph.nodes[node][<span class="string">'layer'</span>] == current_layer + <span class="number">1</span>]</span><br><span class="line">            self.graph.nodes[node_index][<span class="string">'sequence_index'</span>] = sum(positions) / len(positions)</span><br></pre></td></tr></table></figure><p>最后绘画：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    fig = plt.figure(figsize=(int(sequence_len / <span class="number">4</span>), int(max_layer)))</span><br><span class="line">    pic = nx.draw_networkx(self.graph,</span><br><span class="line">                            pos=&#123;</span><br><span class="line">                                k: (self.graph.nodes[k][<span class="string">'sequence_index'</span>],</span><br><span class="line">                                    (max_layer + <span class="number">1</span>) - self.graph.nodes[k][<span class="string">'layer'</span>])</span><br><span class="line">                                <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] == <span class="string">""</span></span><br><span class="line">                                <span class="keyword">else</span> (self.graph.nodes[k][<span class="string">'sequence_index'</span>], <span class="number">0</span>)</span><br><span class="line">                                <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)</span><br><span class="line">                            &#125;,</span><br><span class="line">                            labels=&#123;</span><br><span class="line">                                k: self.graph.nodes[k][<span class="string">'tag'</span>]</span><br><span class="line">                                <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)</span><br><span class="line">                                <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] != <span class="string">""</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            font_size=<span class="number">9</span>,</span><br><span class="line">                            node_size=<span class="number">250</span>,</span><br><span class="line">                            node_color=<span class="string">'gold'</span>,</span><br><span class="line">                            edge_color=<span class="string">'silver'</span>,</span><br><span class="line">                            width=<span class="number">3</span>,</span><br><span class="line">                            )</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(output_dir)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(e.args)</span><br></pre></td></tr></table></figure><p>这一段可能报错的原因很多。如果需要连续反复调用这个函数，那么一个报错很可能打断程序运行。我在这里设置了exception，为了一张图的出错不影响整体程序推进。</p><p>完整程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> pretty_midi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreePainter</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_list, output_file, paint = True)</span>:</span></span><br><span class="line">        self.origin_list = input_list</span><br><span class="line">        self.counter = <span class="number">0</span>  <span class="comment"># 为节点命名，将和弦符号定义为其属性</span></span><br><span class="line">        self.sequence_index = <span class="number">0</span></span><br><span class="line">        self.vertical = <span class="keyword">False</span></span><br><span class="line">        self.color = <span class="string">'positive'</span>  <span class="comment"># color tags &gt; 0</span></span><br><span class="line">        self.depth_limit = <span class="number">10</span></span><br><span class="line">        self.reschedule_index = <span class="keyword">True</span></span><br><span class="line">        self.graph = nx.Graph()</span><br><span class="line">        self.note_name = <span class="keyword">False</span></span><br><span class="line">        self.ignore_sustain = <span class="keyword">False</span></span><br><span class="line">        self.ignore_rest = <span class="keyword">False</span></span><br><span class="line">        self.midi = <span class="keyword">False</span></span><br><span class="line">        self.paint = paint</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Action</span></span><br><span class="line">        <span class="keyword">if</span> self.ignore_sustain:</span><br><span class="line">            self.origin_list = self.reshape_list(self.origin_list)</span><br><span class="line">        <span class="keyword">if</span> self.paint:</span><br><span class="line">            self.list_to_tree(self.origin_list, layer=<span class="number">0</span>)</span><br><span class="line">            self.paint_tree(output_file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape_list</span><span class="params">(self, input_list)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> isinstance(input_list[<span class="number">0</span>], list): <span class="comment"># 递归地解决左子树</span></span><br><span class="line">            input_list[<span class="number">0</span>] = self.reshape_list(input_list[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> isinstance(input_list[<span class="number">1</span>], list): <span class="comment"># 递归地解决右子树</span></span><br><span class="line">            input_list[<span class="number">1</span>] = self.reshape_list(input_list[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># 边界有几种情况：都不删，都删，和只删一边</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">0</span>], list) <span class="keyword">and</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">1</span>], list): <span class="comment"># 两个子树都为叶子节点，边界条件</span></span><br><span class="line">            <span class="keyword">if</span> input_list[<span class="number">0</span>] == <span class="string">"-"</span> <span class="keyword">and</span> input_list[<span class="number">1</span>] == <span class="string">"-"</span>:  <span class="comment"># 都删需要满足两边都是叶子</span></span><br><span class="line">                <span class="keyword">return</span> _sustain</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">0</span>], list):</span><br><span class="line">            <span class="keyword">if</span> input_list[<span class="number">0</span>] == <span class="string">"-"</span>: <span class="comment"># 删左边需要保证左边是叶子</span></span><br><span class="line">                <span class="keyword">return</span> input_list[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(input_list[<span class="number">1</span>], list):</span><br><span class="line">            <span class="keyword">if</span> input_list[<span class="number">1</span>] == <span class="string">"-"</span>: <span class="comment"># 删右边需要保证右边是叶子</span></span><br><span class="line">                <span class="keyword">return</span> input_list[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> input_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flat_list</span><span class="params">(self, the_list)</span>:</span></span><br><span class="line">        now = the_list[:]</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> now:</span><br><span class="line">            head = now.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> isinstance(head, list):</span><br><span class="line">                now = head + now</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(head)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">list_to_tree</span><span class="params">(self, input, layer)</span>:</span>  <span class="comment"># 递归地添加所有节点，做成中序树</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(input, list) <span class="keyword">and</span> layer &lt; self.depth_limit:  <span class="comment"># 当前节点不是叶节点 ，或深度没有到达限制</span></span><br><span class="line">            left_node = self.list_to_tree(input[<span class="number">0</span>], layer + <span class="number">1</span>)  <span class="comment"># 左子树，返回子树的root</span></span><br><span class="line">            current_node = self.add_node(layer, tag=<span class="keyword">None</span>)  <span class="comment"># 当前节点</span></span><br><span class="line">            right_node = self.list_to_tree(input[<span class="number">1</span>], layer + <span class="number">1</span>)  <span class="comment"># 右子树，返回子树的root</span></span><br><span class="line">            self.graph.add_edge(left_node, current_node)</span><br><span class="line">            self.graph.add_edge(right_node, current_node)</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> isinstance(input, list):  <span class="comment"># 当前节点是叶节点</span></span><br><span class="line">            current_node = self.add_node(layer, tag=input)</span><br><span class="line">        <span class="keyword">elif</span> layer &gt;= self.depth_limit:</span><br><span class="line">            child_list = self.flat_list(input)</span><br><span class="line">            left_list = child_list[:int(len(child_list) / <span class="number">2</span>)]</span><br><span class="line">            right_list = child_list[int(len(child_list) / <span class="number">2</span>):]</span><br><span class="line">            child_node_list = list()</span><br><span class="line">            <span class="keyword">for</span> leaf <span class="keyword">in</span> left_list:  <span class="comment"># 左子树</span></span><br><span class="line">                child_node = self.list_to_tree(leaf, layer + <span class="number">1</span>)</span><br><span class="line">                child_node_list.append(child_node)</span><br><span class="line">            current_node = self.add_node(layer, tag=<span class="keyword">None</span>)  <span class="comment"># 多叉树，但还是要保持中序（为了美观）</span></span><br><span class="line">            <span class="keyword">for</span> leaf <span class="keyword">in</span> right_list:  <span class="comment"># 右子树</span></span><br><span class="line">                child_node = self.list_to_tree(leaf, layer + <span class="number">1</span>)</span><br><span class="line">                child_node_list.append(child_node)</span><br><span class="line">            <span class="keyword">for</span> child_node <span class="keyword">in</span> child_node_list:</span><br><span class="line">                self.graph.add_edge(child_node, current_node)</span><br><span class="line">        <span class="keyword">return</span> current_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_node</span><span class="params">(self, layer, tag)</span>:</span></span><br><span class="line">        self.graph.add_node(self.counter)</span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:  <span class="comment"># 叶子</span></span><br><span class="line">            self.graph.nodes[self.counter][<span class="string">'tag'</span>] = tag</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 中间节点</span></span><br><span class="line">            self.graph.nodes[self.counter][<span class="string">'tag'</span>] = <span class="string">""</span></span><br><span class="line">        self.graph.nodes[self.counter][<span class="string">'layer'</span>] = layer</span><br><span class="line">        self.graph.nodes[self.counter][<span class="string">'sequence_index'</span>] = self.sequence_index</span><br><span class="line">        self.counter += <span class="number">1</span>  <span class="comment"># 更新counter标记</span></span><br><span class="line">        self.sequence_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.counter - <span class="number">1</span>  <span class="comment"># 返回这次添加的counter_id</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">paint_tree</span><span class="params">(self, output_dir)</span>:</span></span><br><span class="line">        max_layer = max([self.graph.nodes[k][<span class="string">'layer'</span>] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)])</span><br><span class="line">        sequence_len = max([self.graph.nodes[k][<span class="string">'sequence_index'</span>] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)]) + <span class="number">1</span></span><br><span class="line">        leaf_len = len([self.graph.nodes[k] <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes) <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] != <span class="string">''</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.reschedule_index:  <span class="comment"># 将子树尝试均匀排列</span></span><br><span class="line">            position_counter = <span class="number">0</span></span><br><span class="line">            beat_flag = <span class="number">4</span></span><br><span class="line">            blank_counter = <span class="number">0</span></span><br><span class="line">            bar_flag = leaf_len / <span class="number">4</span></span><br><span class="line">            <span class="keyword">for</span> leaf_index <span class="keyword">in</span> range(sequence_len):  <span class="comment"># 先修正最底层</span></span><br><span class="line">                <span class="keyword">if</span> self.graph.nodes[leaf_index][<span class="string">'tag'</span>] != <span class="string">''</span>:</span><br><span class="line">                    self.graph.nodes[leaf_index][<span class="string">'sequence_index'</span>] = position_counter</span><br><span class="line">                    position_counter += <span class="number">1</span></span><br><span class="line">                    position_counter += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> (position_counter - blank_counter) % beat_flag == <span class="number">0</span>:</span><br><span class="line">                        position_counter += <span class="number">1</span></span><br><span class="line">                        blank_counter += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> (position_counter - blank_counter) % bar_flag == <span class="number">0</span>:</span><br><span class="line">                        position_counter += <span class="number">1</span></span><br><span class="line">                        blank_counter += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 反过来修正上面所有层数</span></span><br><span class="line">            <span class="keyword">for</span> layer_index <span class="keyword">in</span> range(max_layer):  <span class="comment"># 0 to max_layer - 1</span></span><br><span class="line">                current_layer = max_layer - layer_index  <span class="comment"># reverse</span></span><br><span class="line">                <span class="comment"># 寻找直接子节点</span></span><br><span class="line">                <span class="keyword">for</span> node_index <span class="keyword">in</span> range(sequence_len):</span><br><span class="line">                    <span class="keyword">if</span> self.graph.nodes[node_index][<span class="string">'layer'</span>] == current_layer <span class="keyword">and</span> self.graph.nodes[node_index][</span><br><span class="line">                        <span class="string">'tag'</span>] == <span class="string">''</span>:  <span class="comment"># 中间节点</span></span><br><span class="line">                        position_list = list()</span><br><span class="line">                        adj_node_list = list(self.graph.adj[node_index].keys())</span><br><span class="line">                        positions = [self.graph.nodes[node][<span class="string">'sequence_index'</span>] <span class="keyword">for</span> node <span class="keyword">in</span> adj_node_list</span><br><span class="line">                                     <span class="keyword">if</span> self.graph.nodes[node][<span class="string">'layer'</span>] == current_layer + <span class="number">1</span>]</span><br><span class="line">                        self.graph.nodes[node_index][<span class="string">'sequence_index'</span>] = sum(positions) / len(positions)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            fig = plt.figure(figsize=(int(sequence_len / <span class="number">4</span>), int(max_layer)))</span><br><span class="line">            pic = nx.draw_networkx(self.graph,</span><br><span class="line">                                   pos=&#123;</span><br><span class="line">                                       k: (self.graph.nodes[k][<span class="string">'sequence_index'</span>],</span><br><span class="line">                                           (max_layer + <span class="number">1</span>) - self.graph.nodes[k][<span class="string">'layer'</span>])</span><br><span class="line">                                       <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] == <span class="string">""</span></span><br><span class="line">                                       <span class="keyword">else</span> (self.graph.nodes[k][<span class="string">'sequence_index'</span>], <span class="number">0</span>)</span><br><span class="line">                                       <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)</span><br><span class="line">                                   &#125;,</span><br><span class="line">                                   labels=&#123;</span><br><span class="line">                                       k: self.graph.nodes[k][<span class="string">'tag'</span>]</span><br><span class="line">                                       <span class="keyword">for</span> k <span class="keyword">in</span> list(self.graph.nodes)</span><br><span class="line">                                       <span class="keyword">if</span> self.graph.nodes[k][<span class="string">'tag'</span>] != <span class="string">""</span></span><br><span class="line">                                   &#125;,</span><br><span class="line">                                   font_size=<span class="number">9</span>,</span><br><span class="line">                                   node_size=<span class="number">250</span>,</span><br><span class="line">                                   node_color=<span class="string">'gold'</span>,</span><br><span class="line">                                   edge_color=<span class="string">'silver'</span>,</span><br><span class="line">                                   width=<span class="number">3</span>,</span><br><span class="line">                                   )</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line">            <span class="comment"># if self.vertical:</span></span><br><span class="line">            <span class="comment">#     for _, item in pic.item():</span></span><br><span class="line">            <span class="comment">#         item.set_rotation('vertical')</span></span><br><span class="line"></span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.savefig(output_dir)</span><br><span class="line">            plt.close(fig)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e.args)</span><br></pre></td></tr></table></figure><p>测试程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">parse_tree = [[[[[[[<span class="string">"G4"</span>, <span class="string">"-"</span>], [[[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"F4"</span>, <span class="string">"-"</span>]], <span class="string">"G4"</span>]], <span class="string">"-"</span>], [[<span class="string">"A#4"</span>, <span class="string">"-"</span>], [<span class="string">"-"</span>, <span class="string">"-"</span>]]], [[[<span class="string">"C5"</span>, <span class="string">"-"</span>], [<span class="string">"F4"</span>, <span class="string">"-"</span>]], [[[[<span class="string">"G4"</span>, <span class="string">"-"</span>], [<span class="string">"-"</span>, <span class="string">"-"</span>]], [<span class="string">" "</span>, <span class="string">" "</span>]], [[[[<span class="string">" "</span>, <span class="string">" "</span>], [<span class="string">"D4"</span>, <span class="string">"-"</span>]], [[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"-"</span>, <span class="string">"-"</span>]]], [[<span class="string">"A#4"</span>, <span class="string">"-"</span>], [<span class="string">"G4"</span>, <span class="string">"-"</span>]]]]]], [[[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"F4"</span>, <span class="string">"-"</span>]], [[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"D4"</span>, <span class="string">"-"</span>]]]], [[[[[<span class="string">"C4"</span>, <span class="string">"-"</span>], [<span class="string">"A#3"</span>, <span class="string">"-"</span>]], [[[[[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"C4"</span>, <span class="string">"-"</span>]], [[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">" "</span>, <span class="string">" "</span>]]], <span class="string">" "</span>], <span class="string">" "</span>]], [[<span class="string">"C4"</span>, <span class="string">"-"</span>], [<span class="string">"-"</span>, <span class="string">"-"</span>]]], [[<span class="string">"-"</span>, <span class="string">"-"</span>], [<span class="string">"D4"</span>, <span class="string">"-"</span>]]]]</span><br><span class="line">s = TreePainter(parse_tree, <span class="string">'1.png'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;画一棵二叉树。附可执行的Python代码。&lt;/p&gt;
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://ldzhangyx.github.io/tags/python/"/>
    
      <category term="MIR" scheme="http://ldzhangyx.github.io/tags/MIR/"/>
    
      <category term="networkx" scheme="http://ldzhangyx.github.io/tags/networkx/"/>
    
      <category term="structure" scheme="http://ldzhangyx.github.io/tags/structure/"/>
    
  </entry>
  
  <entry>
    <title>借助pretty_midi包进行数据格式转换</title>
    <link href="http://ldzhangyx.github.io/2020/01/13/music-practice/"/>
    <id>http://ldzhangyx.github.io/2020/01/13/music-practice/</id>
    <published>2020-01-13T06:44:21.000Z</published>
    <updated>2020-01-13T08:03:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>一些能让你的计算机音乐代码更好写的技巧。</p><a id="more"></a><h1 id="如何将midi文件与numpy数据互相转换？"><a href="#如何将midi文件与numpy数据互相转换？" class="headerlink" title="如何将midi文件与numpy数据互相转换？"></a>如何将midi文件与numpy数据互相转换？</h1><p>midi文件是以事件序列的方式存储的。一般来说，midi在文件头之后，会包含一系列事件，包括开始，停止（最常见）和其他指令。具体的MIDI文件信息可以参见<a href="http://blog.bitfoc.us/p/495" target="_blank" rel="noopener">这篇博文</a>，对MIDI文件有着简约明了的解释。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>有一些音乐生成模型，直接采用了MIDI message作为输入和输出序列；但是，对于大多数symbolic的研究来说，我们会选择将音符序列映射到一个130维的one-hot向量序列中，一个音符/休止符/持续对应一个向量；而对于chord，有两种方法表示：</p><ol><li>使用<a href="https://www.wikiwand.com/en/Chroma_feature" target="_blank" rel="noopener">chroma表示</a>；</li><li>将12个大调，12个小调单独表示，其余和弦归为第25类（如下图）。</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>MIDI能表示的音高从0-127，一共128种。加上rest和sustain，只有130种表示。这意味着我们不需要特意去做word embedding，而是可以直接将one-hot向量输入模型。</p><p>这种表示类似于piano-roll，也是一种常用表示。只不过piano在rest和sustain上的表示略有不同。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>选定一个分辨率，如16分音符，则一首音乐里的所有音符都有一个相对于分辨率的长度，而分辨率的时长成为了单位长度。</p><p>一首简单的歌：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>以8分音符为最小分辨率，那么这段歌曲的音符时长为（1，1，1，1，1，1，3，3）. 向量表示为(64, 65, 64, 63, 62, 61, 60, 128, 128, 57, 128, 128)，当然实际上都是one-hot向量表示。</p><h2 id="如何转换一个单旋律midi到numpy矩阵"><a href="#如何转换一个单旋律midi到numpy矩阵" class="headerlink" title="如何转换一个单旋律midi到numpy矩阵"></a>如何转换一个单旋律midi到numpy矩阵</h2><p>首先取出midi中的音乐信息，将第一个音轨提出来，然后取所有音符元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">music = pretty_midi.PrettyMIDI(fpath)</span><br><span class="line">notes = music.instruments[<span class="number">0</span>].notes</span><br></pre></td></tr></table></figure><p>Pretty_midi的文档可以参见：<a href="http://craffel.github.io/pretty-midi/" target="_blank" rel="noopener">http://craffel.github.io/pretty-midi/</a></p><p>下一步，纪录一个时间戳t和保存向量的列表roll。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = <span class="number">0.</span></span><br><span class="line">roll = []</span><br></pre></td></tr></table></figure><p>在Notes里遍历，找出所有音符的音高和长度，同时不放过休止符。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> note <span class="keyword">in</span> notes:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>两个相邻的音符不是无缝连接，说明休止符存在。计算其相对于最小分辨率率<code>unit_time</code>的相对时长T，建立一个(T, 130)的矩阵，将第129维置1.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elapsed_time = note.start - t</span><br><span class="line"><span class="keyword">if</span> elapsed_time &gt; <span class="number">0.</span>:</span><br><span class="line">    steps = torch.zeros((int(round(elapsed_time / unit_time)), <span class="number">130</span>))</span><br><span class="line">    steps[range(int(round(elapsed_time / unit_time))), <span class="number">129</span>] += <span class="number">1.</span></span><br><span class="line">    roll.append(steps)</span><br></pre></td></tr></table></figure><p>如果是无缝连接，那么检查当前音符：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_units = int(round((note.end - note.start) / unit_time))</span><br><span class="line">steps = torch.zeros((n_units, <span class="number">130</span>))</span><br><span class="line">steps[<span class="number">0</span>, note.pitch] += <span class="number">1</span></span><br><span class="line">steps[range(<span class="number">1</span>, n_units), <span class="number">128</span>] += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>其中除第一列记录pitch外，其他列都记录sustain的128.</p><p>最后合成为一个矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(roll, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">melody_to_numpy</span><span class="params">(fpath=<span class="string">"ashover12.mid"</span>, unit_time=<span class="number">0.125</span>)</span>:</span></span><br><span class="line">    music = pretty_midi.PrettyMIDI(fpath)</span><br><span class="line">    notes = music.instruments[<span class="number">0</span>].notes</span><br><span class="line">    t = <span class="number">0.</span></span><br><span class="line">    roll = list()</span><br><span class="line"><span class="comment">#     print(notes[0], notes[-1])</span></span><br><span class="line">    <span class="keyword">for</span> note <span class="keyword">in</span> notes:</span><br><span class="line"><span class="comment">#         print(t, note)</span></span><br><span class="line">        elapsed_time = note.start - t</span><br><span class="line">        <span class="keyword">if</span> elapsed_time &gt; <span class="number">0.</span>:</span><br><span class="line">            steps = torch.zeros((int(round(elapsed_time / unit_time)), <span class="number">130</span>))</span><br><span class="line">            steps[range(int(round(elapsed_time / unit_time))), <span class="number">129</span>] += <span class="number">1.</span></span><br><span class="line">            roll.append(steps)</span><br><span class="line">        n_units = int(round((note.end - note.start) / unit_time))</span><br><span class="line">        steps = torch.zeros((n_units, <span class="number">130</span>))</span><br><span class="line">        steps[<span class="number">0</span>, note.pitch] += <span class="number">1</span></span><br><span class="line">        steps[range(<span class="number">1</span>, n_units), <span class="number">128</span>] += <span class="number">1</span></span><br><span class="line">        roll.append(steps)</span><br><span class="line">        t = note.end</span><br><span class="line">    <span class="keyword">return</span> torch.cat(roll, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h1 id="如何将midi的chord编码为chroma？"><a href="#如何将midi的chord编码为chroma？" class="headerlink" title="如何将midi的chord编码为chroma？"></a>如何将midi的chord编码为chroma？</h1><p>chroma因为不需要考虑sustain的问题，直接遍历得到其总时长：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">max_end = <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> note <span class="keyword">in</span> notes:</span><br><span class="line">    <span class="keyword">if</span> note.end &gt; max_end:</span><br><span class="line">        max_end = note.end</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chord_to_numpy</span><span class="params">(fpath=<span class="string">'12.mid'</span>, unit_time=<span class="number">0.125</span>)</span>:</span></span><br><span class="line">    music = pretty_midi.PrettyMIDI(fpath)</span><br><span class="line">    notes = music.instruments[<span class="number">0</span>].notes</span><br><span class="line">    max_end = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> note <span class="keyword">in</span> notes:</span><br><span class="line">        <span class="keyword">if</span> note.end &gt; max_end:</span><br><span class="line">            max_end = note.end</span><br><span class="line">    chroma = torch.zeros((int(round(max_end / unit_time)), <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> note <span class="keyword">in</span> notes:</span><br><span class="line">        idx = int(round((note.start / unit_time)))</span><br><span class="line">        n_unit = int(round((note.end - note.start) / unit_time))</span><br><span class="line">        chroma[idx:idx + n_unit, note.pitch % <span class="number">12</span>] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> chroma</span><br></pre></td></tr></table></figure><h1 id="如何将numpy矩阵编码回midi？"><a href="#如何将numpy矩阵编码回midi？" class="headerlink" title="如何将numpy矩阵编码回midi？"></a>如何将numpy矩阵编码回midi？</h1><p>仍然用pretty_midi包，指定一个乐器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">music = pretty_midi.PrettyMIDI()</span><br><span class="line">piano_program = pretty_midi.instrument_name_to_program(</span><br><span class="line">    <span class="string">'Acoustic Grand Piano'</span>)</span><br><span class="line">piano = pretty_midi.Instrument(program=piano_program)</span><br></pre></td></tr></table></figure><p>首先根据one-hot向量得到pitch：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">'torch'</span> <span class="keyword">in</span> str(type(i)):</span><br><span class="line">    pitch = int(i.max(<span class="number">0</span>)[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    pitch = int(np.argmax(i))</span><br></pre></td></tr></table></figure><p>然后判断这个pitch该被改写为什么音符。如果pitch=128即sustain，检查所有已读音符的最后一个；如果第一个token就是sustain，则随机初始化一个，避免报错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> pitch &lt; <span class="number">128</span>:</span><br><span class="line">    note = pretty_midi.Note(</span><br><span class="line">        velocity=<span class="number">100</span>, pitch=pitch, start=t, end=t + <span class="number">1</span> / <span class="number">8</span>)</span><br><span class="line">    t += <span class="number">1</span> / <span class="number">8</span></span><br><span class="line">    piano.notes.append(note)</span><br><span class="line"><span class="keyword">elif</span> pitch == <span class="number">128</span>:</span><br><span class="line">    <span class="keyword">if</span> len(piano.notes) &gt; <span class="number">0</span>:</span><br><span class="line">        note = piano.notes.pop()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        p = np.random.randint(<span class="number">60</span>, <span class="number">72</span>)</span><br><span class="line">        note = pretty_midi.Note(</span><br><span class="line">            velocity=<span class="number">100</span>, pitch=int(p), start=<span class="number">0</span>, end=t)</span><br><span class="line">    note = pretty_midi.Note(</span><br><span class="line">        velocity=<span class="number">100</span>,</span><br><span class="line">        pitch=note.pitch,</span><br><span class="line">        start=note.start,</span><br><span class="line">        end=note.end + <span class="number">1</span> / <span class="number">8</span>)</span><br><span class="line">    piano.notes.append(note)</span><br><span class="line">    t += <span class="number">1</span> / <span class="number">8</span></span><br><span class="line"><span class="keyword">elif</span> pitch == <span class="number">129</span>:</span><br><span class="line">    t += <span class="number">1</span> / <span class="number">8</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numpy_to_midi</span><span class="params">(sample_roll, output=<span class="string">'sample.mid'</span>)</span>:</span></span><br><span class="line">    music = pretty_midi.PrettyMIDI()</span><br><span class="line">    piano_program = pretty_midi.instrument_name_to_program(</span><br><span class="line">        <span class="string">'Acoustic Grand Piano'</span>)</span><br><span class="line">    piano = pretty_midi.Instrument(program=piano_program)</span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> sample_roll:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'torch'</span> <span class="keyword">in</span> str(type(i)):</span><br><span class="line">            pitch = int(i.max(<span class="number">0</span>)[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pitch = int(np.argmax(i))</span><br><span class="line">        <span class="keyword">if</span> pitch &lt; <span class="number">128</span>:</span><br><span class="line">            note = pretty_midi.Note(</span><br><span class="line">                velocity=<span class="number">100</span>, pitch=pitch, start=t, end=t + <span class="number">1</span> / <span class="number">8</span>)</span><br><span class="line">            t += <span class="number">1</span> / <span class="number">8</span></span><br><span class="line">            piano.notes.append(note)</span><br><span class="line">        <span class="keyword">elif</span> pitch == <span class="number">128</span>:</span><br><span class="line">            <span class="keyword">if</span> len(piano.notes) &gt; <span class="number">0</span>:</span><br><span class="line">                note = piano.notes.pop()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p = np.random.randint(<span class="number">60</span>, <span class="number">72</span>)</span><br><span class="line">                note = pretty_midi.Note(</span><br><span class="line">                    velocity=<span class="number">100</span>, pitch=int(p), start=<span class="number">0</span>, end=t)</span><br><span class="line">            note = pretty_midi.Note(</span><br><span class="line">                velocity=<span class="number">100</span>,</span><br><span class="line">                pitch=note.pitch,</span><br><span class="line">                start=note.start,</span><br><span class="line">                end=note.end + <span class="number">1</span> / <span class="number">8</span>)</span><br><span class="line">            piano.notes.append(note)</span><br><span class="line">            t += <span class="number">1</span> / <span class="number">8</span></span><br><span class="line">        <span class="keyword">elif</span> pitch == <span class="number">129</span>:</span><br><span class="line">            t += <span class="number">1</span> / <span class="number">8</span></span><br><span class="line">    music.instruments.append(piano)</span><br><span class="line">    music.write(output)</span><br></pre></td></tr></table></figure><h1 id="在NLP模型中，如何将音乐数据自然地融入word-embedding？"><a href="#在NLP模型中，如何将音乐数据自然地融入word-embedding？" class="headerlink" title="在NLP模型中，如何将音乐数据自然地融入word embedding？"></a>在NLP模型中，如何将音乐数据自然地融入word embedding？</h1><p>一般来说，音乐输入直接就是one-hot向量序列。但是一些基于NLP的模型有word embedding层，和word2idx层用于id和word embedding的转换。</p><p>利用这类NLP模型的时候建议做一个这样的预处理：将出现的one-hot向量进行处理，得到一个(id, vector)的字典，用于word embedding。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一些能让你的计算机音乐代码更好写的技巧。&lt;/p&gt;
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://ldzhangyx.github.io/tags/python/"/>
    
      <category term="MIR" scheme="http://ldzhangyx.github.io/tags/MIR/"/>
    
      <category term="NLP" scheme="http://ldzhangyx.github.io/tags/NLP/"/>
    
      <category term="nusic" scheme="http://ldzhangyx.github.io/tags/nusic/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch 1.2版本中，mask.bernoulli_()的问题记录和解决方案</title>
    <link href="http://ldzhangyx.github.io/2019/12/09/bernoulli-bool/"/>
    <id>http://ldzhangyx.github.io/2019/12/09/bernoulli-bool/</id>
    <published>2019-12-09T14:43:07.000Z</published>
    <updated>2019-12-10T08:03:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近coding的时候遇到一个问题。以前都没出现，突然出现了。暂时没法定位是不是PyTorch降级的问题。</p><p>环境：PyTorch 1.2， CUDA 10，cudatoolkit 0.40</p><h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>在mask函数里：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_mask</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.dropout == <span class="number">0.</span>:</span><br><span class="line">        self._weight = self.weight</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mask = self.weight.new_empty(</span><br><span class="line">            self.weight.size(),</span><br><span class="line">            dtype=torch.uint8</span><br><span class="line">        )</span><br><span class="line">        mask.bernoulli_(self.dropout)</span><br><span class="line">        self._weight = self.weight.masked_fill(mask, <span class="number">0.</span>)</span><br></pre></td></tr></table></figure><p>mask是一个只有1和0的矩阵，用于dropout实现。在定义mask时，如果将mask定义为<code>torch.uint8</code>类型，在<code>bernoulli()</code>函数里会报如下warning：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.</span><br></pre></td></tr></table></figure><p>提示初始化为bool类型。初始化后，下一步的<code>bernoulli()</code>函数会报另一个错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: &quot;bernoulli_scalar_cuda_&quot; not implemented for &apos;Bool&apos;</span><br></pre></td></tr></table></figure><p>提示<code>bernoulli</code>函数不支持对bool的运算。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>在<code>bernoulli()</code>和<code>bernoulli()</code>中间做一次类型转换：<code>mask.bool()</code></p><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_mask</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.dropout == <span class="number">0.</span>:</span><br><span class="line">        self._weight = self.weight</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mask = self.weight.new_empty(</span><br><span class="line">            self.weight.size(),</span><br><span class="line">            dtype=torch.uint8</span><br><span class="line">        )</span><br><span class="line">        mask.bernoulli_(self.dropout)</span><br><span class="line">        mask = mask.bool()</span><br><span class="line">        self._weight = self.weight.masked_fill(mask, <span class="number">0.</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近coding的时候遇到一个问题。以前都没出现，突然出现了。暂时没法定位是不是PyTorch降级的问题。&lt;/p&gt;
&lt;p&gt;环境：PyTorch 1.2， CUDA 10，cudatoolkit 0.40&lt;/p&gt;
&lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; c
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://ldzhangyx.github.io/tags/python/"/>
    
      <category term="pytorch" scheme="http://ldzhangyx.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch 1.3及以上版本关于forward函数@staticmethod装饰器的一个坑和解决方案</title>
    <link href="http://ldzhangyx.github.io/2019/12/04/pytorch-skill-1204/"/>
    <id>http://ldzhangyx.github.io/2019/12/04/pytorch-skill-1204/</id>
    <published>2019-12-03T20:39:41.000Z</published>
    <updated>2019-12-03T20:49:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>使用PyTorch编写代码的时候，我们通常将模型整合进一个类，在init方法里声明模型结构，在forward方法里约定模型里数据的正向流动，然后PyTorch自动生成数据的方向传播backward方法。</p><p>PyTorch在1.3版本及之后，规定forward方法必须是静态方法。违反了该原则的代码将会在运行时报下列错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. &quot;,&quot;Please use new-style autograd function withstatic forward method.&quot;,&quot;(Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)&quot;.</span><br></pre></td></tr></table></figure><p>于是一般的解决办法是，在forward方法声明上一行加入<code>@staticmethod</code>装饰器，即可完成修改。</p><p>但是在一些没那么规范的代码下，这个改进可能会成为我们的绊脚石。如：<a href="https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html</a></p><p>这一篇文章里提到的代码，其训练和推断使用了两个不同的路径，使得模型结构比较混乱。我自行尝试后，发现无论如何没有办法解决掉这个问题。</p><p>一个临时的解决办法是：</p><ol><li><p>将PyTorch降级到1.2版本及以下，因为这个改进直到1.3版本才正式生效；</p></li><li><p>手动忽略掉UserWarning：</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用PyTorch编写代码的时候，我们通常将模型整合进一个类，在init方法里声明模型结构，在forward方法里约定模型里数据的正向流动，然后PyTorch自动生成数据的方向传播backward方法。&lt;/p&gt;
&lt;p&gt;PyTorch在1.3版本及之后，规定forward方法
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="pytorch" scheme="http://ldzhangyx.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>MuseScore 3：快速使用小记</title>
    <link href="http://ldzhangyx.github.io/2019/11/26/musescore/"/>
    <id>http://ldzhangyx.github.io/2019/11/26/musescore/</id>
    <published>2019-11-26T14:02:17.000Z</published>
    <updated>2019-11-26T14:09:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>MuseScore 3是一款基本功能免费的软件，主要用处是打谱，以及作为各种音乐文件的阅读和编辑器。这篇文章旨在让你快速上手MuseScore。</p><a id="more"></a><h1 id="新建乐谱后，如何输入音符？"><a href="#新建乐谱后，如何输入音符？" class="headerlink" title="新建乐谱后，如何输入音符？"></a>新建乐谱后，如何输入音符？</h1><p>你可以使用鼠标，midi键盘，普通键盘输入。</p><h2 id="鼠标"><a href="#鼠标" class="headerlink" title="鼠标"></a>鼠标</h2><p>按下左上角的音符“N”按钮，选择工具栏中对应的音符，点击乐谱放置到合理的位置上。</p><h2 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h2><ul><li><p>按下“N”键可以打开输入模式。</p></li><li><p>按下Esc键可以退出输入模式。</p></li><li><p>数字键1-9可以选择不同时长的音符。休止符是0键。</p></li><li><p>输入音名即得到对应音符。如敲击C键可以在乐谱当前位置输入一个C音。</p></li><li><p>方向键上下可以对这个音符做升降。</p></li><li><p>方向键左右可以选择不同的乐谱位置输入。</p></li><li><p>Ctrl + 方向键上下可以对音符移八度。</p></li><li><p>Shift + 音名，可以固定住当前位置，这样依次打音名可以打出一个和弦。</p></li></ul><h2 id="Midi键盘"><a href="#Midi键盘" class="headerlink" title="Midi键盘"></a>Midi键盘</h2><ul><li><p>可以通过midi键盘选择对应音高，用键盘辅助输入。</p></li><li><p>同时弹下的音会被同时记录。</p></li></ul><h1 id="工具箱"><a href="#工具箱" class="headerlink" title="工具箱"></a>工具箱</h1><p>工具箱中所有的工具可以通过拖拽和双击的方法添加到乐谱中。</p><h1 id="选中音符"><a href="#选中音符" class="headerlink" title="选中音符"></a>选中音符</h1><ul><li><p>单击音符可以选中。</p></li><li><p>按下ctrl可以多选。</p></li><li><p>按下shift可以拉一个框，自动选中框内所有音符。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MuseScore 3是一款基本功能免费的软件，主要用处是打谱，以及作为各种音乐文件的阅读和编辑器。这篇文章旨在让你快速上手MuseScore。&lt;/p&gt;
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="music" scheme="http://ldzhangyx.github.io/tags/music/"/>
    
      <category term="musescore" scheme="http://ldzhangyx.github.io/tags/musescore/"/>
    
  </entry>
  
  <entry>
    <title>《Poly-tree： A Tree Structure towards Better Polyphonic Music Representation Learning》论文笔记</title>
    <link href="http://ldzhangyx.github.io/2019/10/30/polytree/"/>
    <id>http://ldzhangyx.github.io/2019/10/30/polytree/</id>
    <published>2019-10-30T10:05:10.000Z</published>
    <updated>2019-10-30T10:05:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>组里的最新工作，投到了ICASSP 2020，提出了一种复调音乐的树结构，并利用结构设计了适当的实验，证明其有效性。</p><a id="more"></a><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>复调音乐是一种共时、离散的时间序列新高，通常被表示为1-d的events序列，或者2d的piano roll，缺点是music knowledge不够多，不能体现复调音乐的内在结构。本文提出poly-tree的树结构，包含三个级别：时间序列——音符——音符属性。同时本文进一步提出了一个Encoder-Decoder网络，以学习复调音乐的latent representation（VAE中的<code>z</code>）。在钢琴表征学习任务实验结果显示，poly-tree在<strong>重建准确性</strong>和<strong>模型泛化</strong>方面优于baseline。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对于复调音乐，我们不仅可以从信号处理的角度理解，还可以从音乐本身来理解。复调音乐有metrical structure和pitch order的概念，metrical structure指的是音符之间的时间关系，它们形成了节奏模式；而pitch order与音程有关，可以由此构建harmony（和声）的概念。这两个属性可以一起组成更高级别的音乐结构，例如repetition和sequence。因此，如果数据结构<strong>优先</strong>反映这两个属性，而将其他细节作为次要信息处理。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>poly-tree的主要结构如下：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>可以看到poly-tree顶层是time-step sequence，每一个time-step，包含了一个list，容纳<strong>同时弹下的音符</strong>；中层的list里，每一个音符由其基本属性概括（如pitch和duration）。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>Midi-like event使用这样的方式表示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>Piano-Roll是用这样的方式表示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>上面乐谱被poly-tree以下面的方式表示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="6.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>时间维度上，音乐以不定长数量的block表示。每一个block搭载了不定长数量的此时onset的音符。音符以(128 + N)长度的向量表示，其中128代表pitch，N的长度取决于音乐片段的总长度。如果音乐片段长度为8拍，分辨率为16分音符，意味着一个音符的duration可能为1（16分）~32（双全），共32种表示，则N=5.</p><p>因为时间维度上的block数量和block里同时出现的音符都是数量不同的，故在两个维度各用一次GRU。第一个GRU将block里的音符做转换，再在时间维度上用GRU将转换后的结果再转换为latent representation。如图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="7.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集使用了Musicalion Dataset和POP909 Dataset，前者是古典音乐钢琴数据集，后面的数据集是组里新公开的流行音乐钢琴数据集。</p><h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><p>对于midi-event表征，使用循环VAE；对于piano-roll表征，训练循环VAE，卷积VAE，全连接VAE，后两者是图像级别的操作。具体参数不表，可以阅读原论文。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="8.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="9.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>可以发现新的表征表现得很好，从主观实验结果也能听出其有更高的质量。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;组里的最新工作，投到了ICASSP 2020，提出了一种复调音乐的树结构，并利用结构设计了适当的实验，证明其有效性。&lt;/p&gt;
    
    </summary>
    
      <category term="论文笔记" scheme="http://ldzhangyx.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="music generation" scheme="http://ldzhangyx.github.io/tags/music-generation/"/>
    
      <category term="MIR" scheme="http://ldzhangyx.github.io/tags/MIR/"/>
    
      <category term="representation learning" scheme="http://ldzhangyx.github.io/tags/representation-learning/"/>
    
      <category term="polyphonic music" scheme="http://ldzhangyx.github.io/tags/polyphonic-music/"/>
    
  </entry>
  
  <entry>
    <title>本站评论系统即日起升级为gitalk组件</title>
    <link href="http://ldzhangyx.github.io/2019/10/23/update-1023/"/>
    <id>http://ldzhangyx.github.io/2019/10/23/update-1023/</id>
    <published>2019-10-23T06:16:12.000Z</published>
    <updated>2019-10-23T08:11:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>本站之前的评论系统使用了valine，评论并不能被即时地阅读。升级了评论系统后，gitalk将访客的评论转为issue添加到GitHub repo中，这样我可以及时收到评论提醒。</p><p>另外，最有效和快速的联系方法是<strong>点击首页头像下的邮箱链接，向我发送邮件</strong>。技术讨论类问题会在一天内进行回复。</p><h1 id="Gitalk配置中踩到的坑"><a href="#Gitalk配置中踩到的坑" class="headerlink" title="Gitalk配置中踩到的坑"></a>Gitalk配置中踩到的坑</h1><ul><li><p>Gitalk.ejs可能获取不到_config.yml的参数，使得OAuth链接的参数为空，导致404 Error问题。可以考虑将gitalk.ejs的参数直接硬编码。</p></li><li><p>配置完成后需要手动访问一次文章页面，完成此文章的评论区初始化。文章不多的话可以考虑全部打开一遍，多的话可以考虑自动脚本。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本站之前的评论系统使用了valine，评论并不能被即时地阅读。升级了评论系统后，gitalk将访客的评论转为issue添加到GitHub repo中，这样我可以及时收到评论提醒。&lt;/p&gt;
&lt;p&gt;另外，最有效和快速的联系方法是&lt;strong&gt;点击首页头像下的邮箱链接，向我发送
      
    
    </summary>
    
    
      <category term="others" scheme="http://ldzhangyx.github.io/tags/others/"/>
    
  </entry>
  
  <entry>
    <title>Python两个代码技巧</title>
    <link href="http://ldzhangyx.github.io/2019/10/16/python-trick-1016/"/>
    <id>http://ldzhangyx.github.io/2019/10/16/python-trick-1016/</id>
    <published>2019-10-16T08:50:16.000Z</published>
    <updated>2019-10-16T08:50:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="字符串格式化：F-string（v3-6-）"><a href="#字符串格式化：F-string（v3-6-）" class="headerlink" title="字符串格式化：F-string（v3.6+）"></a>字符串格式化：F-string（v3.6+）</h1><p>之前版本的Python给字符串赋值会使用<code>%</code>和<code>.format()</code>两种方法。F-string提供了第三种方法。</p><p>F-string的使用例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">name = <span class="string">'Bob'</span></span><br><span class="line">age = <span class="number">12</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f"My name is <span class="subst">&#123;name&#125;</span>, and my age is <span class="subst">&#123;age&#125;</span>."</span>)</span><br></pre></td></tr></table></figure><p>这种表达在阅读代码的时候能让人更加容易将位置和变量对应起来。</p><p>PEP 498中提到，其规范的格式应当是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f &apos; &lt;text&gt; &#123; &lt;expression&gt; &lt;optional !s, !r, or !a&gt; &lt;optional : format specifier&gt; &#125; &lt;text&gt; ... &apos;</span><br></pre></td></tr></table></figure><h1 id="赋值的表达式（Assignment-Expressions，-v3-8-）"><a href="#赋值的表达式（Assignment-Expressions，-v3-8-）" class="headerlink" title="赋值的表达式（Assignment Expressions， v3.8+）"></a>赋值的表达式（Assignment Expressions， v3.8+）</h1><p>这是Python 3.8加入的新功能。众所周知Python的<code>=</code>赋值运算符不返回任何值。新增的赋值表达式运算符<code>:=</code>可以完成运算，同时将赋值结果返回。</p><p>这使得以下代码成为可能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (result := function()) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>而如果用普通的<code>=</code>运算符，只能以额外声明变量实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = function()</span><br><span class="line"><span class="keyword">if</span> result <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>或重复计算表达式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> function() <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">print(function())</span><br></pre></td></tr></table></figure><p>新的语法糖改善了此过程。</p><p>PEP 572完整阐述了这个语法糖的使用。给出的其他例子如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    line = fp.readline()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> line:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><p>可以简化成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (line := fp.readline()):</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><p>以及列表推导式可以从</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">results = [</span><br><span class="line">    f(x) <span class="keyword">for</span> x <span class="keyword">in</span> data</span><br><span class="line">    <span class="keyword">if</span> f(x)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>改进以避免重复运算，到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">results = [</span><br><span class="line">    y <span class="keyword">for</span> x <span class="keyword">in</span> data</span><br><span class="line">    <span class="keyword">if</span> (y := f(x))</span><br><span class="line">]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;字符串格式化：F-string（v3-6-）&quot;&gt;&lt;a href=&quot;#字符串格式化：F-string（v3-6-）&quot; class=&quot;headerlink&quot; title=&quot;字符串格式化：F-string（v3.6+）&quot;&gt;&lt;/a&gt;字符串格式化：F-string（v3.6
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="http://ldzhangyx.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>使音乐模型更好地训练的一些技巧（2019.10.16）</title>
    <link href="http://ldzhangyx.github.io/2019/10/16/practice-1016/"/>
    <id>http://ldzhangyx.github.io/2019/10/16/practice-1016/</id>
    <published>2019-10-16T07:17:32.000Z</published>
    <updated>2019-11-11T07:30:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PyTorch与TensorBoard的交互"><a href="#PyTorch与TensorBoard的交互" class="headerlink" title="PyTorch与TensorBoard的交互"></a>PyTorch与TensorBoard的交互</h1><p>PyTorch最近一直在改进TensorBoard的支持，包括在最新v1.3中，也在一直改进。</p><p>最基本的使用方法是，新建一个<code>SummaryWriter</code>对象，之后在合适的位置进行<code>add_scalar()</code>记录，最后<code>close()</code>即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line">writer.add_scalar(<span class="string">"valid loss"</span>, loss, n_iter) <span class="comment"># 三个参数代表变量，数值，横坐标</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><p>文件会保存在代码的<code>.run/</code>目录里，访问<code>localhost:6006</code>即可进行观察。</p><h1 id="音乐数据集的移调数据扩增"><a href="#音乐数据集的移调数据扩增" class="headerlink" title="音乐数据集的移调数据扩增"></a>音乐数据集的移调数据扩增</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">train_X_augment = []</span><br><span class="line">train_Y_augment = []</span><br><span class="line"><span class="keyword">for</span> i, target <span class="keyword">in</span> enumerate(train_Y):</span><br><span class="line">    train_X_augment.append(pad(train_X[i], pad_size))</span><br><span class="line">    train_Y_augment.append(pad(train_Y[i], pad_size))</span><br><span class="line">    <span class="keyword">if</span> augment_data:</span><br><span class="line">        <span class="keyword">for</span> direction <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">for</span> shift <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">12</span>):</span><br><span class="line">                train_X_temp = (train_X[i]).clone()</span><br><span class="line">                train_X_temp[:] += direction * shift</span><br><span class="line">                train_X_augment.append(pad(train_X_temp, pad_size))</span><br><span class="line">                train_Y_augment.append(pad(train_Y[i], pad_size))</span><br><span class="line">train_X = torch.stack(train_X_augment)</span><br><span class="line">train_Y= torch.stack(train_Y_augment)</span><br></pre></td></tr></table></figure><h1 id="统计模型总参数量"><a href="#统计模型总参数量" class="headerlink" title="统计模型总参数量"></a>统计模型总参数量</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">params = list(model.parameters())</span><br><span class="line">total_params = sum(x.size()[<span class="number">0</span>] * x.size()[<span class="number">1</span>] <span class="keyword">if</span> len(x.size()) &gt; <span class="number">1</span> <span class="keyword">else</span> x.size()[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> params <span class="keyword">if</span> x.size())</span><br><span class="line">print(<span class="string">'Args:'</span>, args)</span><br><span class="line">print(<span class="string">'Model total parameters:'</span>, total_params)</span><br></pre></td></tr></table></figure><h1 id="CUDA-out-of-memory问题"><a href="#CUDA-out-of-memory问题" class="headerlink" title="CUDA out of memory问题"></a>CUDA out of memory问题</h1><p>模型在做evaluate的时候经常遇到CUDA out of memory的问题。常见的做法是用<code>with torch.no_grad()</code>方法将对应的代码块包起来，使模型不存储梯度。</p><p>注意，<code>model.eval()</code>代码执行的仅为<code>dropout</code>层和<code>batchnorm</code>层固定的功能，并不能达到<code>torch.no_grad()</code>这样的效果。</p><h1 id="int与one-hot的转换"><a href="#int与one-hot的转换" class="headerlink" title="int与one-hot的转换"></a>int与one-hot的转换</h1><p><code>torch.nn.functional.one_hot(tensor, num_classes=-1)</code>可以直接将int转为one-hot。</p><p>转回来可以通过这种办法：</p><p><code>melody1[0].tolist().index(1)</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PyTorch与TensorBoard的交互&quot;&gt;&lt;a href=&quot;#PyTorch与TensorBoard的交互&quot; class=&quot;headerlink&quot; title=&quot;PyTorch与TensorBoard的交互&quot;&gt;&lt;/a&gt;PyTorch与TensorBoard的
      
    
    </summary>
    
      <category term="开发笔记" scheme="http://ldzhangyx.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="music generation" scheme="http://ldzhangyx.github.io/tags/music-generation/"/>
    
      <category term="心得体会" scheme="http://ldzhangyx.github.io/tags/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
      <category term="PyTorch" scheme="http://ldzhangyx.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>音乐相关会议的deadline一览</title>
    <link href="http://ldzhangyx.github.io/2019/09/12/music-conference-deadline/"/>
    <id>http://ldzhangyx.github.io/2019/09/12/music-conference-deadline/</id>
    <published>2019-09-12T15:05:35.000Z</published>
    <updated>2019-10-16T07:23:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>网站运营的简要介绍。</p><a id="more"></a><p>之前看到aideadlin.es对AI各个领域会议做了一个汇总。音乐领域没有专门的网站做汇集，于是我fork过来重新整理发布了一个网站，挂载在我特意注册的小号上。</p><p>网址是：yixiao-music.github.io，直接点这个网页的侧栏tab也可以直接进去。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>网页更新采用ISMIR社区的回复更新：<a href="https://groups.google.com/a/ismir.net/forum/#!topic/community/8CnJfljcx0E" target="_blank" rel="noopener">https://groups.google.com/a/ismir.net/forum/#!topic/community/8CnJfljcx0E</a></p><p>我计划手动根据回复对这个网站进行数据更新，以避免我的GitHub小号因不常登陆而收不到PR的情况。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;网站运营的简要介绍。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="http://ldzhangyx.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="music generation" scheme="http://ldzhangyx.github.io/tags/music-generation/"/>
    
      <category term="MIR" scheme="http://ldzhangyx.github.io/tags/MIR/"/>
    
      <category term="community" scheme="http://ldzhangyx.github.io/tags/community/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch中，LSTM的两种不同形式</title>
    <link href="http://ldzhangyx.github.io/2019/09/11/lstm/"/>
    <id>http://ldzhangyx.github.io/2019/09/11/lstm/</id>
    <published>2019-09-11T10:20:56.000Z</published>
    <updated>2019-09-11T10:20:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在LSTM这一块有点扯不清，现在回想一下发现自己将两种LSTM记混了。</p><a id="more"></a><h1 id="LSTM-input与label无关"><a href="#LSTM-input与label无关" class="headerlink" title="LSTM(input与label无关)"></a>LSTM(input与label无关)</h1><p>第一种是这样的：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>t时刻的input x与t-1时刻的label y没有关系，完成的是一个序列到另一个序列的转换。</p><p>Neural Language Models通过input和output的错位，用一行LSTM完成操作。</p><p>PyTorch中，直接</p><h1 id="LSTM（input与label有关）"><a href="#LSTM（input与label有关）" class="headerlink" title="LSTM（input与label有关）"></a>LSTM（input与label有关）</h1><p>LSTM被广泛地用于构造Encoder-Decoder模型。Encoder部分没什么问题，但是Decoder部分与上面提到的结构不同，因为Decoder的过程是一步步解码的过程，是将t-1时刻应有的输出，传递给t时刻的cell。这意味着在编码的时候不能一步到位。</p><p>TensorFlow的解决方案是包装了一个decoder。</p><p>在训练的时候，PyTorch的官方文档框架（<a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html）是这样的：" target="_blank" rel="noopener">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html）是这样的：</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">if use_teacher_forcing:</span><br><span class="line">    # Teacher forcing: Feed the target as the next input</span><br><span class="line">    for di in range(target_length):</span><br><span class="line">        decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">            decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">        loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">        decoder_input = target_tensor[di]  # Teacher forcing</span><br><span class="line"></span><br><span class="line">else:</span><br><span class="line">    # Without teacher forcing: use its own predictions as the next input</span><br><span class="line">    for di in range(target_length):</span><br><span class="line">        decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">            decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">        topv, topi = decoder_output.topk(1)</span><br><span class="line">        decoder_input = topi.squeeze().detach()  # detach from history as input</span><br><span class="line"></span><br><span class="line">        loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">        if decoder_input.item() == EOS_token:</span><br><span class="line">            break</span><br></pre></td></tr></table></figure><p>可以看到Decoder是通过for循环进行逐步解码的。这和上面那类LSTM模型的运作规律<strong>不一致</strong>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在LSTM这一块有点扯不清，现在回想一下发现自己将两种LSTM记混了。&lt;/p&gt;
    
    </summary>
    
      <category term="基础技巧" scheme="http://ldzhangyx.github.io/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="PyTorch" scheme="http://ldzhangyx.github.io/tags/PyTorch/"/>
    
      <category term="基础" scheme="http://ldzhangyx.github.io/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="坑" scheme="http://ldzhangyx.github.io/tags/%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>诗歌生成模型“九歌”：《Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement》论文笔记</title>
    <link href="http://ldzhangyx.github.io/2019/08/10/jiuge/"/>
    <id>http://ldzhangyx.github.io/2019/08/10/jiuge/</id>
    <published>2019-08-10T07:22:58.000Z</published>
    <updated>2019-08-10T07:30:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>清华孙茂松老师组的工作，从效果来看，“九歌”的效果相当不错。适逢最近这个模型开源，我希望能梳理一下和这个模型有关的论文，尤其是《Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement》的工作（发表在EMNLP 2018）。</p><a id="more"></a><h1 id="关于模型开源的相关信息"><a href="#关于模型开源的相关信息" class="headerlink" title="关于模型开源的相关信息"></a>关于模型开源的相关信息</h1><p>今年7月，九歌模型开源。其诗歌生成的模型在这个链接里：<a href="https://github.com/THUNLP-AIPoet/StylisticPoetry" target="_blank" rel="noopener">https://github.com/THUNLP-AIPoet/StylisticPoetry</a></p><p>同时，他们组也放出了相关领域的论文列表：<a href="https://github.com/THUNLP-AIPoet/PaperList" target="_blank" rel="noopener">https://github.com/THUNLP-AIPoet/PaperList</a></p><p>以及诗歌生成的相关数据集：<a href="https://github.com/THUNLP-AIPoet/Datasets" target="_blank" rel="noopener">https://github.com/THUNLP-AIPoet/Datasets</a></p><p>有兴趣的话可以深入了解。</p><h1 id="相关论文梳理"><a href="#相关论文梳理" class="headerlink" title="相关论文梳理"></a>相关论文梳理</h1><p>《Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement》这篇论文在发表之后，被相关的后续论文引用。</p><ul><li><p>Sentiment-Controllable Chinese Poetry Generation</p></li><li><p>Rhetorically Controlled Encoder-Decoder for Modern Chinese Poetry Generation</p></li><li><p>Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System</p></li><li><p>GPT-based Generation for Classical Chinese Poetry（华为诺亚方舟实验室）</p></li></ul><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>论文的目标在于无监督生成风格诗歌。之前的诗歌生成更注重于一致性、连续性。本文更关注于同一输入下生成不同风格的诗歌。</p><p>同一意象下，人们可以以不同的风格写出不同的诗歌：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><ul><li>诗歌并没有明确的风格label。本文使用了无监督的方法生成不同风格的诗词。</li><li>论文中，我们提出了一个模型，可以从诗歌中解耦出不同的风格，并在给定人工风格输入后生成特定风格的诗歌。模型总体是seq2seq的，同时通过最大化衡量两个随机变量之间依赖的互信息，以强化人工风格输入和生成的特定风格输出的关系。</li><li>实验结果表明模型可以生成不同风格的诗歌而不丢失一致性和连贯性。</li></ul><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>模型输入：$s_\text{input}$和风格id，$k \in K$，K为风格总数。</p><h3 id="互信息-Mutual-Information"><a href="#互信息-Mutual-Information" class="headerlink" title="互信息(Mutual Information)"></a>互信息(Mutual Information)</h3><p>互信息常被用于无监督生成模型。当我们遇到存在潜在的类别差别而没有标签数据，我们就需要一类能够无监督地辨别出这类潜在标签的数据。互信息在生成模型中被人们注意，最早应该是InfoGAN的提出。</p><p>给定两个随机变量$X$，$Y$，可以将两个随机变量的互信息记为$I(X, Y)$。互信息表示在一个随机变量中包含另一个随机变量的信息的数量。也可以理解为两个变量的相关性。</p><p>互信息可以表示为联合概率$P(X,Y)$与边缘概率的$P(X)P(Y)$的相关性：</p><script type="math/tex; mode=display">I(X, Y)=\int_{Y} \int_{X} p(X, Y) \log \frac{p(X, Y)}{p(X) p(Y)} d X d Y</script><h3 id="风格解耦的Decoder模型"><a href="#风格解耦的Decoder模型" class="headerlink" title="风格解耦的Decoder模型"></a>风格解耦的Decoder模型</h3><p>定义输入句子$X$，输出句子$Y$，字典为$V$，时间步为$T$。</p><p>模型如图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>将Encoder最后一步的hidden state与风格的one-hot向量concatenate起来，送Decoder。</p><p>我们无法从理论上证明，Decoder的output能与风格K正确地对应起来。output很可能会忽略掉风格输入，使得输出不受风格影响。因此我们显式添加一个约束，强制风格K与output有强烈的依赖关系。</p><p>假定K的id分布k是一个均匀分布的随机向量，就是这样：</p><script type="math/tex; mode=display">P_r(\text{sty} = k) = \frac{1}{k}, \text{for }k= 1,2,...,K</script><p>目标转化为：<strong>最大化风格分布$P_r(\text{sty})$与输出分布$P_r(Y;X)$之间的互信息。</strong></p><p>互信息这么计算：</p><script type="math/tex; mode=display">\begin{aligned} & I(\operatorname{Pr}(\text {Sty}), \operatorname{Pr}(Y ; X)) \\=& \sum_{k=1}^{K} \operatorname{Pr}(\text {Sty}=k) \int_{Y | k ; X} \log \frac{\operatorname{Pr}(Y, S t y=k ; X)}{\operatorname{Pr}(\text {Sty}=k) \operatorname{Pr}(Y ; X)} d Y \\=& \sum_{k=1}^{K} \operatorname{Pr}(\text {Sty}=k) \int_{Y | k ; X} \log \frac{\operatorname{Pr}(Y, S t y=k ; X)}{\operatorname{Pr}(Y ; X)} d Y \\ &-\sum_{k=1}^{K} \operatorname{Pr}(\text {Sty}=k) \log \operatorname{Pr}(\text {Sty}=k)\\=& \sum_{k=1}^{K} \operatorname{Pr}(\text {Sty}=k) \int_{Y | k ; X} \log \operatorname{Pr}(\text {Sty}=k | Y) d Y+\log K \\ =&\int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(\text {Sty}=k | Y) \log P(\text {Sty}=k | Y) d Y+\log K\end{aligned}</script><p>因为输入变量$\text{sty}$与$X$相互独立，所以</p><script type="math/tex; mode=display">\operatorname{Pr}(S t y=k | Y ; X)=\operatorname{Pr}(S t y=k | Y)</script><p>由于后验分布$\operatorname{Pr}(S t y=k | Y)$是未知的，我们无法对它计算积分。于是我们使用变分推理最大化的方式，训练一个参数化的函数$Q(\text{Sty}=k|Y)$，这个函数估计了后验分布，最大化方程互信息的下界：</p><script type="math/tex; mode=display">\begin{aligned} & I(\operatorname{Pr}(S t y), \operatorname{Pr}(Y ; X))-\log K \\=& \int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(S t y=k | Y) \log \operatorname{Pr}(S t y=k | Y) d Y \\=& \int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(S t y=k | Y) \log Q(S t y=k | Y) d Y \\ &+\int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(S t y=k | Y) \log \frac{\operatorname{Pr}(S t y=k | Y)}{Q(S t y=k | Y)} d Y \\=& \int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(S t y=k | Y) \log Q(S t y=k | Y) d Y \\ &+\int_{Y ; X} K L(\operatorname{Pr}(S t y | Y), Q(\operatorname{Sty} | Y)) d Y \\ \geq & \int_{Y ; X} \sum_{k=1}^{K} \operatorname{Pr}(S t y=k | Y) \log Q(S t y=k | Y) d Y \\=& \sum_{k=1}^{K} \operatorname{Pr}(S t y=k) \int_{Y | k ; X} \log Q(S t y=k | Y) d Y \end{aligned}</script><p>我们知道KL散度一定是非负的，故上式的不等式一定成立。</p><p>因此我们只需要设计一个参数化的函数Q，使得Q被模型最大化，那么目的就达到了。</p><h3 id="后验分布估计"><a href="#后验分布估计" class="headerlink" title="后验分布估计"></a>后验分布估计</h3><p>给定输出序列$Y$，函数$Q$估计序列$Y$的风格的概率分布。直接计算序列$Y$的平均embedding，用矩阵$W$映射为一个值：</p><script type="math/tex; mode=display">Q(S t y | Y)=\operatorname{softmax}\left(W \cdot \frac{1}{T} \sum_{i=1}^{T} e\left(y_{i}\right)\right)</script><p>最后要做的是计算$Q$在$Y|k;X$上的积分，然而序列$Y$的搜索空间是字典长度的指数，因此采用枚举的方式计算积分。如果我们采样部分Y，这个结果是不可微的。这里我们使用embedding的期望进行积分的近似。</p><h3 id="期望的词向量embedding"><a href="#期望的词向量embedding" class="headerlink" title="期望的词向量embedding"></a>期望的词向量embedding</h3><p>之前的相关工作是《Semantic parsing with semi-supervised sequential autoencoders》。即，只生成一个期望embedding序列，$Y|k;X$，拥有100%的生成概率。下式表达第i词的分布：</p><script type="math/tex; mode=display">p\left(y_{i} | y_{1}, y_{2}, \ldots y_{i-1}, X\right)=g\left(y_{i}, s_{i}\right)</script><p>所以第i词的期望就是：</p><script type="math/tex; mode=display">\operatorname{expect}(i ; k, X)=\sum_{c \in V} g\left(c | s_{i}\right) e(c)</script><p>之后将其喂给下一步的输出：</p><script type="math/tex; mode=display">s_{i+1}=L S T M_{d e c o d e r}\left(s_{i},\left[e x p e c t(i ; k, X), a_{i+1}\right]\right)</script><p>然后使用这些期望向量近似$Y|k;X$的概率分布。</p><p>所以，上面推导出来的</p><script type="math/tex; mode=display">Q(S t y | Y)=\operatorname{softmax}\left(W \cdot \frac{1}{T} \sum_{i=1}^{T} e\left(y_{i}\right)\right)</script><p>可以被重写为：</p><script type="math/tex; mode=display">\mathcal{L}_{r e g}=\frac{1}{K} \sum_{k=1}^{K} \log \left\{\operatorname{softmax}\left(W * \frac{1}{T} \sum_{i=1}^{T} \operatorname{expect}(i ; k, X)\right)[k]\right\}</script><p>k代表第k个风格。所以上面一直推导的的积分公式就可以表达为上式。</p><p>于是上面那个公式就可以作为正则项加入训练过程，作为一个额外的loss：</p><script type="math/tex; mode=display">\operatorname{Train}(X, Y)=\sum_{i=1}^{T} \log p\left(y_{i} | y_{1} y_{2} \ldots y_{i-1}, X\right)+\lambda \mathcal{L}_{\text { reg }}</script><p>loss的前半部分与风格没有什么关系，保证生成的效果，公式中的X置零；而后半部分保证了结果的风格相关。</p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>主要通过人工评估。</p><h3 id="数据集与模型细节"><a href="#数据集与模型细节" class="headerlink" title="数据集与模型细节"></a>数据集与模型细节</h3><p>16.8W首古诗，一半五言，一半七言。8:1:1划分。将连续的两个句子作为训练对$(X,Y)$。</p><p>embedding和Encoder的hidden size为512，风格K=10，所以Decoder的hidden state维度为1034维。</p><p>batch size=50，前5W个batch中$\lambda=0$，之后设为1.</p><h4 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h4><ul><li>Seq2seq，主要用于对比风格模块的提升。</li><li>Polish(Yan, 2016)，特点是多次修改生成的句子。</li><li>Memory(Zhang et al., 2017)，将memory融入到诗歌生成，可以被视为一个正则化行为。</li></ul><p>不考虑rule-based或模板模型。</p><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>将第一句话作为评估，依次生成后续三个句子。由于模型需要指定风格，于是我们使用上文的函数Q来估计第一句的风格，在后面三句中套用同样的风格。</p><ul><li>流畅性</li><li>一致性</li><li>意义性</li><li>诗歌性</li></ul><p>上述四个指标被纳入考虑。</p><p>分别生成了20首五言和20首七言，作为评估。邀请了10个中国文学专家，做了两组实验。第一组对比seq2seq，第二组对比别的先进模型。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>seq2seq生成的是混合风格的模型，更可能产生无意义的诗歌。风格作为统一信息，为一致性提供了帮助，并且缩小了空间，因此在风格内部能学习得更加准确、紧凑。</p><h3 id="习得风格的可解释性"><a href="#习得风格的可解释性" class="headerlink" title="习得风格的可解释性"></a>习得风格的可解释性</h3><p>10种风格的关键词如下：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>首先输入每种风格各生成5首诗，再由人类专家进行分类。由于是无监督生成的，故模型很可能不会严格对齐人类的风格标注。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>可以看见，人类可以以更高的概率成功识别出很多风格。观察结果表明，模型的学习风格只有两三个关键词有意义、可识别。除此之外，生成的诗歌需要是多样的，否则他们不能被区分开。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="6.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;清华孙茂松老师组的工作，从效果来看，“九歌”的效果相当不错。适逢最近这个模型开源，我希望能梳理一下和这个模型有关的论文，尤其是《Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement》的工作（发表在EMNLP 2018）。&lt;/p&gt;
    
    </summary>
    
      <category term="论文笔记" scheme="http://ldzhangyx.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="诗歌生成" scheme="http://ldzhangyx.github.io/tags/%E8%AF%97%E6%AD%8C%E7%94%9F%E6%88%90/"/>
    
      <category term="generation" scheme="http://ldzhangyx.github.io/tags/generation/"/>
    
      <category term="poem generation" scheme="http://ldzhangyx.github.io/tags/poem-generation/"/>
    
      <category term="distanglement" scheme="http://ldzhangyx.github.io/tags/distanglement/"/>
    
  </entry>
  
  <entry>
    <title>如何评估树结构的相似性？也许可以了解一下Tree Editing Distance</title>
    <link href="http://ldzhangyx.github.io/2019/08/07/tree-evaluation/"/>
    <id>http://ldzhangyx.github.io/2019/08/07/tree-evaluation/</id>
    <published>2019-08-07T09:03:45.000Z</published>
    <updated>2019-08-07T09:03:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>这是一篇关于树编辑距离相关算法和相关包的介绍。</p><a id="more"></a><p>如何衡量两个树结构之间有多相似？这个领域有很多相关研究。在这里介绍一个可能的算法：Tree Editing Distance。</p><p>这个词被翻译为树编辑距离。形象地理解，就是从一棵树通过编辑，变为另一棵树的复杂程度。</p><h1 id="树编辑距离的形式化"><a href="#树编辑距离的形式化" class="headerlink" title="树编辑距离的形式化"></a>树编辑距离的形式化</h1><p>形式化地来说，有序标记树之间的树编辑距离，是奖一棵树转换为另一棵树的节点操作的最小成本序列。定义下面三种编辑：</p><ol><li>删除节点，将其子节点连接到父节点上，以保持有序。</li><li>在一个已知的节点，和这个节点的连续子节点的子序列之间插入一个节点。</li><li>更改这个节点的label。</li></ol><p>每编辑一次需要花费一点成本，而问题的目标是找到一个操作序列，使得总成本最小。</p><h1 id="现有算法"><a href="#现有算法" class="headerlink" title="现有算法"></a>现有算法</h1><p>Queen’s University有一份slides，专门用于讲述一些比较早期的算法：<a href="http://research.cs.queensu.ca/TechReports/Reports/1995-372.pdf" target="_blank" rel="noopener">http://research.cs.queensu.ca/TechReports/Reports/1995-372.pdf</a></p><p>这个问题可以被递归地解决，然而其具有指数级的复杂度。Zhang and Shasha（1989年）将这个问题的复杂度降低到了$O(m^2n^2)$级别，而最新的算法（Demaine et al.）将算法的时间复杂度降低到了$O(n^2m(1+\log \frac{m}{n}))$级别。</p><p>具体的论文亮点可以参考这个网址：<a href="http://tree-edit-distance.dbresearch.uni-salzburg.at/#bibliography" target="_blank" rel="noopener">http://tree-edit-distance.dbresearch.uni-salzburg.at/#bibliography</a></p><h1 id="可以使用的包"><a href="#可以使用的包" class="headerlink" title="可以使用的包"></a>可以使用的包</h1><p>GitHub上有人复现了Zhang and Shasha的算法，并且可以直接通过pip方式安装，import调用： <a href="https://github.com/timtadh/zhang-shasha" target="_blank" rel="noopener">https://github.com/timtadh/zhang-shasha</a></p><p>奥地利萨尔茨堡大学公开了一个Java程序，用于实现RTED等复杂度更低的算法：<a href="http://tree-edit-distance.dbresearch.uni-salzburg.at" target="_blank" rel="noopener">http://tree-edit-distance.dbresearch.uni-salzburg.at</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一篇关于树编辑距离相关算法和相关包的介绍。&lt;/p&gt;
    
    </summary>
    
    
      <category term="structure" scheme="http://ldzhangyx.github.io/tags/structure/"/>
    
      <category term="algorithm" scheme="http://ldzhangyx.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch使用的日常（2019.8.5）</title>
    <link href="http://ldzhangyx.github.io/2019/08/05/pytorch-0801/"/>
    <id>http://ldzhangyx.github.io/2019/08/05/pytorch-0801/</id>
    <published>2019-08-05T08:23:48.000Z</published>
    <updated>2020-02-14T18:08:45.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="nn-Embedding"><a href="#nn-Embedding" class="headerlink" title="nn.Embedding"></a>nn.Embedding</h1><p>我一直对nn.Embedding层感到困惑。它在训练中有没有改变过呢？</p><p>查询StackOverflow，我得到了一个答案：</p><ol><li>我可以随机初始化一个词向量，也可以导入一个预训练的词向量；</li><li>我可以选择是否让它参与训练（默认参与了训练）。</li></ol><p>如果要固定某几层不进行训练，需要做两件事：</p><ol><li>层数的requires_grad参数设为False；</li><li>传给optimizer的parameters需要手动过滤。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)</span><br></pre></td></tr></table></figure><h1 id="CUDA-out-of-memory"><a href="#CUDA-out-of-memory" class="headerlink" title="CUDA out of memory"></a>CUDA out of memory</h1><p>遇到了一次这样的情况。考虑optimizer产生的大量中间结果，使得显存爆炸。</p><p>解决方案：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">    ....</span><br></pre></td></tr></table></figure><p>将validation代码放在里面，减少显存占用。实际起到的效果和<code>model.eval()</code>是一样的。</p><h1 id="Learning-Rate-Scheduler"><a href="#Learning-Rate-Scheduler" class="headerlink" title="Learning Rate Scheduler"></a>Learning Rate Scheduler</h1><p>学习率衰减（weight decay）被证明与参数的二阶范数正则化等价。PyTorch使用<code>lr_scheduler</code>进行学习率衰减操作。下面是一类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.0005)</span><br><span class="line">scheduler = ExponentialLR(optimizer, gamma=0.95, minimum=1e-5)</span><br></pre></td></tr></table></figure><p>在训练的时候这样调整学习率：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scheduler.step()</span><br></pre></td></tr></table></figure><p>将这行代码插入你认为应该调整的地方。下面是一种常见做法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = model(input)</span><br><span class="line">loss = loss(output, label)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br><span class="line">schedule.step()</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="使用GELU激活函数"><a href="#使用GELU激活函数" class="headerlink" title="使用GELU激活函数"></a>使用GELU激活函数</h1><p>一些实验证明在NLP领域，GELU函数的效果要好于RELU。</p><h1 id="Word-Embedding的workflow"><a href="#Word-Embedding的workflow" class="headerlink" title="Word Embedding的workflow"></a>Word Embedding的workflow</h1><p>对NLP的数据集做预处理，一般需要两个步骤。</p><ol><li><p>建立word2idx的映射，建立一个字典。</p></li><li><p>idx2vector的映射，使得每一个index对应一个vector。</p></li></ol><p>在不使用高阶API（如pytorch-nlp库）时，两个映射函数都需要自己完成。</p><p>建立word2idx的映射时，首先创建字典。其切分函数一般使用<code>split()</code>或<code>nltk.tokenize()</code>进行单词分割。一般来说需要在句子前后添加<code>&lt;SOS&gt;</code>和<code>&lt;EOS&gt;</code>占位符，使得模型学习到句子的结束。</p><p>在获取数据时，根据字典坐word2idx的转换操作时，有两种方法可供参考。第一种是<code>for</code>循环，而第二种是使用<code>map()</code>函数，将字典作为参数进行转换，在并行化上有优势。</p><p>而idx2vector，如果使用GloVe这类预训练的word vector，可以直接在embedding层里使用<code>nn.Embedding.from_pretrained()</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">embedding_layer = nn.Embedding.from_pretrained(torch.from_numpy(embeddings), freeze=<span class="keyword">True</span>)</span><br><span class="line">embed = Embed(embedding_layer, input_size=input_dim, size=size)</span><br></pre></td></tr></table></figure><p>模型的output一般是embedding size的vector，但是要经过全连接层，通过softmax映射到vocab size大小的vector，然后进行交叉熵运算。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;nn-Embedding&quot;&gt;&lt;a href=&quot;#nn-Embedding&quot; class=&quot;headerlink&quot; title=&quot;nn.Embedding&quot;&gt;&lt;/a&gt;nn.Embedding&lt;/h1&gt;&lt;p&gt;我一直对nn.Embedding层感到困惑。它在训练中有没有
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《Regularizing and Optimizing LSTM Language Models》论文笔记</title>
    <link href="http://ldzhangyx.github.io/2019/07/31/awd-lstm/"/>
    <id>http://ldzhangyx.github.io/2019/07/31/awd-lstm/</id>
    <published>2019-07-31T13:43:44.000Z</published>
    <updated>2019-08-01T07:53:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>人称“语言建模的王者”，AWD-LSTM模型。</p><a id="more"></a><p>原文地址：<a href="https://openreview.net/references/pdf?id=rJI9awpBf" target="_blank" rel="noopener">https://openreview.net/references/pdf?id=rJI9awpBf</a></p><h1 id="论文亮点"><a href="#论文亮点" class="headerlink" title="论文亮点"></a>论文亮点</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文为了解决词级别的语言建模问题，研究了正则化、优化LSTM类模型的策略。本文提出了weighted-dropped LSTM，在hidden to hidden weights上使用了DropConnect，作为循环正则化的形式；此外引入了NT-AvSGD，是平均随机梯度方法的非单调触发变体，使用NT条件自动确定平均触发。</p><p>使用这些和其他正则化策略，AWD-LSTM在PTB和WikiTest-2上达到了最优ppl。模型可用于Q-RNN（Quasi-RNN，和SRU目的一致，都是对RNN进行了并行化改进）。</p><h2 id="Weight-Dropped-LSTM"><a href="#Weight-Dropped-LSTM" class="headerlink" title="Weight-Dropped LSTM"></a>Weight-Dropped LSTM</h2><p>首先给出LSTM的公式：</p><script type="math/tex; mode=display">\begin{aligned} i_{t} &=\sigma\left(W^{i} x_{t}+U^{i} h_{t-1}\right) \\ f_{t} &=\sigma\left(W^{f} x_{t}+U^{f} h_{t-1}\right) \\ o_{t} &=\sigma\left(W^{o} x_{t}+U^{o} h_{t-1}\right) \\ \tilde{c}_{t} &=\tanh \left(W^{c} x_{t}+U^{c} h_{t-1}\right) \\ c_{t} &=i_{t} \odot \tilde{c}_{t}+f_{t} \odot+\tilde{c}_{t-1} \\ h_{t} &=o_{t} \odot \tanh \left(c_{t}\right) \end{aligned}</script><p>正则化技术用于防止RNN过度拟合。之前的递归正则化对$h_{t-1}$或$c_{t}$起作用，阻止了黑盒RNN的实现。</p><p>建议使用DropConnect。DropConnect应用于隐藏状态之间的权重矩阵(Ui, Uf, Uo, Uc)，而不是隐藏状态或记忆状态。这一丢弃操作只在前向和反向传播前进行一次，从而最小化对训练速度的影响，并且适用于任何标准的黑盒RNN优化实现。通过丢弃隐藏状态之间的权重矩阵的部分信息，可以防止LSTM循环连接的过拟合。</p><h2 id="NT-ASGD"><a href="#NT-ASGD" class="headerlink" title="NT-ASGD"></a>NT-ASGD</h2><p>在语言建模过程中，不带动量的SGD的表现比其他优化方法更好。 我们调查AvSGD进一步改善训练过程。AvSGD展示了许多惊讶的结果，比如说而渐近二阶收敛。普通SGD更新公式如下：</p><script type="math/tex; mode=display">w_{k+1}=w_{k}-\gamma_{k} \hat{\nabla} f\left(w_{k}\right)</script><p>但AvSGD不使用最后一步的迭代作为解，而是使用</p><script type="math/tex; mode=display">\frac{1}{(K-T+1)} \sum_{i=T}^{K} w_{i}</script><p>其中K是迭代总数，T是用户指定的平均计算触发器。</p><p>ASGD的缺点在于，学习率$\ita_k$和T的调参没有明确的方法论。</p><p>理想情况下，SGD收敛到稳态分布时，需要触发平均。语言建模使用的一种常见策略是指标停滞时降低学习率，而触发也可以参照这种方法。</p><p>NT-ASGD的作法是，</p><ul><li>仅当验证测度在多次循环后没有改善的情况下才触发平均。所以，当验证测度在n次循环（n称为非单调间隔超参数）后没有改善时，算法换用ASGD。论文作者发现n=5这一设置效果良好。</li><li>使用恒定学习率，因此无需进一步调整。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="其他正则化策略"><a href="#其他正则化策略" class="headerlink" title="其他正则化策略"></a>其他正则化策略</h2><h3 id="变长BPTT"><a href="#变长BPTT" class="headerlink" title="变长BPTT"></a>变长BPTT</h3><p>论文作者指出了固定长度BPTT的低效。假设我们在100个元素上进行长度为10的固定窗口的BPTT。在这一情形下，任何可以被10整除的元素将没有任何元素可以反向传播。固定长度BPTT阻止了1/10的数据以循环的方式改善自身，还有8/10的数据仅仅使用部分BPTT窗口。</p><p>变长BPTT首先选择一个基本序列长度。人工制定一个BPTT，然后基本BPTT长度有p的概率选择BPTT，也有1-p的概率选择BPTT/2。</p><p>然后通过基本BPTT长度计算得到sequence length：</p><script type="math/tex; mode=display">\text{sequence length} = \max(5, l \in N(bptt, \sigma))</script><p>l从正态分布中取样得到结果。这一步是必要的，因为取样任意序列长度的情况下， 使用固定学习率将倾向于短序列。</p><h3 id="变分Dropout"><a href="#变分Dropout" class="headerlink" title="变分Dropout"></a>变分Dropout</h3><p>在标准dropout中，每次调用dropout时取样一个新的dropout掩码。而在变分dropout中，dropout掩码只在第一次调用时取样，接着锁定的dropout掩码重复应用于前向和反向过程中的所有连接。</p><p>尽管RNN的隐藏到隐藏转换中使用了DropConnect，但其他所有dropout操作中使用了变分dropout，特别是在给定的前向和反向传播中，LSTM的所有输入和输出使用同样的dropout掩码。mini-batch内的每个样本使用不同的dropout掩码，而不是在所有样本上使用同一个掩码，以确保元素丢弃的多样性。</p><h3 id="嵌入Dropout"><a href="#嵌入Dropout" class="headerlink" title="嵌入Dropout"></a>嵌入Dropout</h3><p>实际上就是在Embedding Matrix上使用dropout，使得该字在完整的前向、反向传播上都消失了。该技术最早由A Theoretically Grounded Application of Dropout in Recurrent Neural Networks这篇论文提出。</p><h3 id="权重绑定"><a href="#权重绑定" class="headerlink" title="权重绑定"></a>权重绑定</h3><p>权重绑定在embedding和softmax layer上共享了权重，减少了模型中的总参数。该技术具有理论动机（Inan等，2016），并防止模型必须学习输入和输出之间的一对一对应，从而对标准LSTM语言模型进行实质性改进。</p><h3 id="独立embedding-size和hidden-size"><a href="#独立embedding-size和hidden-size" class="headerlink" title="独立embedding size和hidden size"></a>独立embedding size和hidden size</h3><p>在大多数自然语言处理任务中，预训练和训练的单词矢量都具有相对较低的维度 - 通常在100到400维之间。大多数先前的LSTM语言模型将单词向量的维度与LSTM的隐藏状态的维度联系起来。即使减少单词嵌入大小对防止过度拟合也没有好处，语言模型的总参数的最简单减少是减少单词向量大小。</p><p>为了实现这一点，修改第一个和最后一个LSTM层，使得它们的输入和输出维度分别等于减小的嵌入大小。</p><h3 id="激活正则化和时域激活正则化"><a href="#激活正则化和时域激活正则化" class="headerlink" title="激活正则化和时域激活正则化"></a>激活正则化和时域激活正则化</h3><p>L2正则化除用于网络参数上，还可以用在独立单元的激活上，和不同时间步里，RNN的输出上。</p><p>激活正则化惩罚显著过大的激活：</p><script type="math/tex; mode=display">\alpha L_{2}\left(m \odot h_{t}\right)</script><p>时域激活正则化，惩罚过大的hidden state波动：</p><script type="math/tex; mode=display">\beta L_{2}\left(h_{t}-h_{t+1}\right)</script><h2 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h2><p>在PTB和WikiText-2上实验。PTB的词汇量约1W单词，导致大量词汇OOV。WT2的词汇量超过3W。</p><p>LSTM隐单元为三层，1150神经元，Embedding size为400.loss被examples和timesteps平均。embedding被均匀初始化在[-0.1, 0.1]之间，其他权重在$[-\frac{1}{\sqrt{H}}, \frac{1}{\sqrt{H}}]$之间，H为hidden size。</p><p>NT-AvSGD算法训练750 epoches，L相当于1 epoch，n=5. batch size为80（WT2）和40（PTB）。经验表明batch size较大时表现更好。完成后，运行AvSGD，T=0，热启动w0作为finetuning step以进一步改进解。对于这个finetuning步骤，使用算法1的相同的标准终止执行。</p><p>最大范数为0.25的梯度裁剪，初始学习率为30，随机BPTT长度设置为N(70, 5)，p=0.95和N(35, 5)，p=0.05. 用于word vector的dropout、LSTM层间输出，LSTM最上层输出，embedding dropout分别为(0.4, 0.3, 0.4, 0.1)。对WD-LSTM，dropour=0.5用在rurrent weight matrices，而WT2上值增加到0.65，考虑到增加到词汇量。</p><p>对于所以实验，分别使用2和1的AR和TAR值，并将embedding和softmax权重联系起来。所有超参数通过反复实验选择。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="指针模型"><a href="#指针模型" class="headerlink" title="指针模型"></a>指针模型</h3><p>在过去的工作中，已经证明基于指针的注意力模型在改进语言建模方面非常有效（Merity等，2016; Grave等，2016）。鉴于对基础神经语言模型的这种实质性改进，关于指针增强的有效性仍然是一个悬而未决的问题，特别是当重量绑定等改进可能以相互排斥的方式起作用时。</p><p>可以以可忽略的成本在预训练的语言模型之上添加神经缓存模型（Grave等，2016）。神经缓存将先前隐藏状态存储在存储器单元中，然后使用由缓存建议的概率分布和用于预测的语言模型的简单凸组合。缓存模型有三个超参数：缓存的内存大小（窗口），组合的系数（确定两个分布如何混合），以及缓存分布的平坦度。一旦获得训练有素的语言模型，所有这些都在验证集上进行调整，并且不需要自己进行培训，使得使用起来非常便宜。这些超参数的调整值分别为PTB（2000,0.1,1.0）和WT2（3785,0.1279,0.662）。</p><p>在表1和表2中，我们表明该模型进一步改善了语言模型的困惑，PTB的6个困惑点和WT2的11个点。<br>虽然这比Grave等报道的增益要小。<br>（2016），使用LSTM没有重量绑定，这仍然是一个实质性的下降。<br>鉴于神经缓存模型的简单性以及缺乏任何受过训练的组件，这些结果表明现有的神经语言模型基本上缺乏，无法捕获长期依赖关系或有效记住最近看到的单词。<br>为了理解指针对模型的影响，特别是验证集的困惑，我们详细说明了每个单词对表3中缓存模型的整体困惑的贡献。<br>我们计算WikiText-2数据集的验证部分中的目标字的LSTM和LSTM与缓存模型之间的损失函数值（即，对数困扰）的总差异的总和。<br>我们提出差异总和的结果而不是均值，因为后者不合适地过分强调了不经常出现的单词，其中高速缓存有助于显着地忽略频繁出现的单词，其中高速缓存提供适度的改进，累积地做出强有力的贡献。<br>最大累积增益在提高的<unk>令牌的处理，虽然这是超过11540个的情况。<br>第二个最好的改进，大约五分之一由<unk>令牌给定的增益，为经，然而，这仅字发生161次。<br>这表明缓存对于相对罕见的单词仍然有显着帮助，丘吉尔，布莱斯或索尼克进一步证明了这一点。<br>当处理频繁的单词类别（例如标点符号或停用单词）时，缓存不是有益的，语言模型很可能适合这些单词类别。<br>这些观察结果激发了缓存框架的设计，该框架更加了解两个模型的相对优势。</unk></unk></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="AWD-QRNN"><a href="#AWD-QRNN" class="headerlink" title="AWD-QRNN"></a>AWD-QRNN</h3><p>概括一下就是模型也适合Q-RNN。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="模型消融分析"><a href="#模型消融分析" class="headerlink" title="模型消融分析"></a>模型消融分析</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="6.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>详见原论文。 最明显的困惑度提升来自LSTM hidden to hidden的lSTM正则化，也就是DropConnect。</p><h2 id="代码与训练速度"><a href="#代码与训练速度" class="headerlink" title="代码与训练速度"></a>代码与训练速度</h2><p><a href="https://github.com/salesforce/awd-lstm-lm" target="_blank" rel="noopener">https://github.com/salesforce/awd-lstm-lm</a></p><p>代码在上述网址开源，记载了更加详细的实验结果。readme里特意提及了速度的问题。NVIDIA Quadro GP100的速度在PTB上大约是65秒一个epoch。考虑到我们将会使用的HookTheory，这个速度相比WT2的速度更具有参考价值。作者体积K80的速度大约是1/3，而我做实验可以用到一块1080Ti(for each task)。根据NVIDIA提供的compute Capability数值来看：</p><ul><li>Tesla K80：3.7</li><li>Tesla V100：7.0</li><li>Tesla P100：6.0</li><li>Quadro GP100：6.0</li><li>GTX 1080Ti：6.1</li><li>Jetson Nano：5.3</li></ul><p>猜想在词级语言建模任务上，我达到45秒每epoch的速度是正常的。另外这个计算力表其实和我的认知差别有点大。K80这么弱的吗？<br>值得一提的是Jetson Nano，达到5.3的分数意味着可以一用了。过段时间我会调研一下树莓派4和Jetson Nano。</p><h1 id="想法和见解"><a href="#想法和见解" class="headerlink" title="想法和见解"></a>想法和见解</h1><p>还能说什么呢，一年被引用200+次，只能说大佬牛逼，工作量和模型质量都是一流的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;人称“语言建模的王者”，AWD-LSTM模型。&lt;/p&gt;
    
    </summary>
    
      <category term="论文笔记" scheme="http://ldzhangyx.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="AWD-LSTM" scheme="http://ldzhangyx.github.io/tags/AWD-LSTM/"/>
    
      <category term="language model" scheme="http://ldzhangyx.github.io/tags/language-model/"/>
    
  </entry>
  
</feed>
