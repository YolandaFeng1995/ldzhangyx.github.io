<!DOCTYPE html>
<html>
<head>
    
<!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-126536496-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    
    <title>《A Deep Generative Framework for Paraphrase Generation》论文笔记 | 张逸霄的技术小站 | 欢迎RSS订阅我的个人主页！</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="循环神经网络,变分自编码器,自动问答,句子复述">
    <meta name="description" content="这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语句的语法正确性也有一定提升。论文地址：https://arxiv.org/pdf/1709.05074.pdf">
<meta name="keywords" content="循环神经网络,变分自编码器,自动问答,句子复述">
<meta property="og:type" content="article">
<meta property="og:title" content="《A Deep Generative Framework for Paraphrase Generation》论文笔记">
<meta property="og:url" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/index.html">
<meta property="og:site_name" content="张逸霄的技术小站">
<meta property="og:description" content="这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语句的语法正确性也有一定提升。论文地址：https://arxiv.org/pdf/1709.05074.pdf">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/1.jpg">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/3.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/4.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/5.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/6.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/7.png">
<meta property="og:updated_time" content="2018-09-28T21:10:14.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《A Deep Generative Framework for Paraphrase Generation》论文笔记">
<meta name="twitter:description" content="这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语句的语法正确性也有一定提升。论文地址：https://arxiv.org/pdf/1709.05074.pdf">
<meta name="twitter:image" content="http://ldzhangyx.github.io/2018/09/26/deep-para-generation/1.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="张逸霄的技术小站" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">张逸霄</h5>
          <a href="mailto:ldzhangyx@outlook.com" title="ldzhangyx@outlook.com" class="mail">ldzhangyx@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-link"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/projects"  >
                <i class="icon icon-lg icon-code"></i>
                项目列表
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/ldzhangyx" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                GitHub
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://yixiao-music.github.io" target="_blank" >
                <i class="icon icon-lg icon-music"></i>
                音乐会议Deadline
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">《A Deep Generative Framework for Paraphrase Generation》论文笔记</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">《A Deep Generative Framework for Paraphrase Generation》论文笔记</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-09-26T08:44:14.000Z" itemprop="datePublished" class="page-time">
  2018-09-26
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#背景材料"><span class="post-toc-number">1.</span> <span class="post-toc-text">背景材料</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#实现"><span class="post-toc-number">2.</span> <span class="post-toc-text">实现</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#论文笔记"><span class="post-toc-number">3.</span> <span class="post-toc-text">论文笔记</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#摘要"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">摘要</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#引入"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">引入</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#方法"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">方法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#VAE结构"><span class="post-toc-number">3.3.1.</span> <span class="post-toc-text">VAE结构</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#模型结构"><span class="post-toc-number">3.3.2.</span> <span class="post-toc-text">模型结构</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#实验"><span class="post-toc-number">3.4.</span> <span class="post-toc-text">实验</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据集"><span class="post-toc-number">3.4.1.</span> <span class="post-toc-text">数据集</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#MSCOCO数据集"><span class="post-toc-number">3.4.1.1.</span> <span class="post-toc-text">MSCOCO数据集</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Quora数据集"><span class="post-toc-number">3.4.2.</span> <span class="post-toc-text">Quora数据集</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#实验设置"><span class="post-toc-number">3.4.3.</span> <span class="post-toc-text">实验设置</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#评测"><span class="post-toc-number">3.5.</span> <span class="post-toc-text">评测</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#结论"><span class="post-toc-number">3.6.</span> <span class="post-toc-text">结论</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#想法"><span class="post-toc-number">4.</span> <span class="post-toc-text">想法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#文章亮点"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">文章亮点</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#想法-1"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">想法</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-deep-para-generation"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">《A Deep Generative Framework for Paraphrase Generation》论文笔记</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-09-26 16:44:14" datetime="2018-09-26T08:44:14.000Z"  itemprop="datePublished">2018-09-26</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语句的语法正确性也有一定提升。<br>论文地址：<a href="https://arxiv.org/pdf/1709.05074.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1709.05074.pdf</a></p>
<a id="more"></a>
<h1 id="背景材料"><a href="#背景材料" class="headerlink" title="背景材料"></a>背景材料</h1><p>关于变分自编码器在NLP领域的相关介绍，可以看<a href="http://rsarxiv.github.io/2017/03/02/PaperWeekly%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%83%E6%9C%9F/" target="_blank" rel="noopener">这篇讨论</a>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="1.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>关于文本生成的背景研究，可以看<a href="https://www.msra.cn/zh-cn/news/features/ruihua-song-20161226" target="_blank" rel="noopener">这篇文章</a>。</p>
<p>关于VAE的原理（流形学习）和工程实现，可以看<a href="https://blog.csdn.net/JackyTintin/article/details/53641885" target="_blank" rel="noopener">这篇博文</a>。这篇博文详细介绍了VAE的训练过程，Encoder部分（识别模型）和Decoder部分（生成模型）的结构和各个参数的含义。这篇文章同时也提及了reparemetriazation trick的原理。</p>
<p>对于VAE结构的理解和讨论，可以看<a href="https://zhuanlan.zhihu.com/p/34998569" target="_blank" rel="noopener">这篇文章</a>。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>Keras实现<a href="https://github.com/paulx3/keras_generative_pg" target="_blank" rel="noopener">在这里</a>。</p>
<p>PyTorch实现<a href="https://github.com/ale3otik/paraphrases-generator" target="_blank" rel="noopener">在这里</a>。</p>
<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>复述生成是NLP一个重要的课题，本文的模型将VAE和LSTM结合起来生成复述。传统的VAE结合RNN时，生成的句子不符合复述的要求，所以我们将模型的Encoder和Decoder都将原始的句子作为condition进行干涉，这样就达到了复述的效果。这个模型简单、模块化，可以生成不同的多种复述。在量化评测里，本模型明显优于state-of-the-art模型；分析发现模型语法良好；在新数据集上进行了测试，提供了一个baseline。</p>
<h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>Introduction这部分，作者介绍了Paraphrase在QA等方面的应用，以及之前的paraphrase方法，认为其多制约于规则，而深度学习的生成模型更加是数据驱动。<br>区别于VAE的在句子生成上的其他应用，本文的复述模型需要捕获原本句子的特征，所以unconditional的句子生成模型并不适用于此任务。conndition的机制在过去曾被应用到CV领域，然而CV的应用仅仅是用有限的class label作为condition，以及不需要任何的intermediate representation。本文的方法在Encoder和Decoder方面都进行了condition，并且通过LSTM得到intermediate representation。</p>
<p>本文的生成框架对比seq2seq模型，尽管后者可以使用beam search，但不能同时产生多个效果很好的结果，因为beam search的后面结果总是比最顶部的差。在Quora数据集上，本文的模型表现很好。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="VAE结构"><a href="#VAE结构" class="headerlink" title="VAE结构"></a>VAE结构</h3><p>VAE是一个深度生成式隐变量模型，可以从高维输入学习到丰富、非线性的表示。<br>编码器方面，相比AE使用了一个确切的编码器函数$q_{\Phi}$，VAE使用了后验分布$q_{\Phi}(\mathbf{z}|\mathbf{x})$（或者说识别模型）。这个后验分布通常被假设为高斯分部，所以参数$\Phi$只有均值和方差。VAE使后验分布$q_{\Phi}(\mathbf{z}|\mathbf{x})$尽可能地接近先验分布$p(\mathbf{z})$，通常也被视为高斯分布。<br>VAE的解码器模型，使用了另一个分布$p_{\theta}(\mathbf{x}|\mathbf{z})$，也就是输入隐变量$\mathbf(z)$，还原出$\mathbf{x}$。其参数$\theta$使用另一个前馈神经网络的输出值。<br>将观测数据$x^{(i)}$的对数似然可以写作：</p>
<script type="math/tex; mode=display">\log p_\theta(x^{(i)} = KL(q_\varPhi(z|x^{(i)})||p_\theta(z|x^{(i)})) + L(\theta, \varPhi; x^{(i)}))</script><p>将$ELBO$记为$L$，然后通过优化$L$，来间接优化似然。<br>$L$可以写作：</p>
<script type="math/tex; mode=display">L(\theta, \varPhi; x^{(i)})) = -KL(q_\varPhi(z|x^{(i)})||p_\theta(z)) + E_{q_\varPhi(z|x)}[\log p_\theta(x^{(i)}|z)]</script><p>优化目标变为后面两项。</p>
<p>具体的推导可以参考<a href="https://arxiv.org/pdf/1606.05908.pdf" target="_blank" rel="noopener">这个教程</a>。</p>
<p>更多地，在建模文字数据的时候，也可以使用KL-term annealing以及dropout of inputs of the decoder等训练技巧，避免一些问题。</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>我们的训练集使用了N对句子，表示为${\mathbf{s}_n^{(o), \mathbf{s}_n^{(p)}}^N_{n=1}$，其中原始句子用$o$标注，复述句子用$p$标注。句子的向量表示标记为$x^{(o)}$与$x^{(p)}$，</p>
<p>去掉LSTM后，本文的宏观模型如图所示：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>区别于传统的VAE，本文构建的模型将$x^{o}$作为了condition加在了Encoder和Decoder之上。</p>
<p>更加细节的结构如图所示：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>实际上，本文的模型包括了三个LSTM encoder和一个LSTM decoder，总共有4个LSTM，如上图所示。</p>
<p>在VAE的Encoder方面，两个LSTM encoder被使用，第一个转换原始句子$s^{(o)}$到其向量表示$x^{o}$，与复述句子$s^{(p)}$送入第二个LSTM。将两个句子都编码进了LSTM之后，使用一个前馈网络输出$\Phi$，也就是向量表示的均值和方差，送入VAE。</p>
<p>在VAE的Decoder方面，VAE输出隐变量$z$，第三个LSTM编码原始句子，然后将原始句子的向量表示$x^{(o)}$与$z$一同送入第四个LSTM，产生复述的句子。</p>
<p>将LSTM抽象化，可以得到一个这样的模型：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>这个模型的variational lower-bound，也就是$ELBO$如下。最小化KL散度的过程等同于最大化$ELBO$的过程。</p>
<script type="math/tex; mode=display">L(\theta, \Phi; x^{(p)}, x^{(o)})) = E_{q_\Phi(z|x^{(p)}, x^{(o)})}[\log p_\theta(x^{(p)}|z, x^{(o)})] -KL(q_\Phi(z|x^{(p)}, x^{(o)})||p(z))</script><p>模型的训练方法与<a href="https://aclweb.org/anthology/K/K16/K16-1002.pdf" target="_blank" rel="noopener">《Generating sentences from a continuous space》</a>中的相同。这篇论文深深地影响了后续论文的思路。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>本文使用了两个数据集进行评测。</p>
<h4 id="MSCOCO数据集"><a href="#MSCOCO数据集" class="headerlink" title="MSCOCO数据集"></a>MSCOCO数据集</h4><p>这个数据集，也曾用于评测句子复述的方法，对120K张图片分别有人工标注的五句描述。构建数据集的时候，本文随机忽略一个描述，然后将剩下的描述两两配对组成数据集，同时限制长度在15个单词以内，以减少模型复杂度。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="Quora数据集"><a href="#Quora数据集" class="headerlink" title="Quora数据集"></a>Quora数据集</h3><p>Quora在2017年发布了一个数据集，包含400K行潜在的重复问题对。借助这个数据集，本文将重复的问题看作是复述的句子进行训练。重复的问题对大约有155K对，使用50K，100K，150K对进行训练，4K对作为测试。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="6.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>实验的主要参数设置参考了《Generating sentences from a continuous space》的<a href="https://github.com/kefirski/pytorch_RVAE" target="_blank" rel="noopener">实现代码</a>，未对任何数据集做fine-tuning。本文模型中，作者没有使用预先embedding好的词向量，而是自己进行了训练。embedding dimension设置为300，encoder和decoder的dimension是600，隐变量dimension是1100。Encoder只有一层而Decoder有两层。模型使用SGD进行训练，学习率固定为$5*10^{-5}$，dropout为0.3，batch size为32。</p>
<h2 id="评测"><a href="#评测" class="headerlink" title="评测"></a>评测</h2><p>本文使用了BLEU，METEOR和TER进行评测。因为这个过程类似翻译任务，所以借用翻译的指标效果会比较好。评测结果显示优于其他模型。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>评测包含了对实验结果的分析，可以直接阅读原文。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一个深度生成框架，基于VAE，增加了seq2seq模型，用于生成释义。与传统的VAE和无条件句子生成模型不同，这个模型在输入句子上调节VAE的encoder和decoder侧，因此可以为给定句子生成多个释义。在一般复述生成数据集上评估所提出的方法，并且表明它在很大程度上优于现有技术，没有任何超参数调整。本文还评估了对最近发布的问题复述数据集的方法，并展示了其卓越的性能。生成的释义不仅在语义上与原始输入句子相似，而且还能够捕获与原始句子相关的新概念。</p>
<h1 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h1><p><strong>这篇文章是我阅读的第一篇关于VAE文本生成的论文</strong>，我将在本周使用PyTorch完成这个模型的复现工作。在学习VAE背后深层原理的过程中，我遇到了一些麻烦，只能说是初步理解。然而工程上VAE是一个相比GAN更加自然地适用于NLP的模型，其噪声与重建的对抗思路让我对文本生成有了全新的认识。</p>
<p><strong>对于VAE结构，我自己还需要做更多的推导、学习，反复阅读笔记最前面的几篇文章，加深理解。如果不能完整理解VAE的构建过程，就无从提起改进。</strong></p>
<h2 id="文章亮点"><a href="#文章亮点" class="headerlink" title="文章亮点"></a>文章亮点</h2><p>文章提出了一个基于VAE的模型，但这个模型并不是单纯的文本生成，而是使用了condition，那么这个condition对VAE公式要做一些改动，这个思维的推理过程结合了一定理论成分。<br>在句子复述的领域中，这个模型生成的句子在可读性（METEOR，人类评估）上有着一定优势，能不能用于语法改错？虽然语法改错上我猜测基于规则的模型会更加精确全面，但一定程度上自动改善语法问题，应该有一定帮助。</p>
<h2 id="想法-1"><a href="#想法-1" class="headerlink" title="想法"></a>想法</h2><p>这篇文章使用VAE来做句子复述，那么是否可以将condition的概念拓展到另外的领域？</p>
<p>在2016年的那篇VAE做NLP的开创性论文中，提及了这样一个问题，在实际的训练过程中，KL散度可能会出现collapse，导致后验等于先验。由于 RNN-based 的 decoder 有着非常强的 modeling power，直接导致即使依赖很少的 history 信息也可以让 reconstruction errors 降得很低，换句话说，decoder 不依赖 encoder 提供的 z 了，VAE-LSTM模型因此退化成RNN-LM语言模型。</p>
<p>在那篇论文里，使用的缓解办法就是KL cost annealing 和 Word dropout。目前对VAE结构的改进研究也很多，我认为改变VAE结构，进行微调，其效果有可能陷入GAN的一堆改进结构的泥淖里。</p>
<p>如果将VAE引入其他模型会怎么样呢？哈佛NLP组提出过<a href="https://zhuanlan.zhihu.com/p/40621695" target="_blank" rel="noopener">注意力模型的解决方案</a>。我觉得这方面的思考非常有吸引力。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2018-09-28T21:10:14.000Z" itemprop="dateUpdated">2018-09-29 05:10:14</time>
</span><br>


        
        原文地址：<a href="/2018/09/26/deep-para-generation/" target="_blank" rel="external">http://ldzhangyx.github.io/2018/09/26/deep-para-generation/</a>
        
    </div>
    
    <footer>
        <a href="http://ldzhangyx.github.io">
            <img src="/img/avatar.jpg" alt="张逸霄">
            张逸霄
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/变分自编码器/">变分自编码器</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/句子复述/">句子复述</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/循环神经网络/">循环神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自动问答/">自动问答</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&title=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&title=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&source=这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2018/10/14/self-attention/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">self-attention与attention简要梳理</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/09/26/xiaoice-band/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">《XiaoIce Band: A Melody and Arrangement Generation Framework for Pop Music》论文笔记</h4>
      </a>
    </div>
  
</nav>



    

















    <section class="comments" id="comments">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
        <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
        <script>
            var id = location.pathname
            if (location.pathname.length > 50) {
              id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
            }
            const gitalk = new Gitalk({
              clientID: '2fe1bcc914de92fd5141',
              clientSecret: '38e2830b66e3ce7e3a8b21cc86bbd2b715f6b2e3',
              repo: 'ldzhangyx.github.io',
              owner: 'ldzhangyx',
              admin: ['ldzhangyx'],
              id: id,      // Ensure uniqueness and length less than 50
              title: document.title.split('|')[0],
              distractionFreeMode: false  // Facebook-like distraction free mode
            })
            gitalk.render('gitalk-container')
        </script>
    </section>
    


</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        非常感谢~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>张逸霄 &copy; 2017 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&title=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&title=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&source=这篇文章发表在2018年的AAAI上，继承了VAE在自然语言处理上的应用，将其应用于句子复述上，用于生成相似的句子；同时因为RNN可以作为语言模型使用，语..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《《A Deep Generative Framework for Paraphrase Generation》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2018/09/26/deep-para-generation/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJklEQVR42u3aUY6DMAwFwN7/0uwBKthnGyqRTL5WVUozrGTZsT+feB0n63tPvv/6W58nFgYGxmsZx+U623P9nO8jXu85+1ZyNgwMjH0YSShMYl310NUXcfo5BgYGxk2h867Xh4GBgXH9uF4YrdahGBgYGL0iNk8Ee8/8US2OgYHxQkYeCn//9yP9DQwMjFcxjuLKW4+9pkLzVBgYGEsz8gCXp2XVxLEXcDEwMPZh9H4ygfUKzupF3ujNYWBgvIqR86qX/sl4WTKI9k8yioGBsTSjGnx7JWsemqtFLwYGxm6MeXsgv5Krvpp50omBgfF2Rt4AmBxuEsqj/wAGBsbSjMnVfK/orVILJTQGBsaijOoVWD6RNWmRlq/bMDAwFmVUj5tE7nubCqPyFQMDYwlGdeSiFy4nwxZ5yMbAwFiV0SsmJ4fLA3RzZgQDA2M5xnOBeNLsvGGcAgMDYyHGJIHLRyKq+Vu1bMbAwFibMSlEJ0fsBd8oEGNgYCzKeGQ8q5gU9loRp10ODAyMRRnzoYfrPXmx2mwwYGBgbMNIssj8uPnh5m1ODAyMVRlHcSVXafm1fvL8KHBjYGAszZi0MyeXZb3Gw2TgAwMD4+2MauGal769N1ctnjEwMPZh9IYqJgnf/Pnl6QwMDIxtGNcla7XB2QvxUWMAAwNje0YVOamto3YCBgbGBoxJMyAvcedh/YZaHAMD44WMvHTspYm99PHe0hoDA+O1jD/tUfoIuwTHFwAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdnjs.cloudflare.com/ajax/libs/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Yixiao Zhang's Website';
            clearTimeout(titleTime);
        } else {
            document.title = 'Yixiao Zhang's Website';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
