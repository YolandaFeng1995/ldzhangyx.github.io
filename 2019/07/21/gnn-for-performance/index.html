<!DOCTYPE html>
<html>
<head>
    
<!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-126536496-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    
    <title>《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记 | 张逸霄的技术小站 | 欢迎RSS订阅我的个人主页！</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="music generation,structure,音乐生成,VAE,图网络">
    <meta name="description" content="这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师组（出身Stanford的CCRMA实验室，师承Malcolm Slaney老师）。">
<meta name="keywords" content="music generation,structure,音乐生成,VAE,图网络">
<meta property="og:type" content="article">
<meta property="og:title" content="《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记">
<meta property="og:url" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/index.html">
<meta property="og:site_name" content="张逸霄的技术小站">
<meta property="og:description" content="这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师组（出身Stanford的CCRMA实验室，师承Malcolm Slaney老师）。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/1.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/r1.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/r2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/r3.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/r4.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/eq2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/3.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/4.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/5.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/6.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/7.png">
<meta property="og:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/8.png">
<meta property="og:updated_time" content="2019-07-21T16:15:10.050Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记">
<meta name="twitter:description" content="这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师组（出身Stanford的CCRMA实验室，师承Malcolm Slaney老师）。">
<meta name="twitter:image" content="http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/1.png">
    
        <link rel="alternate" type="application/atom+xml" title="张逸霄的技术小站" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">张逸霄</h5>
          <a href="mailto:ldzhangyx@outlook.com" title="ldzhangyx@outlook.com" class="mail">ldzhangyx@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-link"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/projects"  >
                <i class="icon icon-lg icon-code"></i>
                项目列表
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/ldzhangyx" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                GitHub
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://yixiao-music.github.io" target="_blank" >
                <i class="icon icon-lg icon-music"></i>
                音乐会议Deadline
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-21T08:38:46.000Z" itemprop="datePublished" class="page-time">
  2019-07-21
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Abstract"><span class="post-toc-number">1.</span> <span class="post-toc-text">Abstract</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Introduction"><span class="post-toc-number">2.</span> <span class="post-toc-text">Introduction</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Background"><span class="post-toc-number">3.</span> <span class="post-toc-text">Background</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#GNN"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">GNN</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#VAE"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">VAE</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Model"><span class="post-toc-number">4.</span> <span class="post-toc-text">Model</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#GGNN"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">GGNN</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Hierarchical-Attention-RNN（HAN）"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">Hierarchical Attention RNN（HAN）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Iterative-Sequential-Graph-Network"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">Iterative Sequential Graph Network</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Expressive-Performance-Rendering-System"><span class="post-toc-number">5.</span> <span class="post-toc-text">Expressive Performance Rendering System</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#输入和输出"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">输入和输出</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#模块"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">模块</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Related-Works"><span class="post-toc-number">6.</span> <span class="post-toc-text">Related Works</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Experiment"><span class="post-toc-number">7.</span> <span class="post-toc-text">Experiment</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Data"><span class="post-toc-number">7.1.</span> <span class="post-toc-text">Data</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#对比模型"><span class="post-toc-number">7.2.</span> <span class="post-toc-text">对比模型</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#训练设置"><span class="post-toc-number">7.3.</span> <span class="post-toc-text">训练设置</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#评估"><span class="post-toc-number">7.4.</span> <span class="post-toc-text">评估</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#重建误差（Reconstruction-Loss）"><span class="post-toc-number">7.4.1.</span> <span class="post-toc-text">重建误差（Reconstruction Loss）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#相关系数"><span class="post-toc-number">7.4.2.</span> <span class="post-toc-text">相关系数</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#聆听测试"><span class="post-toc-number">7.4.3.</span> <span class="post-toc-text">聆听测试</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Conclusion"><span class="post-toc-number">8.</span> <span class="post-toc-text">Conclusion</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#想法和见解"><span class="post-toc-number">9.</span> <span class="post-toc-text">想法和见解</span></a></li></ol>
        </nav>
    </aside>


<article id="post-gnn-for-performance"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-21 16:38:46" datetime="2019-07-21T08:38:46.000Z"  itemprop="datePublished">2019-07-21</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师组（出身Stanford的CCRMA实验室，师承Malcolm Slaney老师）。</p>
<a id="more"></a>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文使用图神经网络表示乐谱，将其应用于钢琴演奏的渲染过程中。具体地说，本文使用了音符级别的门控图网络（GGNN）和在小节级别的带分层Attention机制（HAN）的bi-LSTM，进行模型设计。为了建模不同的表现风格，本文使用了VAE。试验结果表明，本文提出的模型产生了更像人类的表现。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>如同演员的表现能更好地调动观众情绪一样，音乐的演奏也具有很多细节。使用计算方法表达演奏，从基于规则的方法、高斯过程、卡尔曼滤波、贝叶斯网络、条件随机场、循环神经网络，都有相关的研究。然而，之前的方法仍然在这个task上有缺陷。</p>
<p>近年来，生成模型在各个领域取得了很多成果，音乐上如自动作曲、音乐转录、声音合成等，都有显著成就。</p>
<p>将神经网络应用到音乐数据，一个主要问题在于定义其输入结构。一般来说，乐谱根据其音高，转换成一个一维的序列数据(Simon &amp; Oore, 2017; Oore et al., 2018; Jeong et al., 2018)。但是一维的编码可能会丢失音符之间的一些多边关系。</p>
<p>另一种输入表示是通过采样，得到Piano Roll的2D矩阵。这使得CNN可以使用，但是基于采样的表示需要更高的维度，和随乐曲复杂性而跟着增长的时间分辨率。这种高维可能会阻碍模型学习长期结构。</p>
<p>为了解决这个问题，我们提出了一种基于GNN的模型，音符作为图中的节点，而乐谱中音符的关系被转化为一个表（后文会详细论述表的构造）。</p>
<p>如图1所示，我们将GNN结合到轻量的RNN来学习长期结构。此外，我们建议使用迭代循环来使用彼此的结果更新GNN和RNN的输入。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>与其他生成任务类似，给定condition，生成各种结果是建模有表现力的演奏的重要目标。我们采用VAE训练模型，包含相同条件C但具有不同输出Y的数据。</p>
<p>系统的范围侧重于为MusicXML格式的乐谱生成MIDI格式的演奏。</p>
<p>论文两点有两个：</p>
<ol>
<li>首次尝试图网络学习乐谱表示；</li>
<li>HAN+RNN的新方法，对钢琴演奏的模仿是无需数据上的额外注释的。</li>
</ol>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><p>虽然CNN和RNN分别在图像处理和序列建模方面取得了重大进展，但是有各种类型的数据无法用这些网络正确处理，图形就是其中一个例子。利用图形神经网络（GNN）处理图形数据的早期研究由（Gori等人，2005）和（Scarselli等人，2009）引入。（Li et al。，2016）介绍了门控图神经网络（GGNN），它结合了现代RNN实践的门控循环单元和GNN。虽然之前的模型受到收缩映射的限制，但GGNN模型首先克服了这一局限。最近使用GNN的研究在各种任务中取得了最新成果，例如分析引文网络（Kipf＆Welling，2016），分子结构（Jin等，2018），程序代码（Allamanis等，2018）），学习结构化政策（Wang et al。，2018a）。</p>
<h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>我们的模型组合了音符级的GGNN，小节级的HAN（使用LSTM），使用在迭代方法中。</p>
<h2 id="GGNN"><a href="#GGNN" class="headerlink" title="GGNN"></a>GGNN</h2><p>我们采用了有向多类别边GGNN（其实就是有向图，箭头还分了个类）学习输入乐谱中的隐含表示。图可以表示为边与节点的集合，即$G=(V,E)$，其中V是节点，E是边。在音乐中，E就是相邻音符之间的连接线。</p>
<p>我们定义了六种边：next，rest，onset，sustain，voice，slur。</p>
<p>next：将音符连接到接下来的音符上。如接下来的音符在上一个音符结束时恰好开始。<br>rest：将音符连接到休止符后面的音符上。多个休止符会被当做单个处理。<br>onset：连接两个同时开始的音符。<br>sustain：在一个音符的开始和结尾中间出现的音符用sustain连接。<br>voice：是next边集的子集。它们仅用以连接同一个语音内的音符。<br>slur：在同一个圆滑线下的音符通过slur边互相连接。</p>
<p>（sustain和slur的定义有一些模糊，因为其没有注明是否仅为邻接的）</p>
<p>除了onset边以外，所有的边都是有向的。所以我们将前向和后向的边视为两种不同的类型。同时，为每一个音符添加自我连接，这样一共得到12种不同的边。每种边共享不同的权重参数。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们使用GGNN，因为它在学习图中的节点级表示方面有优势。</p>
<p>GGNN的概念介绍如下：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="r1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="r2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="r3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="r4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>论文中对于GGNN的表述没有超出上面所介绍的范围。</p>
<h2 id="Hierarchical-Attention-RNN（HAN）"><a href="#Hierarchical-Attention-RNN（HAN）" class="headerlink" title="Hierarchical Attention RNN（HAN）"></a>Hierarchical Attention RNN（HAN）</h2><p>我们之前的工作曾使用过HAN渲染有表现力的钢琴演奏。（对比了HRNN和HMRNN）</p>
<p>在分层RNN模型中，使用HAN的原因是其直接适用于GNN。事实上，因为HAN使用注意力来总结较低级别的表示，因此它可以直接应用于任何类型的网络。</p>
<p>我们的系统里，使用了context attention（《Hierarchical attention networks for document classification》里的），将音符表示转为小节向量。attention同时使用了多头注意力机制（multi-head attention）。通过这种方法，每一个小节的内容可以转化到高层的一个节点里。</p>
<p>作者的公式有一些问题，不过大致上就是attention计算那一套，其中$u_c$是context vector。因为context vector并没有接受其他输入，实际上这是一个trainable的参数。计算细节不在此赘述。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="eq2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Iterative-Sequential-Graph-Network"><a href="#Iterative-Sequential-Graph-Network" class="headerlink" title="Iterative Sequential Graph Network"></a>Iterative Sequential Graph Network</h2><p>组合来自不同分层单元的输出的简单方法是将它们连接为单个向量。然而，这种方法具有以下限制：较低级别的层不能以较高层中编码的长期上下文为条件，因为较高级别的输出不会影响较低级别的层。<br>在HRNN和HM-RNN中，较低级别的隐藏状态在分层边界处被馈送到较高级别，反之亦然。然而，在HAN中，隐藏状态传播仅在自下而上的方向上进行。<br>当模型的目标结果是给定顺序输入的单个输出时，例如在最初应用HAN的文档分类中，这种限制并不重要。但是为每个音符学习音乐表示时，我们希望高层的信息也能传到底层去，利用更加扩展的上下文学习。<br>为了克服这个限制，我们提出了GGNN和HAN的组合，称为迭代顺序图网络（ISGN），GGNN和HAN以迭代的方式将它们的结果互相馈送：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>GGNN不仅接受音符表示，还接受高层的hidden state，以concatenate的方式输送。第一次迭代中，高层信息为0，之后再用HAN高层状态接进来。</p>
<p>这样的结构有两个优点：</p>
<ol>
<li>GGNN可以将HAN输出作为输入，考虑更长时间的context。</li>
<li>RNN可以自回归推理，可以补偿GGNN中缺乏的自回归机制。</li>
</ol>
<p>另外，多次迭代也一定程度上能弥补非自回归模型的缺点。</p>
<h1 id="Expressive-Performance-Rendering-System"><a href="#Expressive-Performance-Rendering-System" class="headerlink" title="Expressive Performance Rendering System"></a>Expressive Performance Rendering System</h1><p>下图展示了模型结构。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h2><p>模型使用预定义的乐谱和演奏作为输入和输出。特征提取方案在《 Score and performance features for rendering expressive music performances》有详述。输入feature包括各类音乐信息，比如音高、市场、速度、响度、起始偏差、清晰度、踏板等。</p>
<h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><p>系统包括三个结构：乐谱编码器$E_s$，演奏编码器$E_p$，演奏解码器$D_p$。对于给定输入X，$E_s$推断乐谱条件$C$。模块包括两层GGNN，和一层LSTM。输入X经过三层选链接，第一层GGNN仅更新音符级别特征（固定小节级别的特征）；第二层GGNN更新整个隐状态。输出进行skip connection组成C。</p>
<p>根据C和对应的演奏特征Y，$E_p$编码出latent vector Z。Encoder的输入使用了全连接，对concatenated data进行了降维。编码器由GGNN和LSTM组成，具体如图。</p>
<p>Decoder解码器产生演奏特征Y，迭代地推断输入乐谱中每个音符的演奏参数。解码采用了分层解码的概念（《A hierarchical latent vector model for learning long-term structure in music》）。</p>
<p>解码器的输入是C、小节级别演奏风格向量$z_m$，和初始演奏参数的concatenatation。具体设置可以参考原论文。</p>
<h1 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h1><p>最近使用深度神经网络进行音乐生成的最值得注意的研究是Music Transformer（Huang et al。，2019）。该研究的目的是通过将作曲和表演结合为一个单一阶段来产生音乐。基于由self-attention组成的原始Transformer模型（Vaswani等，2017），他们提出了相对位置嵌入的音高和时间，并成功地通过超越他们以前的基于LSTM的模型生成具有长期结构的音乐作品 （Oore等，2018）。然而，如上所述，该任务与本文的范围不同。我们的研究侧重于解释和执行给定的乐谱，但Music Transformer更像是制作即兴创作。</p>
<p>最近，VAE已被用于若干音乐数据生成模型中，例如音乐生成（Roberts等，2018），音乐风格转移（Brunner等，2018）。<br>（Maezawa，2018）正如我们在这项工作中所做的那样，采用有condition的VAE来表现音乐表现。然而，VAE中的潜在向量是在音符级别生成的，而我们的模型使用VAE编码整个演奏，因此单个潜在向量可以表示整个片段的表现风格。<br>已经有关于使用包括神经网络的数据驱动方法自动生成表达演奏任务的研究，其在（Cancino-Chacon等人，’2018）中得到了很好的总结，但是它们实现了有限的演奏要素。<br>例如，他们只推断了速度（Malik＆Ek，2017），忽略了速度变化（Lauly，2010; Giraldo＆Ramirez，2016），假设旋律总是高音（Flossmann等，2013; Kim等 。，2013），或使用标准化的节奏（Grachten＆Cancino Chacon’，2017）。<br>我们的模型旨在实现全面的演奏要素。</p>
<p>将图连接应用在音乐上，生成有表现力的演奏，也有研究(Moulieras &amp; Pachet, 2016)。但是系统仅限于生成单音旋律，且图连接仅用于捕获单音上的音符特征。这个研究与我们的有基本性的不同。</p>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>收集了MuseScore、Musicalion（这是公开的吗？）的MusicXML数据，以及Yamaha e-competition的MIDI数据，将其做了对齐（Makamura, 2017）。</p>
<p>收集到了16位作曲家的227个作品，以及1061个演奏，包含3606930个音符。</p>
<h2 id="对比模型"><a href="#对比模型" class="headerlink" title="对比模型"></a>对比模型</h2><p>本文使用了基于HAN的VAE模型。HAN模型包括使用HAN的score encoder和演奏decoder。score encoder使用音符和语音LSTM作为字符表示，HAN作为节拍几别和小节级别的表示。Baseline省略了HAN和语音LSTM，仅使用音符级别的LSTM。仅使用GGNN替换语音和音符LSTM的修改版本被称为G-HAN。</p>
<p>模型对比如下：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="训练设置"><a href="#训练设置" class="headerlink" title="训练设置"></a>训练设置</h2><p>具体参见原论文。</p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><h3 id="重建误差（Reconstruction-Loss）"><a href="#重建误差（Reconstruction-Loss）" class="headerlink" title="重建误差（Reconstruction Loss）"></a>重建误差（Reconstruction Loss）</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="6.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="聆听测试"><a href="#聆听测试" class="headerlink" title="聆听测试"></a>聆听测试</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="8.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>我们提出了一种迭代序列图网络，它结合了门控图神经网络和分层注意RNN，用于为给定的乐谱建模表现的钢琴演奏。定量和定性评估表明，与以前的模型相比，所提出的模型取得了显着的进步。对于未来的工作，我们将进一步研究如何定量评估表达性能模型。</p>
<h1 id="想法和见解"><a href="#想法和见解" class="headerlink" title="想法和见解"></a>想法和见解</h1><p>用图网络进行乐谱表示是一个很棒的主意。音乐不同于NLP其他任务的一点在于，它可以是多声部协调进行的；音乐的Piano Roll相比图像的丰富信息来说，也比较稀疏。乐谱上的音符稀疏度，用一个图来表示是相当合理的。规定图网络的连接线属性，对图拓扑结构进行定义和约束，图就能自然地表示出乐谱。</p>
<p>论文阐述了一个生成任务，VAE的中间结果z是随机取样的。但是从表示学习的角度来看，VAE能解耦出演奏风格，z必然有其意义。如果指定VAE中间的z，而不是随机生成，那么能否做到某种意义上的演奏风格迁移？</p>
<p>本文的模型设计也颇有意思。实际上，LSTM的表示是GNN的高层表示，这种表示方法是自然且高效的，如果不使用GNN，这种方法难以自然地导出。HAN和GNN的流动机制也是一个很有意思的点。</p>
<p>评估中，模型的性能并不突出，我个人猜测是因为音乐生成任务较困难，在其他的task上也许能有更好的表现。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-07-21T16:15:10.050Z" itemprop="dateUpdated">2019-07-22 00:15:10</time>
</span><br>


        
        原文地址：<a href="/2019/07/21/gnn-for-performance/" target="_blank" rel="external">http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/</a>
        
    </div>
    
    <footer>
        <a href="http://ldzhangyx.github.io">
            <img src="/img/avatar.jpg" alt="张逸霄">
            张逸霄
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VAE/">VAE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/music-generation/">music generation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/structure/">structure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/图网络/">图网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/音乐生成/">音乐生成</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&title=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&title=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&source=这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/07/26/esac/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">我们来聊聊EsAC和Essen Folk Song Database</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/07/21/music-toolkits/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">音乐生成的兵器库：必要的包和数据集</h4>
      </a>
    </div>
  
</nav>



    

















    <section class="comments" id="comments">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
        <script src="gitalk.min.js"></script>
        <script>
            var id = location.pathname
            if (location.pathname.length > 50) {
              id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
            }
            const gitalk = new Gitalk({
              clientID: '2fe1bcc914de92fd5141',
              clientSecret: '38e2830b66e3ce7e3a8b21cc86bbd2b715f6b2e3',
              accessToken: '6d91fb0c829c1a9b85219dd747aa5952fd3ec312',
              repo: 'ldzhangyx.github.io',
              owner: 'ldzhangyx',
              admin: ['ldzhangyx'],
              id: id,      // Ensure uniqueness and length less than 50
              title: document.title.split('|')[0],
              distractionFreeMode: false  // Facebook-like distraction free mode
            })
            gitalk.render('gitalk-container')
        </script>
    </section>
    


</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        非常感谢~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>张逸霄 &copy; 2017 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&title=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&title=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&source=这篇文章的亮点在于利用了图网络编码额外信息，来改进其他任务效果的思想。这篇文章写作清晰，想法新颖，值得关注。文章出自韩国KAIST的Juhan Nam老师..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《《Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance》论文笔记》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/2019/07/21/gnn-for-performance/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJElEQVR42u3ay26DQAwF0P7/T7fbVm3ItQ2VMIdVFMFkDgvHj/n4iK/PX9f374/vT+589dTJFwYGxm0Zn4fXMWOycvJqkvsxMDCew0hC4av7J5s4DrjJ3jAwMDBGQTBIATEwMDCuYEy2VS1iMTAwMHoJXPLsWUXyJbU4BgbGDRl54+z/P18y38DAwLgVo9e4z9O4s8L3m11hYGCsZuQBLi9QJ0nkZD8YGBhPYPSCYILMt9tr2GFgYOxmVAeQ1XuqYTofErzJcDEwMBYxegG3N9TspYPJrjAwMHYz8qWrzbLqQYpJMYyBgbGbcXW4rAbTUS2OgYGxlFENc9WtJOv3WnI/PmNgYDyGkTfCquPJPOrn6/yR4WJgYCxl5IVr7zBENRmdhHIMDIytjPyganW0Wa6hg9WacRoDA+PmjHm3Kt9uD1w+bIGBgbGUkQwD8vFAb5BZHZeW/0MwMDBuy5gndmcdvJiMIjAwMHYzkh++7ifzoxXlkQAGBsY6Ru8Y/Xw8Ofn+j1/HwMB4DKO6UJVdLZ7zF42BgfFkRt6+z9tqhdMfcW8NAwNjK6M3DJgcZp0Uz4WkEAMDYxHjhGjdSgTzYcNktICBgbGJUQ2yxyPPvN3fa8y9fCkYGBgPYFTD6KSsraabhVocAwMDI36qekSjN37AwMDAOKG9dbjd3uDh5WvCwMB4ACMvRKtHK/Lh6CRAY2Bg7Gb0gmaSm/WK2CoGAwNjNeMLX3ssulpaGkgAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdnjs.cloudflare.com/ajax/libs/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Yixiao Zhang's Website';
            clearTimeout(titleTime);
        } else {
            document.title = 'Yixiao Zhang's Website';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
