<!DOCTYPE html>
<html>
<head>
    
<!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-126536496-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    
    <title>项目列表 Project List | 张逸霄的技术小站 | 欢迎RSS订阅我的个人主页！</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="">
    <meta name="description" content="两个音乐无监督隐式结构树提取模型Two Unsupervised Latent Tree Extraction on Symbolic Music Sequence, 2019@card{ Note-level Structure Binary Tree Parsing using Ordered Neurons产生长音乐序列的关键是音乐的层次结构，可以将其表示为音符级别的二叉树。 大多数工作试图">
<meta property="og:type" content="website">
<meta property="og:title" content="项目列表 Project List">
<meta property="og:url" content="http://ldzhangyx.github.io/projects/index.html">
<meta property="og:site_name" content="张逸霄的技术小站">
<meta property="og:description" content="两个音乐无监督隐式结构树提取模型Two Unsupervised Latent Tree Extraction on Symbolic Music Sequence, 2019@card{ Note-level Structure Binary Tree Parsing using Ordered Neurons产生长音乐序列的关键是音乐的层次结构，可以将其表示为音符级别的二叉树。 大多数工作试图">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/11.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/12.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/14.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/13.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/5.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/9.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/6.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/7.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/1.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/2.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/3.png">
<meta property="og:image" content="http://ldzhangyx.github.io/projects/4.png">
<meta property="og:updated_time" content="2020-01-11T08:27:11.840Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="项目列表 Project List">
<meta name="twitter:description" content="两个音乐无监督隐式结构树提取模型Two Unsupervised Latent Tree Extraction on Symbolic Music Sequence, 2019@card{ Note-level Structure Binary Tree Parsing using Ordered Neurons产生长音乐序列的关键是音乐的层次结构，可以将其表示为音符级别的二叉树。 大多数工作试图">
<meta name="twitter:image" content="http://ldzhangyx.github.io/projects/11.png">
    
        <link rel="alternate" type="application/atom+xml" title="张逸霄的技术小站" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">张逸霄</h5>
          <a href="mailto:ldzhangyx@outlook.com" title="ldzhangyx@outlook.com" class="mail">ldzhangyx@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-link"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect active">
              <a href="/projects"  >
                <i class="icon icon-lg icon-code"></i>
                项目列表
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/community"  >
                <i class="icon icon-lg icon-microphone"></i>
                社群活动
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/ldzhangyx" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                GitHub
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://yixiao-music.github.io" target="_blank" >
                <i class="icon icon-lg icon-music"></i>
                音乐会议Deadline
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">项目列表 Project List</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header page-header">

    <div class="container fade-scale">
        <h1 class="title">项目列表 Project List</h1>
        <h5 class="subtitle">
            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    <article class="page-article fade" itemprop="blogPage">
        <div class="post-content page-content" id="page-content" itemprop="pageContent">
            <h1 id="两个音乐无监督隐式结构树提取模型"><a href="#两个音乐无监督隐式结构树提取模型" class="headerlink" title="两个音乐无监督隐式结构树提取模型"></a>两个音乐无监督隐式结构树提取模型</h1><h2 id="Two-Unsupervised-Latent-Tree-Extraction-on-Symbolic-Music-Sequence-2019"><a href="#Two-Unsupervised-Latent-Tree-Extraction-on-Symbolic-Music-Sequence-2019" class="headerlink" title="Two Unsupervised Latent Tree Extraction on Symbolic Music Sequence, 2019"></a>Two Unsupervised Latent Tree Extraction on Symbolic Music Sequence, 2019</h2><div class="card">
<h3 id="Note-level-Structure-Binary-Tree-Parsing-using-Ordered-Neurons"><a href="#Note-level-Structure-Binary-Tree-Parsing-using-Ordered-Neurons" class="headerlink" title="Note-level Structure Binary Tree Parsing using Ordered Neurons"></a>Note-level Structure Binary Tree Parsing using Ordered Neurons</h3><p>产生长音乐序列的关键是音乐的层次结构，可以将其表示为音符级别的二叉树。 大多数工作试图使用监督方法来学习结构，但是这种方法受到手动标记数据的缺乏的严重限制。 为了解决该问题，我使用了有序神经元（也称为ON-LSTM），它推断出可以用来预测先前音符的最佳音乐树结构。 具体来说，它由具有特殊结构状态的多层LSTM网络组成：在每个单元内，添加了两个独立的门单元，用于估计每个步骤的当前状态与先前历史状态之间的相关程度，这也指示是开始一个新的子结构还是只是当前结构的延续。 然后，可以使用贪婪算法从每个先前步骤中计算出的估计值中获得旋律的树形结构。 对和弦和旋律数据集的主观分析表明，生成的层次结构是明确的；GTTM数据集上的客观实验结果表明，该结构同时具有一定的准确性。</p>
<p>The critical key to generating long music sequences is the hierarchical structure of music, which can be represented as note-level binary-trees. Most works try to learn the structure using supervised methods, but such methods are severely limited by the scarcity of manually labeled data. To deal with the problem, I utilized ordered neuron (also known as ON-LSTM), which infers the best possible music tree structure that can be used to predict preceding notes. To be specific, it consists of a multi-layer LSTM network with a special structure state: Inside each cell, two independent gate units are added for estimating the degree of correlation between the current state and the previous historical state for each step, which also indicates if there starts a new sub-structure or just be the continuation of the current structure. Then, the tree structure of the melody can be obtained from the estimated value calculated in each previous step by using the greedy algorithm. Subjective analysis on chord and melody datasets shows that the generated hierarchical structure is explicit; objective experimental results on the GTTM dataset show that the structure has certain accuracy at the same time. </p>
<p>Open Source Code: <a href="https://github.com/ldzhangyx/Unsupervised-Music-Structure-Extraction-via-Ordered-Neurons" target="_blank" rel="noopener">https://github.com/ldzhangyx/Unsupervised-Music-Structure-Extraction-via-Ordered-Neurons</a></p>
<p>Features:</p>
<ul>
<li>A very first program on unsupervised music structure parsing</li>
<li>Support note-level parsing and chord level parsing</li>
<li>Support Nottingham Dataset, Billboard Dataset, HookTheory Melody/Chord Dataset</li>
<li>Provide a MIDI/numpy transfer toolkit</li>
<li>Provide a visualization toolkit for parse trees.</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="11.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Parsing Result: HookTheory Melody Dataset</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="12.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Parsing Result: Billboard Chord Dataset</p>
</div>
<div class="card">
<h3 id="Note-level-Structure-Binary-Tree-Parsing-using-Inside-Outside-Algorithm"><a href="#Note-level-Structure-Binary-Tree-Parsing-using-Inside-Outside-Algorithm" class="headerlink" title="Note-level Structure Binary Tree Parsing using Inside-Outside Algorithm"></a>Note-level Structure Binary Tree Parsing using Inside-Outside Algorithm</h3><p>这个算法启发自DIORA模型，其使用了Inside-outside算法，通过计算音乐序列的结构二叉树的概率，得到二叉树所有可能结构的概率加权。通过CYK算法计算出一棵二叉树后，使用Tree-LSTM模型作为解码器，还原出原来的序列。这个类似VAE的方法，使得二叉树的推导无监督化。</p>
<p>This algorithm is inspired by the DIORA model, which uses the Inside-outside algorithm, and calculates the probability of the structure of the binary tree of the music sequence to obtain the probability weight of all possible structures of the binary tree. After calculating a binary tree through the CYK algorithm, the Tree-LSTM model is used as a decoder to restore the original sequence. This VAE-like method makes the derivation of the binary tree unsupervised.</p>
<p>Open Source Code: <a href="https://github.com/ldzhangyx/diora-for-music-structure" target="_blank" rel="noopener">https://github.com/ldzhangyx/diora-for-music-structure</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="14.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="借助结构化信息的音乐类比生成"><a href="#借助结构化信息的音乐类比生成" class="headerlink" title="借助结构化信息的音乐类比生成"></a>借助结构化信息的音乐类比生成</h1><h2 id="Deep-Music-Analogy-via-Latent-Tree-Structure-Transfer-2019"><a href="#Deep-Music-Analogy-via-Latent-Tree-Structure-Transfer-2019" class="headerlink" title="Deep Music Analogy via Latent Tree Structure Transfer, 2019"></a>Deep Music Analogy via Latent Tree Structure Transfer, 2019</h2><div class="card">
<p>对于音乐结构迁移任务，我通过将树结构矢量视为条件约束，将生成的结构合并到条件VAE模型中，这与情感生成程序类似。 我这样训练了有条件的VAE，然后在推理过程中将结构更改为另一首音乐。 实验结果表明，生成的音乐节奏准确地改变为另一首歌曲的节奏。 结构不仅包括节奏模式，而且它们的高级功能（例如重复，模仿和变体）应反映在任务中。 因此，正在进行一项实验，将所有音符减少为连续演奏的十六分音符，以消除节奏模式的影响。 这些后续实验可能会导致音乐的结构迁移任务取得更多进展。</p>
<p>For the music structure transfer task, I incorporated the generated structure into a conditional VAE model by treating the tree structure vector as a condition constraint, which is like the sentimental generation program. I trained a conditional VAE as such and then changed the structure to another piece of music during the inference process. The experimental results show that the generated music rhythm accurately changes to the rhythm of another song. Structures not only include rhythmic patterns, but their high-level features such as repetition, imitation, and mold advancement should be reflected in the task. Hence, there is an ongoing experiment to reduce all notes to a continuous play of sixteenth notes to eliminate the effects of rhythm patterns. These follow-up experiments may lead to more progress in the structural transfer task of music.</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="13.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="使用神经网络条件随机场的短语级音乐分句"><a href="#使用神经网络条件随机场的短语级音乐分句" class="headerlink" title="使用神经网络条件随机场的短语级音乐分句"></a>使用神经网络条件随机场的短语级音乐分句</h1><h2 id="Phrase-level-Music-Segmentation-Using-Neural-CRF-2019"><a href="#Phrase-level-Music-Segmentation-Using-Neural-CRF-2019" class="headerlink" title="Phrase-level Music Segmentation Using Neural CRF, 2019"></a>Phrase-level Music Segmentation Using Neural CRF, 2019</h2><div class="card">
<p>这是在短语级音乐分割上的一项工作。 以前的模型只是将旋律分割视为一种顺序分类任务，只能对隐藏状态之间的上下文信息进行回复。 与它们相比，我的模型还使用条件随机场（CRF）对标签之间的关系进行建模。 我使用Essen Folksong数据集进行了比较实验，该数据集包含6,000多种世界各地的民歌。 原始数据采用简谱，因此我将数据表示形式转换为一个one-hot向量，每个向量都表示一个16分音符。实验结果表明，我的模型的F1分数为83％，在F1-measure得分上比基线LSTM和CNN分类模型的性能高出约10％。 此外，我们设计了一种新颖的线性标签技术来训练类似CRF的模型，使训练过程更稳定，并且在F1测量结果中表现更进约1%.</p>
<p>我将原始数据集，清洗之后的数据集，和项目的所有代码于GitHub开源。相关论文正在撰写中。</p>
<p>This work is on phrase-level music segmentation. Previous models simply considered melody segmentation as a sequential classification task, which only reply on context information among hidden states. Compared with them, my model also models the relationship among labels using a Conditional Random Field (CRF). I did comparison experiments using the Essen Folksong Dataset, a dataset includes more than 6,000 world-wide folk songs. The original data is in numbered musical notations, thus I transformed the data representation into one-hot vectors, each as a 16th note. Experimental results show that my models gets F1-measure of 83%, which perform roughly 10% better than the baseline LSTM and CNN classification models on the F-measure score. Besides, we disigned a novel linear label technique for training CRF-like models, making the training process more stable, and even perform 1% better in F1-measure result.</p>
<p>I open sourced the original dataset, the cleaned dataset, and all the code of the project on GitHub. I am preparing a manusciript for upcoming conferences (ICMC, ISMIR, etc.)</p>
<p>Project Code: <a href="https://github.com/ldzhangyx/music-melody-segmentation-using-neural-CRF/tree/master/code" target="_blank" rel="noopener">https://github.com/ldzhangyx/music-melody-segmentation-using-neural-CRF/tree/master/code</a><br>Essen Folksong Database: <a href="https://github.com/ldzhangyx/music-melody-segmentation-using-neural-CRF/tree/master/" target="_blank" rel="noopener">https://github.com/ldzhangyx/music-melody-segmentation-using-neural-CRF/tree/master/</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="基于元学习的人工智能投资模型-Bachelor’s-Thesis"><a href="#基于元学习的人工智能投资模型-Bachelor’s-Thesis" class="headerlink" title="基于元学习的人工智能投资模型(Bachelor’s Thesis)"></a>基于元学习的人工智能投资模型(Bachelor’s Thesis)</h1><h2 id="A-Meta-Learning-AI-Investiment-Model-2019"><a href="#A-Meta-Learning-AI-Investiment-Model-2019" class="headerlink" title="A Meta Learning AI Investiment Model, 2019"></a>A Meta Learning AI Investiment Model, 2019</h2><div class="card">
<p>利用计算机技术和数学模型，替代人为主观判断，准确预测金融市场的状态以进行量化交易，是一个富有实际意义的课题。深度学习算法凭借其优势，近年来逐渐成为预测市场状态的重要算法之一。然而，金融市场的状态随着时间，会发生一定的改变。通过过去几年的数据样本学习到的深度学习模型，很可能因为市场状态发生了变化，从而不符合当前市场规律。针对现有深度学习模型的这一问题，本文提出了基于元学习的算法，训练出第二个深度学习模型（下称教师模型），通过观察当前市场状态，针对性地指导原有深度学习模型（下称学生模型）做出相应的调整和训练。<br>本文提出的元学习模型，从下面几个方向进行了数据分析，设计了相应的特征输入，用于教师模型的训练：市场发生的大趋势变化、市场数据的不变性规律、市场状态的间歇性变化、市场数据的噪声。教师模型综合考虑上述特征，在损失函数上对数据样本进行加权操作，从而指导学生模型的训练方向。从实验结果分析，元学习方法使用的各个特征的有效性被证明，通过元学习方法指导过后的模型，在回测的年化超额收益率和多头超额收益率上，相比原有模型均有显著提升，并且具有一定的泛化性。</p>
<p>Using computer technology and mathematical models to accurately predict the state of financial markets, to replace human subjective judgment, is a practical topic. With its advantages, deep learning algorithms have gradually become one of the important algorithms for predicting market conditions in recent years. However, the state of the financial market will change over time. The deep learning model learned through the data samples of the past few years is likely to be inconsistent with current rules because of changes in market state. Aiming at this problem of the existing deep learning model, this paper proposes a meta-learning-based algorithm to train another deep learning model (hereinafter referred to as the teacher model) to guide the original deep learning model (hereinafter referred to as the student model) by observing the current market state make corresponding adjustments and re-training.<br>The meta-learning model proposed in this paper analyzes the data from the following directions and designs the corresponding feature input for the training of the teacher model: the trend of the market, the invariant part of market data, the intermittent state of the market. the changes, and the noise of data. The teacher model comprehensively considers the above characteristics and weights the data samples on the loss function to guide the training direction of the student model. From the analysis of the experimental results, the effectiveness of each feature used in the meta-learning method is proved. The model guided by the meta-learning method has a significant improvement in annualized excess return and long excess return compared to the original model and has a good generalization capacity.</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="9.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="音乐会议截止日期一览"><a href="#音乐会议截止日期一览" class="headerlink" title="音乐会议截止日期一览"></a>音乐会议截止日期一览</h1><h2 id="Music-Conference-Deadline-Overview-System-2019"><a href="#Music-Conference-Deadline-Overview-System-2019" class="headerlink" title="Music Conference Deadline Overview System, 2019"></a>Music Conference Deadline Overview System, 2019</h2><div class="card">
<p>这个项目使用了Ruby和Python进行开发。我从SMC network和ISMIR community中搜集了计算机音乐领域的主要会议，和人工智能领域的一些会议，将其列成表格，动态显示截止日期，以倒计时方式进行提醒。这个项目以静态无后台网站的方式挂载在github.io页面，接受公开的pull request。项目同时也在ISMIR community中公开。我已经收到了<strong>UPF Music Technology Group</strong>的邀请，将会在未来进行项目合作。</p>
<p>This project was developed using Ruby and Python. From the SMC network and the ISMIR community, I collected major conferences in the field of computer music, and some conferences in the field of artificial intelligence. I listed them in a table, dynamically displayed deadlines, and reminded them in countdowns. This project is mounted on the github.io page as a static backgroundless website and accepts public pull requests. The project is also disclosed in the ISMIR community. I have received an invitation from the <strong>UPF Music Technology Group</strong> and will collaborate on this project in the future.</p>
<p>Open Source Code: <a href="https://github.com/yixiao-music/yixiao-music.github.io" target="_blank" rel="noopener">https://github.com/yixiao-music/yixiao-music.github.io</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="6.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="利用深度信念网络预处理得到更好的抽取式文本摘要"><a href="#利用深度信念网络预处理得到更好的抽取式文本摘要" class="headerlink" title="利用深度信念网络预处理得到更好的抽取式文本摘要"></a>利用深度信念网络预处理得到更好的抽取式文本摘要</h1><h2 id="Pretraining-Sentences-with-RBM-for-Extractive-Document-Summarization-2018"><a href="#Pretraining-Sentences-with-RBM-for-Extractive-Document-Summarization-2018" class="headerlink" title="Pretraining Sentences with RBM for Extractive Document Summarization, 2018"></a>Pretraining Sentences with RBM for Extractive Document Summarization, 2018</h2><div class="card">
<p>我们提出了一种神经网络摘要提取模型，其中使用受限玻尔兹曼机（RBM）在没有监督的情况下进行了预训练的句子。 预先训练的句子用作基于递归神经网络（RNN）的序列模型的输入，以进行提取摘要。 我们的模型产生的摘录摘要在DUC 2004和CNN / DailyMail数据集上均凭借单文档和多文档设置超越了state of the art。 我们还介绍了一种简单而有效的算法，用于构建用于提取摘要的训练语料库，即具有标注摘要的句子的文档。</p>
<p>We present a neural extractive summarizer with sentences pre-trained without supervision using a Restricted Boltzmann Machine (RBM). The pre-trained sentences serve as input to a Recurrent Neural Network (RNN) based sequence model for extractive summarization. Our model produces extractive summaries that beat the state-of-the-art with single and multi-document settings on both the DUC 2004 and CNN/DailyMail datasets. We also introduce a simple but efficient algorithm for building a training corpus for extractive summarization, i.e., documents with labelled summary-worthy sentences.</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="Unity-3D引擎的音乐节奏游戏"><a href="#Unity-3D引擎的音乐节奏游戏" class="headerlink" title="Unity 3D引擎的音乐节奏游戏"></a>Unity 3D引擎的音乐节奏游戏</h1><h2 id="Music-Rhythm-Game-Using-Unity-3D-Engine-2018"><a href="#Music-Rhythm-Game-Using-Unity-3D-Engine-2018" class="headerlink" title="Music Rhythm Game Using Unity 3D Engine, 2018"></a>Music Rhythm Game Using Unity 3D Engine, 2018</h2><div class="card">
<p>我们设计了一个3D的音乐节奏游戏。游戏采用了Unity 3D制作，拥有像素画风。我们设计了十六个方形石砖，以4*4的方式排列，玩家可以操纵角色从一个石砖走到另一个石砖，但是时机必须和背景音乐的鼓点相同。为了提高可玩性，我们设计了七个互不相同的小世界，并编写了五万词的剧情故事。</p>
<p>我们使用了情绪可控的的风格化音乐生成模型，以保证每一次游玩时，音乐的节奏都不一样。我们将音乐生成服务托管在Azure云服务器上，并编写代码，在每一次游玩之前向服务器发起生成音乐的请求。对于节奏，我们采用了rule-based的节奏提取算法。</p>
<p>这个游戏在2018年的创新杯拿到了奖项。</p>
<p>We designed a 3D music rhythm game. The game is made in Unity 3D and has a pixel style. We designed sixteen square stone bricks, arranged in a 4 * 4 manner. Players can manipulate characters to walk from one stone brick to another, but the timing must be the same as the drumbeat of background music. To improve playability, we designed seven different small worlds and wrote a 50,000-word storyline.</p>
<p>We use a mood-controllable stylized music generation model to ensure that the rhythm of the music is different every time we play. We host the music generation service on an Azure cloud server and write code to make a request to the server to generate music before each play. For rhythm, we used a rule-based rhythm extraction algorithm.</p>
<p>This game won a prize in Microsoft Imagine Cup 2018.</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure> 
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure> 
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</div>
<h1 id="情绪可控的风格化音乐生成"><a href="#情绪可控的风格化音乐生成" class="headerlink" title="情绪可控的风格化音乐生成"></a>情绪可控的风格化音乐生成</h1><h2 id="Sentiment-controllable-Stylic-Music-Generation-2017"><a href="#Sentiment-controllable-Stylic-Music-Generation-2017" class="headerlink" title="Sentiment-controllable Stylic Music Generation, 2017"></a>Sentiment-controllable Stylic Music Generation, 2017</h2><div class="card">
<p>给定输入句子，模型自动生成与文本情感匹配的音乐。我设计了一个模型，该模型包含两个部分：</p>
<ol>
<li>使用LSTM的文本情感检测器</li>
<li>使用sequence-GAN的风格化作曲模型。</li>
</ol>
<p>该系统的关键功能是NLP-情感-音乐的接口：情感信息来自LSTM检测器，并由GAN作为条件加以控制，充当音乐和文本的可控制的通用表示形式。为此，我们首先需要一个对齐良好的文本音乐数据集，在这里我可以通过组合两个数据集来解决问题：文本情感数据集和情感音乐数据集。由于缺乏情感-音乐数据，我们使用了一种自动方法来生成数据集：情感标签由预先训练的半监督SVM分类器的输出给定，其中输入了歌词和元数据的情感。基于对齐的数据集，可以以端到端的方式训练系统。每个循环包含两个步骤：LSTM的监督学习和GAN序列的策略梯度。我向损失函数添加了情感约束，以确保模型可以利用情感表示。</p>
<p>该项目获得2017年“银杏黄”创新创业基金的资助。</p>
<p>Given input sentences, the goal is to create music that matches the emotion of the texts. I designed a model that contains two parts: </p>
<ol>
<li>a text sentiment detector using LSTM;</li>
<li>a stylistic composer using sequence-GAN. </li>
</ol>
<p>The key feature of the system is the NLP-sentiment-music interface: the sentiment information comes from the LSTM detector and is taken in as condition by GAN, acting as a controllable common representation of music and text. To this end, we first need a well-aligned text-music dataset where I solve the problem by combining two datasets: a text-sentiment dataset and a sentiment-music dataset. Due to the lack of sentiment-music data, we used an automated method to generate a dataset: the sentiment labels are given by the outputs of a pre-trained semi-supervised SVM classifier given inputs of the emotion of lyrics and metadata. Based on the aligned dataset, the system can be trained in an end-to-end fashion. Each loop contains two steps: supervised learning for the LSTM and policy gradient for the sequence GAN. I added a sentiment constraint to the loss function to ensure that the sentiment representation is utilized by the model.</p>
<p>This project is funded by the 2017 Ginkgo Innovation and Entrepreneurship Fund.</p>
</div>

        </div>

        

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        

















    <section class="comments" id="comments">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
        <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
        <script>
            var id = location.pathname
            if (location.pathname.length > 50) {
              id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
            }
            const gitalk = new Gitalk({
              clientID: '2fe1bcc914de92fd5141',
              clientSecret: '38e2830b66e3ce7e3a8b21cc86bbd2b715f6b2e3',
              accessToken: '6d91fb0c829c1a9b85219dd747aa5952fd3ec312',
              repo: 'ldzhangyx.github.io',
              owner: 'ldzhangyx',
              admin: ['ldzhangyx'],
              id: id,      // Ensure uniqueness and length less than 50
              title: document.title.split('|')[0],
              distractionFreeMode: false  // Facebook-like distraction free mode
            })
            gitalk.render('gitalk-container')
        </script>
    </section>
    


    </article>
    
<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        非常感谢~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>


</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>张逸霄 &copy; 2017 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://ldzhangyx.github.io/projects/&title=《项目列表 Project List》 — 张逸霄的技术小站&pic=http://ldzhangyx.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://ldzhangyx.github.io/projects/&title=《项目列表 Project List》 — 张逸霄的技术小站&source=自然语言处理、音乐生成、音乐结构分析等领域的经验分享，也有PyTorch等代码的实践归纳。" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://ldzhangyx.github.io/projects/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《项目列表 Project List》 — 张逸霄的技术小站&url=http://ldzhangyx.github.io/projects/&via=http://ldzhangyx.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://ldzhangyx.github.io/projects/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAAB0ElEQVR42u3aQU7EMAwF0N7/0mU7CE35tpPASC8rBJ30MQvL/sl1xet+Wa+/eX7+3ZM/d1u8cHFxx9z7cb17/fPzCa65Jy4u7kFuUozyQvb8qXw3XFzcz+L2+pC8DcLFxf0U7qph5lAhw8XFHXOT4SeBPhesvPVZMKvh4uIOuHnp2ffzlnwXFxe3xb1ba97ENN+Li4t7hFstOtW/5iNT4bO4uLjHuas6iuT4JB+HCikOLi7umJtvOnlNLzSJJjBcXNxt3KTE9C5VLA5fcHFxj3CjQ834mfwwpnckg4uLe4bbG1omY0z+qbeBCC4u7mbupOF43rpXyHrXvHBxcXdwqxek8jaoWraSLwsXF3c3txduLpu04sGp0JHh4uIu5ZbDylZLNHkGFxf3DLd6zJm3Jsnw02ykcHFxN3OrYUfSlFRHmuRw99vwg4uLu5nbizmqMUo1tf1lN1xc3M3cu7h6EUnvK7iqtRMXF3cRdxJoVmORQhMzR+Pi4o65eUgxCVDyCxnllBcXF3cbt1poqocuvdYnyndxcXH/lFstRluGH1xc3H/G7f0bk7Enun6Bi4u7jVsdfpI4tZrKNG+T4eLibuDmgenk+kWOyMckXFzcDdwv1AefZs8P+awAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdnjs.cloudflare.com/ajax/libs/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Yixiao Zhang's Website';
            clearTimeout(titleTime);
        } else {
            document.title = 'Yixiao Zhang's Website';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
